{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02f5034c",
   "metadata": {},
   "source": [
    "Most codes of context encoder is referenced from ProtoSeq by Gaël Guibon https://github.com/gguibon/protoseq <br>\n",
    "\n",
    "For the vocab library, I downloaded the source code from https://github.com/vincentzlt/torchtext "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b519a0",
   "metadata": {},
   "source": [
    "Put all libraries here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "095b8486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e9d9e455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os, re, time, pickle, collections, importlib, datetime\n",
    "\n",
    "import pandas as pd, numpy as np, pickle\n",
    "from chardet import detect\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "from wordebd import WORDEBD\n",
    "from vocab import Vocab, Vectors\n",
    "from munch import Munch\n",
    "from cnnlstmseq import CNNLSTMseq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a9b14b",
   "metadata": {},
   "source": [
    "Cleaning methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8a3bd9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoding_type(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        rawdata = f.read()\n",
    "    return detect(rawdata)['encoding']\n",
    "\n",
    "def detect_misspelling(source):\n",
    "    pass\n",
    "\n",
    "def replace_spelling(source):    \n",
    "    return re.sub(\"Åf\", \"'\", source)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96e478d",
   "metadata": {},
   "source": [
    "Context Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "10cb5d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# referenced from DialogueGCN, mastodon code\n",
    "def preprocess_text(x):\n",
    "    # Use regex to replace punctuations with spaces\n",
    "    x = re.sub(r'[^\\w\\s]', ' ', x)\n",
    "\n",
    "    # Replace multiple whitespaces with a single space\n",
    "    x = ' '.join(x.split())\n",
    "\n",
    "    # Convert to lowercase\n",
    "    x = x.lower()\n",
    "\n",
    "    return x\n",
    "\n",
    "def load_pretrained_glove(file_path='embed/glove/glove.840B.300d.txt', vector_dimension=300):\n",
    "    glv_vector = {}\n",
    "    start_time = time.time()\n",
    "    with open(file_path, encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            \n",
    "            # Skip lines with unexpected formats or incomplete data\n",
    "            if len(values) < vector_dimension + 1 or not all(v.replace('.', '').isdigit() or v.startswith('-') for v in values[1:]):\n",
    "                continue\n",
    "            \n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:vector_dimension+1], dtype='float')\n",
    "            glv_vector[word] = coefs\n",
    "            print(f\"Took {time.time() - start_time} seconds to load pretrained GloVe model.\")\n",
    "    return glv_vector\n",
    "\n",
    "def encode_labels(encoder, l):\n",
    "    return encoder[l]\n",
    "\n",
    "def load_data_from_npy(file_path):\n",
    "    try:\n",
    "        data = np.load(file_path, allow_pickle=True)\n",
    "        if isinstance(data, np.ndarray):\n",
    "            if data.ndim == 2:\n",
    "                return pd.DataFrame(data)\n",
    "            else:\n",
    "                raise ValueError(\"The loaded array is not two-dimensional.\")\n",
    "        else:\n",
    "            raise TypeError(\"The loaded object is not a NumPy array.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {file_path}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error: An exception occurred - {str(e)}\")\n",
    "        return None\n",
    "    \n",
    "# def sentence_embedding(sentence, embeddings):\n",
    "#     words = sentence.split()\n",
    "#     vectors = [embeddings.get(word, np.zeros(300)) for word in words]\n",
    "#     mean_vector = np.mean(vectors, axis=0)\n",
    "#     return mean_vector\n",
    "\n",
    "def _read_words(data, convmode=None):\n",
    "    '''\n",
    "        Count the occurrences of all words\n",
    "        @param convmode: str, None for non conversational scope, 'naive' for classic or naive approach, 'conv' for conversation depth into account (one additional dim and nested values)\n",
    "        @param data: list of examples\n",
    "        @return words: list of words (with duplicates)\n",
    "    '''\n",
    "    words = []\n",
    "    if convmode is None:\n",
    "        for example in data:\n",
    "            words += example     \n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c584216b",
   "metadata": {},
   "source": [
    "Put main function here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "612c0738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MacRoman\n"
     ]
    }
   ],
   "source": [
    "print(get_encoding_type(\"data/train_sent_emo_dya.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ec0c5f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('data/train_sent_emo_dya.csv', encoding='MacRoman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "598ac1d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Dialogue_ID</th>\n",
       "      <th>Utterance_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>also I was the point person on my companyÅfs t...</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You mustÅfve had your hands full.</td>\n",
       "      <td>The Interviewer</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>That I did. That I did.</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>So letÅfs talk a little bit about your duties.</td>\n",
       "      <td>The Interviewer</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My duties?  All right.</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Now youÅfll be heading a whole division, so yo...</td>\n",
       "      <td>The Interviewer</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I see.</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>But thereÅfll be perhaps 30 people under you s...</td>\n",
       "      <td>The Interviewer</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Good to know.</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>We can go into detail</td>\n",
       "      <td>The Interviewer</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Utterance          Speaker  \\\n",
       "0  also I was the point person on my companyÅfs t...         Chandler   \n",
       "1                  You mustÅfve had your hands full.  The Interviewer   \n",
       "2                            That I did. That I did.         Chandler   \n",
       "3     So letÅfs talk a little bit about your duties.  The Interviewer   \n",
       "4                             My duties?  All right.         Chandler   \n",
       "5  Now youÅfll be heading a whole division, so yo...  The Interviewer   \n",
       "6                                             I see.         Chandler   \n",
       "7  But thereÅfll be perhaps 30 people under you s...  The Interviewer   \n",
       "8                                      Good to know.         Chandler   \n",
       "9                              We can go into detail  The Interviewer   \n",
       "\n",
       "  Sentiment  Dialogue_ID  Utterance_ID  \n",
       "0   neutral            0             0  \n",
       "1   neutral            0             1  \n",
       "2   neutral            0             2  \n",
       "3   neutral            0             3  \n",
       "4  positive            0             4  \n",
       "5   neutral            0             5  \n",
       "6   neutral            0             6  \n",
       "7   neutral            0             7  \n",
       "8   neutral            0             8  \n",
       "9   neutral            0             9  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_features = list(X_train.keys()[6:])\n",
    "drop_features.append(\"Emotion\")\n",
    "drop_features\n",
    "y_train = X_train[[\"Emotion\", \"Dialogue_ID\"]].copy()\n",
    "X_train = X_train.drop(drop_features, axis=1)\n",
    "X_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "05ec2052",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Dialogue_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>surprise</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fear</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>surprise</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>surprise</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Emotion  Dialogue_ID\n",
       "0    neutral            0\n",
       "1    neutral            0\n",
       "2    neutral            0\n",
       "3    neutral            0\n",
       "4   surprise            0\n",
       "5    neutral            0\n",
       "6    neutral            0\n",
       "7    neutral            0\n",
       "8    neutral            0\n",
       "9    neutral            0\n",
       "10      fear            0\n",
       "11   neutral            0\n",
       "12  surprise            0\n",
       "13   neutral            0\n",
       "14  surprise            1"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4c164874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Dialogue_ID</th>\n",
       "      <th>Utterance_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>also i was the point person on my company s tr...</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>you must ve had your hands full</td>\n",
       "      <td>The Interviewer</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>that i did that i did</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>so let s talk a little bit about your duties</td>\n",
       "      <td>The Interviewer</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>my duties all right</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>now you ll be heading a whole division so you ...</td>\n",
       "      <td>The Interviewer</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>i see</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>but there ll be perhaps 30 people under you so...</td>\n",
       "      <td>The Interviewer</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>good to know</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>we can go into detail</td>\n",
       "      <td>The Interviewer</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Utterance          Speaker  \\\n",
       "0  also i was the point person on my company s tr...         Chandler   \n",
       "1                    you must ve had your hands full  The Interviewer   \n",
       "2                              that i did that i did         Chandler   \n",
       "3       so let s talk a little bit about your duties  The Interviewer   \n",
       "4                                my duties all right         Chandler   \n",
       "5  now you ll be heading a whole division so you ...  The Interviewer   \n",
       "6                                              i see         Chandler   \n",
       "7  but there ll be perhaps 30 people under you so...  The Interviewer   \n",
       "8                                       good to know         Chandler   \n",
       "9                              we can go into detail  The Interviewer   \n",
       "\n",
       "  Sentiment  Dialogue_ID  Utterance_ID  \n",
       "0   neutral            0             0  \n",
       "1   neutral            0             1  \n",
       "2   neutral            0             2  \n",
       "3   neutral            0             3  \n",
       "4  positive            0             4  \n",
       "5   neutral            0             5  \n",
       "6   neutral            0             6  \n",
       "7   neutral            0             7  \n",
       "8   neutral            0             8  \n",
       "9   neutral            0             9  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[\"Utterance\"] = X_train[\"Utterance\"].apply(lambda x: replace_spelling(x)).apply(lambda x: preprocess_text(x))\n",
    "X_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d07da4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## encode the emotion labels ##\n",
    "file1 = open('data/dump/label_encoder.pkl', 'rb')\n",
    "file2 = open('data/dump/label_decoder.pkl', 'rb')\n",
    "\n",
    "if file1 and file2 is None:\n",
    "    labels = set(y_train.Emotion)\n",
    "    label_encoder = {label: i for i, label in enumerate(labels)}\n",
    "    label_decoder = {i: label for i, label in enumerate(labels)}\n",
    "\n",
    "    pickle.dump(label_encoder, open('data/dump/label_encoder.pkl', 'wb'))\n",
    "    pickle.dump(label_decoder, open('data/dump/label_decoder.pkl', 'wb'))\n",
    "    \n",
    "else:\n",
    "    label_encoder = pickle.load(file1)\n",
    "    label_decoder = pickle.load(file2)\n",
    "    file1.close()\n",
    "    file2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c499f651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Dialogue_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Emotion  Dialogue_ID\n",
       "0         1            0\n",
       "1         1            0\n",
       "2         1            0\n",
       "3         1            0\n",
       "4         5            0\n",
       "5         1            0\n",
       "6         1            0\n",
       "7         1            0\n",
       "8         1            0\n",
       "9         1            0\n",
       "10        3            0\n",
       "11        1            0\n",
       "12        5            0\n",
       "13        1            0\n",
       "14        5            1"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[\"Emotion\"] = y_train[\"Emotion\"].apply(lambda x: encode_labels(label_encoder, x))\n",
    "y_train[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4e2fce5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## tokenize all sentences ##\n",
    "file = open('data/dump/tokenizer.pkl', 'rb')\n",
    "\n",
    "if file is None:\n",
    "    all_text = list(X_train.Utterance)\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(all_text)\n",
    "    pickle.dump(tokenizer, open('data/dump/tokenizer.pkl', 'wb'))\n",
    "else:\n",
    "    tokenizer = pickle.load(file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "74c1817d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert the sentences into sequences ##\n",
    "train_sequence = tokenizer.texts_to_sequences(list(X_train.Utterance))\n",
    "X_train['sentence_length'] = [len(item) for item in train_sequence]\n",
    "\n",
    "max_num_tokens = 250\n",
    "\n",
    "train_sequence = pad_sequences(train_sequence, maxlen=max_num_tokens, padding='post')\n",
    "\n",
    "X_train['sequence'] = list(train_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ab702389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('also', 26),\n",
       "             ('i', 5701),\n",
       "             ('was', 616),\n",
       "             ('the', 2463),\n",
       "             ('point', 9),\n",
       "             ('person', 27),\n",
       "             ('on', 668),\n",
       "             ('my', 861),\n",
       "             ('company', 8),\n",
       "             ('s', 2444),\n",
       "             ('transition', 1),\n",
       "             ('from', 142),\n",
       "             ('kl', 1),\n",
       "             ('5', 6),\n",
       "             ('to', 2121),\n",
       "             ('gr', 1),\n",
       "             ('6', 10),\n",
       "             ('system', 10),\n",
       "             ('you', 4441),\n",
       "             ('must', 30),\n",
       "             ('ve', 267),\n",
       "             ('had', 176),\n",
       "             ('your', 489),\n",
       "             ('hands', 13),\n",
       "             ('full', 10),\n",
       "             ('that', 1856),\n",
       "             ('did', 262),\n",
       "             ('so', 869),\n",
       "             ('let', 224),\n",
       "             ('talk', 85),\n",
       "             ('a', 2067),\n",
       "             ('little', 198),\n",
       "             ('bit', 24),\n",
       "             ('about', 428),\n",
       "             ('duties', 3),\n",
       "             ('all', 659),\n",
       "             ('right', 603),\n",
       "             ('now', 370),\n",
       "             ('ll', 367),\n",
       "             ('be', 608),\n",
       "             ('heading', 5),\n",
       "             ('whole', 46),\n",
       "             ('division', 11),\n",
       "             ('have', 797),\n",
       "             ('lot', 78),\n",
       "             ('of', 906),\n",
       "             ('see', 317),\n",
       "             ('but', 587),\n",
       "             ('there', 482),\n",
       "             ('perhaps', 4),\n",
       "             ('30', 12),\n",
       "             ('people', 140),\n",
       "             ('under', 26),\n",
       "             ('can', 696),\n",
       "             ('dump', 7),\n",
       "             ('certain', 3),\n",
       "             ('amount', 1),\n",
       "             ('them', 147),\n",
       "             ('good', 265),\n",
       "             ('know', 1105),\n",
       "             ('we', 1102),\n",
       "             ('go', 498),\n",
       "             ('into', 68),\n",
       "             ('detail', 1),\n",
       "             ('no', 1143),\n",
       "             ('don', 721),\n",
       "             ('t', 1575),\n",
       "             ('beg', 2),\n",
       "             ('then', 204),\n",
       "             ('definite', 1),\n",
       "             ('answer', 12),\n",
       "             ('for', 622),\n",
       "             ('monday', 6),\n",
       "             ('think', 379),\n",
       "             ('say', 179),\n",
       "             ('with', 607),\n",
       "             ('some', 201),\n",
       "             ('confidence', 1),\n",
       "             ('fit', 6),\n",
       "             ('in', 811),\n",
       "             ('well', 674),\n",
       "             ('here', 494),\n",
       "             ('really', 436),\n",
       "             ('absolutely', 25),\n",
       "             ('relax', 24),\n",
       "             ('who', 214),\n",
       "             ('waitress', 3),\n",
       "             ('went', 80),\n",
       "             ('out', 494),\n",
       "             ('last', 84),\n",
       "             ('month', 10),\n",
       "             ('forget', 26),\n",
       "             ('it', 2170),\n",
       "             ('were', 188),\n",
       "             ('talking', 54),\n",
       "             ('actually', 101),\n",
       "             ('ok', 150),\n",
       "             ('yeah', 842),\n",
       "             ('sure', 114),\n",
       "             ('hey', 703),\n",
       "             ('mon', 25),\n",
       "             ('wanna', 156),\n",
       "             ('hear', 51),\n",
       "             ('something', 162),\n",
       "             ('sucks', 12),\n",
       "             ('do', 690),\n",
       "             ('ever', 78),\n",
       "             ('chris', 1),\n",
       "             ('says', 30),\n",
       "             ('they', 370),\n",
       "             ('re', 732),\n",
       "             ('closing', 5),\n",
       "             ('down', 123),\n",
       "             ('bar', 8),\n",
       "             ('way', 119),\n",
       "             ('apparently', 13),\n",
       "             ('turning', 1),\n",
       "             ('kinda', 56),\n",
       "             ('coffee', 35),\n",
       "             ('place', 73),\n",
       "             ('just', 849),\n",
       "             ('where', 142),\n",
       "             ('are', 601),\n",
       "             ('gonna', 476),\n",
       "             ('hang', 24),\n",
       "             ('got', 324),\n",
       "             ('me', 1011),\n",
       "             ('get', 501),\n",
       "             ('beer', 4),\n",
       "             ('pick', 59),\n",
       "             ('roommate', 14),\n",
       "             ('betcha', 1),\n",
       "             ('is', 963),\n",
       "             ('italian', 11),\n",
       "             ('guy', 168),\n",
       "             ('um', 102),\n",
       "             ('mm', 9),\n",
       "             ('oh', 1438),\n",
       "             ('god', 267),\n",
       "             ('poor', 8),\n",
       "             ('monica', 173),\n",
       "             ('what', 1225),\n",
       "             ('he', 634),\n",
       "             ('her', 377),\n",
       "             ('when', 256),\n",
       "             ('wrote', 11),\n",
       "             ('this', 988),\n",
       "             ('poem', 4),\n",
       "             ('look', 363),\n",
       "             ('vessel', 2),\n",
       "             ('empty', 12),\n",
       "             ('nothing', 75),\n",
       "             ('inside', 11),\n",
       "             ('touched', 5),\n",
       "             ('seem', 16),\n",
       "             ('emptier', 2),\n",
       "             ('still', 123),\n",
       "             ('thinks', 21),\n",
       "             ('she', 463),\n",
       "             ('vase', 6),\n",
       "             ('totally', 56),\n",
       "             ('seemed', 4),\n",
       "             ('happy', 53),\n",
       "             ('too', 174),\n",
       "             ('done', 45),\n",
       "             ('hi', 208),\n",
       "             ('doing', 128),\n",
       "             ('ah', 116),\n",
       "             ('y', 464),\n",
       "             ('building', 11),\n",
       "             ('paper', 8),\n",
       "             ('route', 10),\n",
       "             ('how', 380),\n",
       "             ('d', 169),\n",
       "             ('woman', 55),\n",
       "             ('interviewed', 1),\n",
       "             ('pretty', 77),\n",
       "             ('tough', 8),\n",
       "             ('thank', 147),\n",
       "             ('mark', 13),\n",
       "             ('coached', 1),\n",
       "             ('because', 182),\n",
       "             ('once', 25),\n",
       "             ('started', 23),\n",
       "             ('fall', 6),\n",
       "             ('line', 14),\n",
       "             ('and', 1766),\n",
       "             ('wouldn', 52),\n",
       "             ('shut', 13),\n",
       "             ('up', 403),\n",
       "             ('m', 1065),\n",
       "             ('proud', 8),\n",
       "             ('listen', 112),\n",
       "             ('sorry', 238),\n",
       "             ('been', 182),\n",
       "             ('crazy', 40),\n",
       "             ('jealous', 9),\n",
       "             ('like', 538),\n",
       "             ('ameri', 4),\n",
       "             ('ccan', 1),\n",
       "             ('everybody', 37),\n",
       "             ('job', 46),\n",
       "             ('joe', 27),\n",
       "             ('top', 12),\n",
       "             ('notch', 3),\n",
       "             ('liked', 17),\n",
       "             ('ho', 35),\n",
       "             ('which', 51),\n",
       "             ('part', 34),\n",
       "             ('exactly', 19),\n",
       "             ('thing', 129),\n",
       "             ('give', 115),\n",
       "             ('specifics', 3),\n",
       "             ('love', 172),\n",
       "             ('best', 53),\n",
       "             ('scene', 10),\n",
       "             ('kangaroo', 3),\n",
       "             ('surprised', 9),\n",
       "             ('world', 30),\n",
       "             ('war', 2),\n",
       "             ('epic', 2),\n",
       "             ('fell', 13),\n",
       "             ('asleep', 15),\n",
       "             ('didn', 166),\n",
       "             ('take', 120),\n",
       "             ('any', 85),\n",
       "             ('suggestions', 2),\n",
       "             ('coming', 40),\n",
       "             ('buddy', 17),\n",
       "             ('later', 44),\n",
       "             ('mad', 24),\n",
       "             ('at', 354),\n",
       "             ('him', 271),\n",
       "             ('or', 152),\n",
       "             ('call', 95),\n",
       "             ('an', 143),\n",
       "             ('ambulance', 1),\n",
       "             ('okay', 870),\n",
       "             ('tell', 248),\n",
       "             ('rachel', 165),\n",
       "             ('messed', 2),\n",
       "             ('dessert', 2),\n",
       "             ('thanksgiving', 22),\n",
       "             ('not', 614),\n",
       "             ('truth', 7),\n",
       "             ('day', 57),\n",
       "             ('yes', 191),\n",
       "             ('dying', 4),\n",
       "             ('wish', 27),\n",
       "             ('ring', 41),\n",
       "             ('if', 353),\n",
       "             ('buried', 6),\n",
       "             ('spirit', 2),\n",
       "             ('going', 205),\n",
       "             ('wander', 1),\n",
       "             ('nether', 1),\n",
       "             ('eternity', 1),\n",
       "             ('enough', 42),\n",
       "             ('honey', 68),\n",
       "             ('great', 221),\n",
       "             ('usual', 1),\n",
       "             ('teaching', 5),\n",
       "             ('aerobics', 1),\n",
       "             ('partying', 3),\n",
       "             ('much', 114),\n",
       "             ('case', 9),\n",
       "             ('wondering', 8),\n",
       "             ('those', 86),\n",
       "             ('legs', 4),\n",
       "             ('new', 69),\n",
       "             ('james', 5),\n",
       "             ('bond', 7),\n",
       "             ('poster', 1),\n",
       "             ('hold', 43),\n",
       "             ('moment', 17),\n",
       "             ('another', 51),\n",
       "             ('back', 200),\n",
       "             ('together', 56),\n",
       "             ('uh', 415),\n",
       "             ('bout', 2),\n",
       "             ('tomorrow', 51),\n",
       "             ('afternoon', 5),\n",
       "             ('central', 10),\n",
       "             ('perk', 1),\n",
       "             ('village', 1),\n",
       "             ('five', 45),\n",
       "             ('ish', 1),\n",
       "             ('having', 71),\n",
       "             ('phone', 56),\n",
       "             ('has', 95),\n",
       "             ('finally', 11),\n",
       "             ('paid', 9),\n",
       "             ('off', 111),\n",
       "             ('even', 102),\n",
       "             ('though', 31),\n",
       "             ('bob', 20),\n",
       "             ('impression', 5),\n",
       "             ('thinkin', 4),\n",
       "             ('sees', 2),\n",
       "             ('tomorow', 1),\n",
       "             ('probably', 39),\n",
       "             ('realize', 18),\n",
       "             ('hoping', 5),\n",
       "             ('doesn', 85),\n",
       "             ('show', 32),\n",
       "             ('will', 136),\n",
       "             ('seek', 1),\n",
       "             ('comfort', 1),\n",
       "             ('open', 27),\n",
       "             ('arms', 5),\n",
       "             ('wry', 1),\n",
       "             ('stranger', 3),\n",
       "             ('next', 57),\n",
       "             ('table', 25),\n",
       "             ('pure', 3),\n",
       "             ('evil', 7),\n",
       "             ('horny', 7),\n",
       "             ('alone', 26),\n",
       "             ('nobody', 15),\n",
       "             ('respects', 1),\n",
       "             ('bucket', 5),\n",
       "             ('believe', 96),\n",
       "             ('put', 86),\n",
       "             ('does', 111),\n",
       "             ('garbage', 4),\n",
       "             ('wedding', 60),\n",
       "             ('late', 27),\n",
       "             ('fine', 110),\n",
       "             ('watch', 29),\n",
       "             ('video', 4),\n",
       "             ('phoebe', 152),\n",
       "             ('phobo', 2),\n",
       "             ('phewbedo', 2),\n",
       "             ('phaybobo', 2),\n",
       "             ('bye', 76),\n",
       "             ('pheebs', 108),\n",
       "             ('london', 9),\n",
       "             ('baby', 81),\n",
       "             ('need', 106),\n",
       "             ('hug', 2),\n",
       "             ('bring', 32),\n",
       "             ('anything', 80),\n",
       "             ('estelle', 4),\n",
       "             ('lined', 2),\n",
       "             ('bunch', 6),\n",
       "             ('auditions', 1),\n",
       "             ('health', 9),\n",
       "             ('insurance', 4),\n",
       "             ('time', 204),\n",
       "             ('shouldn', 18),\n",
       "             ('toilet', 5),\n",
       "             ('wrong', 45),\n",
       "             ('blinding', 1),\n",
       "             ('pain', 8),\n",
       "             ('stomach', 4),\n",
       "             ('lifting', 1),\n",
       "             ('weights', 1),\n",
       "             ('before', 94),\n",
       "             ('passed', 1),\n",
       "             ('haven', 34),\n",
       "             ('able', 20),\n",
       "             ('stand', 15),\n",
       "             ('since', 28),\n",
       "             ('serious', 28),\n",
       "             ('sounds', 21),\n",
       "             ('hernia', 2),\n",
       "             ('doctor', 26),\n",
       "             ('åekay', 7),\n",
       "             ('sticking', 1),\n",
       "             ('why', 262),\n",
       "             ('start', 30),\n",
       "             ('working', 24),\n",
       "             ('again', 111),\n",
       "             ('damn', 9),\n",
       "             ('15s', 1),\n",
       "             ('eighteenth', 1),\n",
       "             ('century', 4),\n",
       "             ('indian', 2),\n",
       "             ('artifact', 1),\n",
       "             ('calcutta', 1),\n",
       "             ('wow', 105),\n",
       "             ('more', 90),\n",
       "             ('than', 46),\n",
       "             ('dinosaurs', 3),\n",
       "             ('sum', 2),\n",
       "             ('fun', 63),\n",
       "             ('young', 5),\n",
       "             ('soåc', 9),\n",
       "             ('soåchere', 1),\n",
       "             ('key', 8),\n",
       "             ('apartment', 34),\n",
       "             ('fast', 11),\n",
       "             ('ross', 289),\n",
       "             ('minute', 37),\n",
       "             ('please', 133),\n",
       "             ('joey', 243),\n",
       "             ('broke', 26),\n",
       "             ('wh', 21),\n",
       "             ('happened', 64),\n",
       "             ('different', 20),\n",
       "             ('mean', 327),\n",
       "             ('during', 4),\n",
       "             ('speech', 11),\n",
       "             ('kept', 10),\n",
       "             ('laughing', 2),\n",
       "             ('homo', 1),\n",
       "             ('erectus', 1),\n",
       "             ('knew', 31),\n",
       "             ('anyway', 49),\n",
       "             ('guess', 64),\n",
       "             ('hum', 3),\n",
       "             ('reason', 18),\n",
       "             ('thought', 94),\n",
       "             ('end', 18),\n",
       "             ('feelings', 8),\n",
       "             ('someone', 44),\n",
       "             ('else', 51),\n",
       "             ('professor', 13),\n",
       "             ('clerk', 2),\n",
       "             ('kind', 61),\n",
       "             ('middle', 14),\n",
       "             ('conversation', 8),\n",
       "             ('guys', 260),\n",
       "             ('throw', 32),\n",
       "             ('pool', 6),\n",
       "             ('gentlemen', 9),\n",
       "             ('aren', 21),\n",
       "             ('old', 44),\n",
       "             ('scientists', 4),\n",
       "             ('academics', 3),\n",
       "             ('most', 32),\n",
       "             ('importantly', 4),\n",
       "             ('catch', 11),\n",
       "             ('us', 141),\n",
       "             ('first', 124),\n",
       "             ('geller', 26),\n",
       "             ('conference', 4),\n",
       "             ('happens', 14),\n",
       "             ('keynote', 2),\n",
       "             ('speaker', 2),\n",
       "             ('could', 198),\n",
       "             ('both', 31),\n",
       "             ('wants', 40),\n",
       "             ('hat', 6),\n",
       "             ('oy', 4),\n",
       "             ('sand', 1),\n",
       "             ('said', 125),\n",
       "             ('might', 51),\n",
       "             ('flood', 2),\n",
       "             ('damage', 3),\n",
       "             ('either', 32),\n",
       "             ('big', 97),\n",
       "             ('cat', 12),\n",
       "             ('blind', 5),\n",
       "             ('bash', 1),\n",
       "             ('his', 138),\n",
       "             ('head', 32),\n",
       "             ('umm', 180),\n",
       "             ('lima', 2),\n",
       "             ('bean', 2),\n",
       "             ('bubbling', 2),\n",
       "             ('would', 216),\n",
       "             ('understand', 25),\n",
       "             ('difference', 12),\n",
       "             ('rach', 72),\n",
       "             ('boy', 16),\n",
       "             ('scary', 5),\n",
       "             ('diaper', 2),\n",
       "             ('commercial', 3),\n",
       "             ('babies', 23),\n",
       "             ('responsibilities', 4),\n",
       "             ('ahhh', 4),\n",
       "             ('pizza', 10),\n",
       "             ('delivery', 5),\n",
       "             ('eat', 51),\n",
       "             ('long', 46),\n",
       "             ('ball', 17),\n",
       "             ('forth', 1),\n",
       "             ('huh', 137),\n",
       "             ('uhh', 13),\n",
       "             ('two', 112),\n",
       "             ('straight', 10),\n",
       "             ('hours', 37),\n",
       "             ('without', 32),\n",
       "             ('dropping', 2),\n",
       "             ('pee', 2),\n",
       "             ('bathroom', 15),\n",
       "             ('man', 119),\n",
       "             ('make', 129),\n",
       "             ('switch', 10),\n",
       "             ('erin', 1),\n",
       "             ('unbelievable', 30),\n",
       "             ('better', 62),\n",
       "             ('awkward', 4),\n",
       "             ('nervous', 12),\n",
       "             ('calms', 2),\n",
       "             ('common', 3),\n",
       "             ('loves', 11),\n",
       "             ('sandwiches', 5),\n",
       "             ('sports', 8),\n",
       "             ('although', 11),\n",
       "             ('met', 14),\n",
       "             ('fan', 9),\n",
       "             ('issue', 7),\n",
       "             ('kids', 29),\n",
       "             ('talkin', 4),\n",
       "             ('married', 70),\n",
       "             ('yay', 14),\n",
       "             ('anymore', 28),\n",
       "             ('sleep', 28),\n",
       "             ('cannot', 26),\n",
       "             ('public', 5),\n",
       "             ('peaceful', 2),\n",
       "             ('nodded', 2),\n",
       "             ('night', 91),\n",
       "             ('grandmother', 26),\n",
       "             ('boyfriend', 14),\n",
       "             ('insecure', 2),\n",
       "             ('bed', 28),\n",
       "             ('deaf', 2),\n",
       "             ('constantly', 2),\n",
       "             ('reassure', 2),\n",
       "             ('each', 34),\n",
       "             ('other', 88),\n",
       "             ('idea', 42),\n",
       "             ('loud', 6),\n",
       "             ('want', 260),\n",
       "             ('stay', 48),\n",
       "             ('tonight', 48),\n",
       "             ('thanks', 94),\n",
       "             ('ew', 12),\n",
       "             ('exploded', 3),\n",
       "             ('water', 11),\n",
       "             ('breaking', 8),\n",
       "             ('calm', 8),\n",
       "             ('breathe', 5),\n",
       "             ('insane', 7),\n",
       "             ('kill', 23),\n",
       "             ('dead', 17),\n",
       "             ('dina', 3),\n",
       "             ('one', 371),\n",
       "             ('dwha', 1),\n",
       "             ('gina', 4),\n",
       "             ('dark', 8),\n",
       "             ('hair', 12),\n",
       "             ('airplane', 2),\n",
       "             ('earrings', 6),\n",
       "             ('åesee', 1),\n",
       "             ('saturday', 6),\n",
       "             ('funny', 53),\n",
       "             ('fashion', 9),\n",
       "             ('friend', 65),\n",
       "             ('share', 6),\n",
       "             ('stuff', 91),\n",
       "             ('never', 133),\n",
       "             ('lecture', 3),\n",
       "             ('pa', 1),\n",
       "             ('haa', 1),\n",
       "             ('clothes', 19),\n",
       "             ('monger', 1),\n",
       "             ('should', 161),\n",
       "             ('wear', 28),\n",
       "             ('incredible', 7),\n",
       "             ('amazing', 30),\n",
       "             ('nailed', 1),\n",
       "             ('beautiful', 27),\n",
       "             ('tribbiani', 11),\n",
       "             ('gotta', 93),\n",
       "             ('bus', 4),\n",
       "             ('luck', 12),\n",
       "             ('unless', 5),\n",
       "             ('practice', 6),\n",
       "             ('foxtrot', 1),\n",
       "             ('tango', 1),\n",
       "             ('ahh', 26),\n",
       "             ('ready', 44),\n",
       "             ('dance', 15),\n",
       "             ('girls', 20),\n",
       "             ('åeem', 20),\n",
       "             ('treeger', 5),\n",
       "             ('come', 304),\n",
       "             ('marge', 1),\n",
       "             ('girlfriend', 17),\n",
       "             ('real', 37),\n",
       "             ('same', 29),\n",
       "             ('size', 6),\n",
       "             ('as', 159),\n",
       "             ('nerve', 4),\n",
       "             ('wracking', 1),\n",
       "             ('unfortunately', 4),\n",
       "             ('many', 18),\n",
       "             ('callbacks', 2),\n",
       "             ('play', 66),\n",
       "             ('ben', 50),\n",
       "             ('dad', 38),\n",
       "             ('weird', 40),\n",
       "             ('friends', 58),\n",
       "             ('sign', 5),\n",
       "             ('asked', 31),\n",
       "             ('around', 76),\n",
       "             ('after', 46),\n",
       "             ('audition', 13),\n",
       "             ('knows', 48),\n",
       "             ('narrowed', 4),\n",
       "             ('raymond', 5),\n",
       "             ('kyle', 5),\n",
       "             ('rest', 20),\n",
       "             ('very', 107),\n",
       "             ('happen', 41),\n",
       "             ('such', 45),\n",
       "             ('looks', 36),\n",
       "             ('putting', 7),\n",
       "             ('until', 25),\n",
       "             ('borrowed', 3),\n",
       "             ('blue', 21),\n",
       "             ('kidding', 26),\n",
       "             ('hurt', 22),\n",
       "             ('three', 39),\n",
       "             ('huge', 15),\n",
       "             ('men', 15),\n",
       "             ('gave', 18),\n",
       "             ('bloody', 4),\n",
       "             ('nose', 3),\n",
       "             ('am', 149),\n",
       "             ('wonderful', 6),\n",
       "             ('concussion', 1),\n",
       "             ('welcome', 12),\n",
       "             ('worth', 8),\n",
       "             ('mike', 7),\n",
       "             ('interesting', 12),\n",
       "             ('david', 17),\n",
       "             ('hint', 2),\n",
       "             ('sensing', 1),\n",
       "             ('word', 18),\n",
       "             ('pink', 5),\n",
       "             ('barely', 5),\n",
       "             ('controlled', 1),\n",
       "             ('glee', 1),\n",
       "             ('propose', 4),\n",
       "             ('chandler', 181),\n",
       "             ('talked', 17),\n",
       "             ('supposed', 39),\n",
       "             ('advice', 3),\n",
       "             ('couldn', 43),\n",
       "             ('made', 68),\n",
       "             ('sort', 5),\n",
       "             ('inappropriate', 8),\n",
       "             ('joke', 5),\n",
       "             ('only', 99),\n",
       "             ('few', 18),\n",
       "             ('weeks', 16),\n",
       "             ('completely', 10),\n",
       "             ('hung', 5),\n",
       "             ('heart', 17),\n",
       "             ('broken', 9),\n",
       "             ('hard', 37),\n",
       "             ('recover', 1),\n",
       "             ('father', 38),\n",
       "             ('paul', 6),\n",
       "             ('stevens', 3),\n",
       "             ('meet', 33),\n",
       "             ('chance', 28),\n",
       "             ('change', 16),\n",
       "             ('mind', 30),\n",
       "             ('usually', 5),\n",
       "             ('prefer', 4),\n",
       "             ('elizabeth', 8),\n",
       "             ('boyfriends', 7),\n",
       "             ('address', 4),\n",
       "             ('mr', 30),\n",
       "             ('course', 39),\n",
       "             ('problem', 46),\n",
       "             ('eh', 19),\n",
       "             ('excuse', 37),\n",
       "             ('own', 26),\n",
       "             ('age', 7),\n",
       "             ('ummåc', 3),\n",
       "             ('daddy', 11),\n",
       "             ('tv', 7),\n",
       "             ('yet', 50),\n",
       "             ('wall', 3),\n",
       "             ('tape', 5),\n",
       "             ('matt', 1),\n",
       "             ('lauer', 1),\n",
       "             ('maybe', 127),\n",
       "             ('ones', 16),\n",
       "             ('cleaned', 1),\n",
       "             ('ooooohh', 1),\n",
       "             ('sudden', 10),\n",
       "             ('weren', 10),\n",
       "             ('scouts', 2),\n",
       "             ('camped', 2),\n",
       "             ('uma', 3),\n",
       "             ('thurman', 3),\n",
       "             ('ooo', 1),\n",
       "             ('actress', 4),\n",
       "             ('moral', 3),\n",
       "             ('obligation', 3),\n",
       "             ('feminist', 5),\n",
       "             ('hate', 29),\n",
       "             ('marry', 28),\n",
       "             ('wanted', 63),\n",
       "             ('pocket', 7),\n",
       "             ('surprise', 13),\n",
       "             ('oop', 1),\n",
       "             ('reallyåcvery', 1),\n",
       "             ('excited', 13),\n",
       "             ('charity', 4),\n",
       "             ('event', 1),\n",
       "             ('warm', 8),\n",
       "             ('taking', 15),\n",
       "             ('sweater', 11),\n",
       "             ('letting', 9),\n",
       "             ('yep', 21),\n",
       "             ('hilarious', 1),\n",
       "             ('embarrassing', 2),\n",
       "             ('seen', 33),\n",
       "             ('naked', 34),\n",
       "             ('hundreds', 1),\n",
       "             ('times', 36),\n",
       "             ('true', 24),\n",
       "             ('embarrass', 2),\n",
       "             ('easily', 2),\n",
       "             ('embarrassed', 5),\n",
       "             ('secure', 2),\n",
       "             ('lady', 16),\n",
       "             ('care', 61),\n",
       "             ('rode', 1),\n",
       "             ('bike', 8),\n",
       "             ('yourself', 27),\n",
       "             ('faced', 1),\n",
       "             ('fears', 1),\n",
       "             ('ultimately', 1),\n",
       "             ('overcame', 1),\n",
       "             ('myåc', 1),\n",
       "             ('lucky', 6),\n",
       "             ('total', 2),\n",
       "             ('wuss', 2),\n",
       "             ('check', 41),\n",
       "             ('over', 149),\n",
       "             ('options', 1),\n",
       "             ('number', 29),\n",
       "             ('prototypes', 1),\n",
       "             ('try', 50),\n",
       "             ('mushroom', 1),\n",
       "             ('cap', 1),\n",
       "             ('bologna', 1),\n",
       "             ('toothpicks', 1),\n",
       "             ('kissed', 9),\n",
       "             ('these', 95),\n",
       "             ('took', 32),\n",
       "             ('hotel', 8),\n",
       "             ('lobby', 3),\n",
       "             ('charge', 4),\n",
       "             ('dirty', 7),\n",
       "             ('movie', 25),\n",
       "             ('bag', 24),\n",
       "             ('mashuga', 2),\n",
       "             ('nuts', 11),\n",
       "             ('looking', 43),\n",
       "             ('wait', 152),\n",
       "             ('stole', 8),\n",
       "             ('vic', 2),\n",
       "             ('hell', 27),\n",
       "             ('figure', 18),\n",
       "             ('nothin', 9),\n",
       "             ('character', 8),\n",
       "             ('script', 7),\n",
       "             ('likes', 6),\n",
       "             ('bitch', 17),\n",
       "             ('mine', 32),\n",
       "             ('tasty', 2),\n",
       "             ('starting', 10),\n",
       "             ('feel', 86),\n",
       "             ('history', 9),\n",
       "             ('nice', 91),\n",
       "             ('peel', 6),\n",
       "             ('onion', 2),\n",
       "             ('question', 31),\n",
       "             ('adrienne', 1),\n",
       "             ('attracted', 5),\n",
       "             ('victor', 1),\n",
       "             ('girl', 74),\n",
       "             ('rookie', 2),\n",
       "             ('mistake', 11),\n",
       "             ('camera', 6),\n",
       "             ('ask', 54),\n",
       "             ('brought', 14),\n",
       "             ('their', 31),\n",
       "             ('souvenirs', 2),\n",
       "             ('greg', 2),\n",
       "             ('jenny', 2),\n",
       "             ('hello', 75),\n",
       "             ('deli', 3),\n",
       "             ('eighth', 2),\n",
       "             ('street', 17),\n",
       "             ('food', 22),\n",
       "             ('poisoning', 1),\n",
       "             ('sandwich', 6),\n",
       "             ('miss', 29),\n",
       "             ('getting', 62),\n",
       "             ('ma', 10),\n",
       "             ('appointment', 3),\n",
       "             ('dr', 35),\n",
       "             ('bazida', 1),\n",
       "             ('isn', 45),\n",
       "             ('name', 61),\n",
       "             ('ronni', 2),\n",
       "             ('pet', 3),\n",
       "             ('mortician', 1),\n",
       "             ('remember', 67),\n",
       "             ('kid', 25),\n",
       "             ('used', 20),\n",
       "             ('navy', 2),\n",
       "             ('yard', 1),\n",
       "             ('ships', 1),\n",
       "             ('six', 20),\n",
       "             ('years', 48),\n",
       "             ('memory', 2),\n",
       "             ('wasn', 46),\n",
       "             ('always', 65),\n",
       "             ('terrible', 12),\n",
       "             ('burning', 2),\n",
       "             ('tomatoes', 2),\n",
       "             ('worst', 8),\n",
       "             ('women', 37),\n",
       "             ('em', 13),\n",
       "             ('matter', 30),\n",
       "             ('everything', 42),\n",
       "             ('dick', 1),\n",
       "             ('guru', 1),\n",
       "             ('saj', 1),\n",
       "             ('whoa', 81),\n",
       "             ('duck', 9),\n",
       "             ('åecause', 44),\n",
       "             ('otherwise', 7),\n",
       "             ('waaay', 2),\n",
       "             ('league', 2),\n",
       "             ('work', 82),\n",
       "             ('sit', 26),\n",
       "             ('chair', 4),\n",
       "             ('by', 112),\n",
       "             ('dropped', 3),\n",
       "             ('box', 13),\n",
       "             ('shampoo', 1),\n",
       "             ('bringing', 3),\n",
       "             ('mesozoic', 1),\n",
       "             ('era', 2),\n",
       "             ('21st', 1),\n",
       "             ('dude', 28),\n",
       "             ('ridiculous', 7),\n",
       "             ('bad', 51),\n",
       "             ('bing', 33),\n",
       "             ('won', 68),\n",
       "             ('our', 116),\n",
       "             ('ace', 6),\n",
       "             ('high', 34),\n",
       "             ('jack', 6),\n",
       "             ('queen', 2),\n",
       "             ('king', 10),\n",
       "             ('low', 2),\n",
       "             ('four', 28),\n",
       "             ('ooh', 58),\n",
       "             ('ha', 34),\n",
       "             ('cut', 31),\n",
       "             ('asåc', 2),\n",
       "             ('worked', 10),\n",
       "             ('tickets', 16),\n",
       "             ('courtside', 2),\n",
       "             ('seriously', 15),\n",
       "             ('game', 42),\n",
       "             ('pack', 8),\n",
       "             ('anvil', 1),\n",
       "             ('known', 4),\n",
       "             ('fact', 16),\n",
       "             ('sensitive', 13),\n",
       "             ('quick', 11),\n",
       "             ('aim', 1),\n",
       "             ('o', 19),\n",
       "             ('babes', 1),\n",
       "             ('break', 31),\n",
       "             ('away', 48),\n",
       "             ('left', 51),\n",
       "             ('gimme', 15),\n",
       "             ('immodest', 1),\n",
       "             ('smell', 12),\n",
       "             ('whiff', 1),\n",
       "             ('technically', 9),\n",
       "             ('against', 13),\n",
       "             ('rules', 11),\n",
       "             ('frowned', 3),\n",
       "             ('upon', 3),\n",
       "             ('especially', 11),\n",
       "             ('ran', 13),\n",
       "             ('judgey', 3),\n",
       "             ('von', 5),\n",
       "             ('holierthanthou', 3),\n",
       "             ('careful', 11),\n",
       "             ('reputation', 1),\n",
       "             ('mcnailshisstudents', 1),\n",
       "             ('seems', 13),\n",
       "             ('clear', 12),\n",
       "             ('important', 21),\n",
       "             ('follow', 9),\n",
       "             ('sweet', 28),\n",
       "             ('whatever', 15),\n",
       "             ('dinner', 38),\n",
       "             ('dana', 4),\n",
       "             ('caplin', 2),\n",
       "             ('leave', 37),\n",
       "             ('block', 1),\n",
       "             ('thursday', 1),\n",
       "             ('keystone', 1),\n",
       "             ('college', 8),\n",
       "             ('morning', 45),\n",
       "             ('favorite', 11),\n",
       "             ('genius', 7),\n",
       "             ('robot', 10),\n",
       "             ('touch', 17),\n",
       "             ('wayne', 1),\n",
       "             ('level', 2),\n",
       "             ('keep', 39),\n",
       "             ('hearing', 5),\n",
       "             ('rumors', 1),\n",
       "             ('fired', 7),\n",
       "             ('actors', 5),\n",
       "             ('read', 24),\n",
       "             ('second', 57),\n",
       "             ('stupid', 48),\n",
       "             ('doin', 19),\n",
       "             ('earlier', 2),\n",
       "             ('stressed', 1),\n",
       "             ('apologise', 3),\n",
       "             ('office', 13),\n",
       "             ('wanting', 4),\n",
       "             ('anniversary', 2),\n",
       "             ('ass', 18),\n",
       "             ('told', 65),\n",
       "             ('quit', 14),\n",
       "             ('easier', 8),\n",
       "             ('perfect', 18),\n",
       "             ('promised', 3),\n",
       "             ('swore', 1),\n",
       "             ('gods', 1),\n",
       "             ('sock', 1),\n",
       "             ('keeps', 13),\n",
       "             ('richard', 16),\n",
       "             ('complement', 2),\n",
       "             ('chef', 12),\n",
       "             ('ohhåc', 2),\n",
       "             ('seeing', 16),\n",
       "             ('came', 41),\n",
       "             ('pregnant', 19),\n",
       "             ('forcing', 1),\n",
       "             ('bobby', 7),\n",
       "             ('wellåcso', 2),\n",
       "             ('music', 6),\n",
       "             ('numb', 2),\n",
       "             ('scared', 18),\n",
       "             ('death', 6),\n",
       "             ('help', 60),\n",
       "             ('åecauseåc', 1),\n",
       "             ('sister', 28),\n",
       "             ('brother', 22),\n",
       "             ('mom', 47),\n",
       "             ('telling', 36),\n",
       "             ('uncle', 13),\n",
       "             ('loved', 18),\n",
       "             ('bet', 18),\n",
       "             ('gangster', 1),\n",
       "             ('rap', 1),\n",
       "             ('glad', 26),\n",
       "             ('visiting', 1),\n",
       "             ('couch', 6),\n",
       "             ('ohhh', 13),\n",
       "             ('saw', 25),\n",
       "             ('krista', 2),\n",
       "             ('meeting', 4),\n",
       "             ('fix', 7),\n",
       "             ('myself', 43),\n",
       "             ('victoria', 1),\n",
       "             ('secret', 9),\n",
       "             ('model', 1),\n",
       "             ('goodacre', 3),\n",
       "             ('jill', 10),\n",
       "             ('trapped', 1),\n",
       "             ('atm', 2),\n",
       "             ('vestibule', 4),\n",
       "             ('stuck', 10),\n",
       "             ('bank', 5),\n",
       "             ('personal', 8),\n",
       "             ('shopping', 8),\n",
       "             ('walk', 25),\n",
       "             ('snooty', 1),\n",
       "             ('rich', 4),\n",
       "             ('buy', 19),\n",
       "             ('switched', 2),\n",
       "             ('apartments', 3),\n",
       "             ('gravy', 2),\n",
       "             ('train', 7),\n",
       "             ...])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(tokenizer.word_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53ba917",
   "metadata": {},
   "source": [
    "<b>Idk why glove embeddings and toknizers were used in the orig source code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "db001f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save the data in pickle format ##\n",
    "file = open('data/dump/per_dialog_ids.pkl', \"rb\")\n",
    "if file is None:\n",
    "    dialogSpeakers, dialogInputSeq, dialogInputMaxSeqLen, dialogLabels = {}, {}, {}, {}\n",
    "    X_train_dialog_ids = set(X_train.Dialogue_ID)\n",
    "    all_data = X_train.copy()\n",
    "    # all_data = X_train.append(X_test, ignore_index=True).append(X_valid, ignore_index=True)\n",
    "\n",
    "    for item in list(X_train_dialog_ids):\n",
    "        X_df = all_data[all_data.Dialogue_ID == item]\n",
    "        y_df = y_train[y_train.Dialogue_ID == item]\n",
    "\n",
    "        dialogSpeakers[item] = list(X_df.Speaker)\n",
    "        dialogInputSeq[item] = list(X_df.sequence)\n",
    "        dialogInputMaxSeqLen[item] = max(list(X_df.sentence_length))\n",
    "        dialogLabels[item] = list(y_df.Emotion)\n",
    "\n",
    "    pickle.dump([dialogSpeakers, dialogInputSeq, dialogInputMaxSeqLen, dialogLabels, X_train_dialog_ids], \n",
    "                open('data/dump/per_dialog_ids.pkl', 'wb'))\n",
    "else:\n",
    "    dialogSpeakers, dialogInputSeq, dialogInputMaxSeqLen, dialogLabels, X_train_dialog_ids = pickle.load(file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c2d1f587",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save pretrained embedding matrix ##\n",
    "file = open('data/dump/glv_embedding_matrix.npy', \"rb\")\n",
    "if file is None:\n",
    "    glv_vector = load_pretrained_glove()\n",
    "    word_vector_length = len(glv_vector['the'])#dim=300\n",
    "    word_index = tokenizer.word_index\n",
    "    inv_word_index = {v: k for k, v in word_index.items()}\n",
    "    num_unique_words = len(word_index)\n",
    "    glv_embedding_matrix = np.zeros((num_unique_words + 1, word_vector_length))\n",
    "\n",
    "    for j in range(1, num_unique_words + 1):\n",
    "        glv_embedding_matrix[j] = glv_vector.get(inv_word_index[j], np.random.randn(word_vector_length) / 200)\n",
    "\n",
    "    np.save('data/dump/glv_embedding_matrix.npy', glv_embedding_matrix)\n",
    "    print('Done. Completed preprocessing.')\n",
    "else:\n",
    "    glv_embedding_matrix = np.load('data/dump/glv_embedding_matrix.npy', allow_pickle=True)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9141d9f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5409, 300)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size, embedding_dim = glv_embedding_matrix.shape\n",
    "vocab_size, embedding_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa935a92",
   "metadata": {},
   "source": [
    "No need for Word2Vec, I don't know why it was written in the ref source code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e2390f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectors = Vectors(name=\"wiki-news-300d-1M.vec\", cache=\"data/\", unk_init=['<pad>', '<unk>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1dcec5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectors.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "bef4892c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab = Vocab(ordered_dict=tokenizer.word_counts, specials=['<pad>', '<unk>'], min_freq=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "66952bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab.set_default_index(vocab['<unk>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ababe064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab['hi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e99a70fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = Vectors(name=\"wiki-news-300d-1M.vec\", url=\"data/\", cache=\"data/\")\n",
    "vectors.cache(name=\"data/wiki-news-300d-1M.vec\", url=\"data/\", cache=\"data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8f370ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = os.path.join(os.getcwd(), \"data/wiki-news-300d-1M.vec\")\n",
    "# if os.path.isfile(file_path):\n",
    "#     print(f\"The file exists in the current directory.\")\n",
    "# else:\n",
    "#     print(f\"The file does not exist in the current directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7526420e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([999994, 300])\n"
     ]
    }
   ],
   "source": [
    "print(vectors.vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "02f2db07",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Vocab(counter=collections.Counter(_read_words(X_train.Utterance)), \n",
    "              vectors=vectors,\n",
    "              specials=['<pad>', '<unk>'], \n",
    "              min_freq=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135bea50",
   "metadata": {},
   "source": [
    "Main func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b204cb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ebd = WORDEBD(vocab, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f97126a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WORDEBD(\n",
       "  (embedding_layer): Embedding(40, 300)\n",
       ")"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ebd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d67c3f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Munch({\n",
    "    \"cnn_filter_sizes\":[3,4,5],\n",
    "    \"cnn_num_filters\":100,\n",
    "    \"cuda\":-1,\n",
    "    \"mode\":\"train\",\n",
    "    \"snapshot\":'',\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d1300a",
   "metadata": {},
   "source": [
    "Creating an embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "68a3d350",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNNLSTMseq(ebd, args) # ProtoSeq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b26573c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/01/18 16:34:39, Building embedding\n"
     ]
    }
   ],
   "source": [
    "print(\"{}, Building embedding\".format(\n",
    "    datetime.datetime.now().strftime('%y/%m/%d %H:%M:%S')), flush=True)\n",
    "\n",
    "if args.snapshot != '':\n",
    "    if args.multitask:\n",
    "\n",
    "        print(\"{}, Loading pretrained embedding from {}\".format(\n",
    "            datetime.datetime.now().strftime('%y/%m/%d %H:%M:%S'),\n",
    "            '%s_%s.ebd' % (args.snapshot, args.task)\n",
    "            ))\n",
    "        model.load_state_dict(  torch.load( '%s_%s.ebd' % (args.snapshot, args.task) ), strict=False  )\n",
    "\n",
    "    else:    \n",
    "        # load pretrained models\n",
    "        print(\"{}, Loading pretrained embedding from {}\".format(\n",
    "            datetime.datetime.now().strftime('%y/%m/%d %H:%M:%S'),\n",
    "            '{}.ebd'.format(args.snapshot)\n",
    "            ))\n",
    "        model.load_state_dict(  torch.load( '{}.ebd'.format(args.snapshot) ), strict=False  )\n",
    "\n",
    "# if args.cuda != -1: \n",
    "#     model.cuda(args.cuda)\n",
    "# else: \n",
    "#     model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d1df7d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNLSTMseq(\n",
       "  (ebd): WORDEBD(\n",
       "    (embedding_layer): Embedding(40, 300)\n",
       "  )\n",
       "  (convs): ModuleList(\n",
       "    (0): Conv1d(300, 100, kernel_size=(3,), stride=(1,))\n",
       "    (1): Conv1d(300, 100, kernel_size=(4,), stride=(1,))\n",
       "    (2): Conv1d(300, 100, kernel_size=(5,), stride=(1,))\n",
       "  )\n",
       "  (lstm): LSTM(300, 150, bidirectional=True)\n",
       ")"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1997965f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b64bd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(model.train())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
