{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c64aa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import torch.nn.init as init\n",
    "import dgl\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Parameter\n",
    "from collections import Counter\n",
    "import dgl.function as fn\n",
    "from dgl.nn.functional import edge_softmax\n",
    "import pandas as pd\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f920f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "key=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8aa9fe91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATLayerWithEdgeType(nn.Module):\n",
    "    def __init__(self, num_in_features_per_head, num_out_features_per_head, num_heads, num_edge_types):\n",
    "        super(GATLayerWithEdgeType, self).__init__()\n",
    "        self.num_in_features_per_head = num_in_features_per_head\n",
    "        self.num_out_features_per_head = num_out_features_per_head\n",
    "        self.num_heads = num_heads\n",
    "        self.num_edge_types = num_edge_types\n",
    "\n",
    "        # Linear projection for node features\n",
    "        torch.manual_seed(42)\n",
    "        self.linear_proj = nn.Linear(self.num_in_features_per_head, self.num_heads * self.num_out_features_per_head)\n",
    "        \n",
    "        # Edge type embeddings\n",
    "        torch.manual_seed(42)\n",
    "        self.edge_type_embedding = nn.Embedding(self.num_edge_types, self.num_heads)\n",
    "        \n",
    "    def forward(self, input_data, edge_type):\n",
    "        node_features, edge_indices = input_data\n",
    "\n",
    "        # Linear projection for node features\n",
    "        h_linear = self.linear_proj(node_features.view(-1, self.num_in_features_per_head))\n",
    "        h_linear = h_linear.view(-1, self.num_heads, self.num_out_features_per_head)\n",
    "        h_linear = h_linear.permute(0, 2, 1)\n",
    "\n",
    "        # Edge type embedding\n",
    "        edge_type_embedding = self.edge_type_embedding(edge_type).transpose(0, 1)\n",
    "\n",
    "        # Perform matrix multiplication\n",
    "        attention_scores = torch.matmul(h_linear, edge_type_embedding).squeeze(-1)\n",
    "\n",
    "        # Softmax to get attention coefficients\n",
    "        attention_coefficients = F.softmax(attention_scores, dim=-1)\n",
    "\n",
    "        # Weighted sum of neighbor node representations\n",
    "        updated_representation = torch.matmul(attention_coefficients.transpose(1, 2), h_linear).mean(dim=2)\n",
    "\n",
    "        return updated_representation, attention_coefficients\n",
    "    \n",
    "class GATWithEdgeType(nn.Module):\n",
    "    def __init__(self, num_of_layers, num_heads_per_layer, num_features_per_layer, num_edge_types):\n",
    "        super(GATWithEdgeType, self).__init__()\n",
    "\n",
    "        self.gat_net = nn.ModuleList()\n",
    "\n",
    "        for layer in range(num_of_layers):\n",
    "            num_in_features = num_heads_per_layer[layer - 1] * num_features_per_layer[layer - 1] if layer > 0 else num_features_per_layer[0]\n",
    "            num_out_features = num_heads_per_layer[layer] * num_features_per_layer[layer]\n",
    "            self.gat_net.append(GATLayerWithEdgeType(num_in_features, num_out_features, num_heads_per_layer[layer], num_edge_types))\n",
    "\n",
    "    def forward(self, node_features, edge_indices, edge_types):\n",
    "        h = node_features\n",
    "\n",
    "        attention_scores = []\n",
    "\n",
    "        for layer in self.gat_net:\n",
    "            h, attention_coefficients = layer((h, edge_indices), edge_types)\n",
    "            attention_scores.append(attention_coefficients)\n",
    "\n",
    "        return h, attention_scores\n",
    "\n",
    "class EGATConv(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_node_feats,\n",
    "                 in_edge_feats,\n",
    "                 out_node_feats,\n",
    "                 out_edge_feats,\n",
    "                 num_heads,\n",
    "                 bias=True,\n",
    "                 **kw_args):\n",
    "\n",
    "        super().__init__()\n",
    "        self._num_heads = num_heads\n",
    "        self._out_node_feats = out_node_feats\n",
    "        self._out_edge_feats = out_edge_feats\n",
    "        \n",
    "        self.fc_node = nn.Linear(in_node_feats, out_node_feats * num_heads, bias=bias)\n",
    "        self.fc_ni = nn.Linear(in_node_feats, out_edge_feats * num_heads, bias=False)\n",
    "        self.fc_fij = nn.Linear(in_edge_feats, out_edge_feats * num_heads, bias=False)\n",
    "        self.fc_nj = nn.Linear(in_node_feats, out_edge_feats * num_heads, bias=False)\n",
    "        \n",
    "        # Attention parameter\n",
    "        self.attn = nn.Parameter(torch.FloatTensor(size=(1, num_heads, out_edge_feats)))\n",
    "        \n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.FloatTensor(size=(num_heads * out_edge_feats,)))\n",
    "        else:\n",
    "            self.register_buffer('bias', None)\n",
    "        \n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        torch.manual_seed(42)\n",
    "        gain = init.calculate_gain('relu')\n",
    "        init.xavier_normal_(self.fc_node.weight, gain=gain)\n",
    "        init.xavier_normal_(self.fc_ni.weight, gain=gain)\n",
    "        init.xavier_normal_(self.fc_fij.weight, gain=gain)\n",
    "        init.xavier_normal_(self.fc_nj.weight, gain=gain)\n",
    "        init.xavier_normal_(self.attn, gain=gain)\n",
    "        \n",
    "        if self.bias is not None:\n",
    "            nn.init.constant_(self.bias, 0)\n",
    "\n",
    "    def forward(self, graph, nfeats, efeats, get_attention=False):\n",
    "        with graph.local_scope():\n",
    "            graph.edata['f'] = efeats\n",
    "            graph.ndata['h'] = nfeats\n",
    "            \n",
    "            f_ni = self.fc_ni(nfeats)\n",
    "            f_nj = self.fc_nj(nfeats)\n",
    "            f_fij = self.fc_fij(efeats)\n",
    "            graph.srcdata.update({'f_ni' : f_ni})\n",
    "            graph.dstdata.update({'f_nj' : f_nj})\n",
    "            \n",
    "            graph.apply_edges(fn.u_add_v('f_ni', 'f_nj', 'f_tmp'))\n",
    "            f_out = graph.edata.pop('f_tmp') + f_fij\n",
    "            \n",
    "            if self.bias is not None:\n",
    "                f_out += self.bias\n",
    "            f_out = nn.functional.leaky_relu(f_out)\n",
    "            f_out = f_out.view(-1, self._num_heads, self._out_edge_feats)\n",
    "            \n",
    "            e = (f_out * self.attn).sum(dim=-1).unsqueeze(-1)\n",
    "            graph.edata['a'] = edge_softmax(graph, e)\n",
    "            graph.ndata['h_out'] = self.fc_node(nfeats).view(-1, self._num_heads, self._out_node_feats)\n",
    "            \n",
    "            graph.update_all(fn.u_mul_e('h_out', 'a', 'm'), fn.sum('m', 'h_out'))\n",
    "\n",
    "            h_out = graph.ndata['h_out'].view(-1, self._num_heads, self._out_node_feats)\n",
    "            if get_attention:\n",
    "                return h_out, f_out, graph.edata.pop('a')\n",
    "            else:\n",
    "                return h_out, f_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7adf37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ohe(edge_types):\n",
    "    one_hot_encoding = []\n",
    "    for edge_type in edge_types:\n",
    "        if edge_type == 0:\n",
    "            one_hot_encoding.append([1., 0., 0.])\n",
    "        elif edge_type == 1:\n",
    "            one_hot_encoding.append([0., 1., 0.])\n",
    "        elif edge_type == 2:\n",
    "            one_hot_encoding.append([0., 0., 1.])\n",
    "    return torch.tensor(one_hot_encoding)\n",
    "\n",
    "def get_inferred_edgetypes_GAT(dialog, edge_types):\n",
    "    inferred_edge_types = []\n",
    "    inferred_edge_indices = []\n",
    "    for target_node in dialog.values():\n",
    "        if len(target_node) == 1:\n",
    "            inferred_edge_types.append(0)\n",
    "            inferred_edge_indices.append(0)\n",
    "        else:\n",
    "            edge_index = target_node[0][0]\n",
    "            highest_attention = target_node[0][1]\n",
    "            for src_node in target_node[1:]:\n",
    "                if highest_attention < src_node[1]:\n",
    "                    highest_attention = src_node[1]\n",
    "                    edge_index = src_node[0]\n",
    "            inferred_edge_indices.append(edge_index)\n",
    "            inferred_edge_types.append(edge_types[edge_index].tolist())\n",
    "    return inferred_edge_indices, inferred_edge_types\n",
    "\n",
    "def get_inferred_edgetypes_EGAT(edges_target_nodes, sample_edge_types, size_dialog, dialog_id):\n",
    "    inferred_edge_types = []\n",
    "    for target_idx in range(size_dialog):\n",
    "        num_edges = len(edges_target_nodes[target_idx])\n",
    "        if num_edges == 1:\n",
    "            edgetype_idx = np.argmax(edges_target_nodes[target_idx][0][1])\n",
    "            edge_idx = edges_target_nodes[target_idx][0][0]\n",
    "            inferred_edge_types.append(edgetype_idx)\n",
    "        else:\n",
    "            highest_attn_score = max(edges_target_nodes[target_idx][0][1])\n",
    "            edgetype_idx = np.argmax(edges_target_nodes[target_idx][0][1])\n",
    "            edge_idx = edges_target_nodes[target_idx][0][0]\n",
    "            for sample_edge in range(1, num_edges):\n",
    "                cur_highest_attn_score = max(edges_target_nodes[target_idx][sample_edge][1])\n",
    "                if cur_highest_attn_score > highest_attn_score:\n",
    "                    highest_attn_score = cur_highest_attn_score\n",
    "                    edgetype_idx = np.argmax(edges_target_nodes[target_idx][sample_edge][1])\n",
    "                    edge_idx = edges_target_nodes[target_idx][sample_edge][0]\n",
    "            inferred_edge_types.append(edgetype_idx)\n",
    "    return inferred_edge_types\n",
    "\n",
    "def flatten_extend(matrix):\n",
    "    flat_list = []\n",
    "    for row in matrix:\n",
    "        flat_list.extend(row)\n",
    "    return flat_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7639e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_node_pairs_list(start_idx, end_idx):\n",
    "    list_node_i = []\n",
    "    list_node_j = []\n",
    "    end_idx = end_idx - start_idx\n",
    "    start_idx = 0\n",
    "    for i in range(start_idx, end_idx+1):\n",
    "        val = 0\n",
    "        while (val <= 3) and (i+val <= end_idx):\n",
    "            target_idx = i+val\n",
    "            if target_idx >= 0:\n",
    "                list_node_i.append(i)\n",
    "                list_node_j.append(target_idx)\n",
    "            val = val+1\n",
    "    return [list_node_i, list_node_j]\n",
    "\n",
    "def create_adjacency_dict(node_pairs):\n",
    "    adjacency_list_dict = {}\n",
    "    for i in range(0, len(node_pairs[0])):\n",
    "        source_node, target_node = node_pairs[0][i], node_pairs[1][i]\n",
    "        if source_node not in adjacency_list_dict:\n",
    "            adjacency_list_dict[source_node] = [target_node]\n",
    "        else:\n",
    "            adjacency_list_dict[source_node].append(target_node)\n",
    "    return adjacency_list_dict\n",
    "\n",
    "def get_all_adjacency_list(ranges, key=0):\n",
    "    all_adjacency_list = []\n",
    "    for range_pair in ranges:\n",
    "        start_idx, end_idx = range_pair\n",
    "        if key == 0:\n",
    "            output = create_node_pairs_list(start_idx, end_idx)\n",
    "            output = create_adjacency_dict(output)\n",
    "        elif key == 1:\n",
    "            output = create_node_pairs_list(start_idx, end_idx)\n",
    "            output = torch.tensor(output)\n",
    "        else:\n",
    "            print(\"N/A\")\n",
    "        all_adjacency_list.append(output)\n",
    "    return all_adjacency_list\n",
    "\n",
    "def get_all_edge_type_list(edge_indices, encoded_speaker_list):\n",
    "    dialogs_len = len(edge_indices)\n",
    "    whole_edge_type_list = []\n",
    "    for i in range(dialogs_len):\n",
    "        dialog_nodes_pairs = edge_indices[i]\n",
    "        dialog_speakers = list(encoded_speaker_list[i])\n",
    "        dialog_len = len(dialog_nodes_pairs.keys())\n",
    "        edge_type_list = []\n",
    "        for j in range(dialog_len):\n",
    "            src_node = dialog_nodes_pairs[j]\n",
    "            node_i_idx = j\n",
    "            win_len = len(src_node)\n",
    "            for k in range(win_len):\n",
    "                node_j_idx = src_node[k]\n",
    "                if node_i_idx == node_j_idx:\n",
    "                    edge_type_list.append(0)\n",
    "                else:\n",
    "                    if dialog_speakers[node_i_idx] != dialog_speakers[node_j_idx]:\n",
    "                        edge_type_list.append(1)\n",
    "                    else:\n",
    "                        edge_type_list.append(2)\n",
    "        whole_edge_type_list.append(torch.tensor(edge_type_list).to(torch.int64))\n",
    "    return whole_edge_type_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91faed3",
   "metadata": {},
   "source": [
    "<h3> Data Preparetion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0006630b",
   "metadata": {},
   "source": [
    "<h4> Creating graph features from Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d8a8f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkFile = os.path.isfile(\"data/dump/speaker_encoder_train.pkl\")\n",
    "encodedSpeakersTrain = []\n",
    "rangesTrain = []\n",
    "\n",
    "if not checkFile:\n",
    "    print(\"Run first the contextEncoder2 to generate this file\")\n",
    "else:\n",
    "    with open('data/dump/speaker_encoder_train.pkl', \"rb\") as file:\n",
    "        encodedSpeakersTrain, rangesTrain = pickle.load(file)\n",
    "\n",
    "checkFile = os.path.isfile(\"data/dump/adjListTrain.pkl\")\n",
    "adjacencyListTrain = []\n",
    "\n",
    "if key:\n",
    "    adjacencyListTrain = get_all_adjacency_list(rangesTrain)\n",
    "else:\n",
    "    with open('data/dump/adjListTrain', \"rb\") as file:\n",
    "        adjacencyListTrain = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "771b8350",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'embed/u_prime_BERT_train.pkl'\n",
    "\n",
    "# Load the list from the file using pickle\n",
    "with open(file_path, 'rb') as file:\n",
    "    contextualEmbeddingsTrain = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6055971",
   "metadata": {},
   "outputs": [],
   "source": [
    "edgeIndicesTrain = get_all_adjacency_list(rangesTrain)\n",
    "edgeTypesTrain = get_all_edge_type_list(edgeIndicesTrain, encodedSpeakersTrain)\n",
    "edgeIndicesTrain = get_all_adjacency_list(rangesTrain, key=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469c67ff",
   "metadata": {},
   "source": [
    "<h4> Creating graph features from Test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df15e1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkFile = os.path.isfile(\"data/dump/speaker_encoder_test.pkl\")\n",
    "encodedSpeakersTest = []\n",
    "rangesTest = []\n",
    "\n",
    "if not checkFile:\n",
    "    print(\"Run first the contextEncoder2 to generate this file\")\n",
    "else:\n",
    "    with open('data/dump/speaker_encoder_test.pkl', \"rb\") as file:\n",
    "        encodedSpeakersTest, rangesTest = pickle.load(file)\n",
    "\n",
    "checkFile = os.path.isfile(\"data/dump/adjListTest.pkl\")\n",
    "adjacencyListTest = []\n",
    "\n",
    "if key:\n",
    "    adjacencyListTest = get_all_adjacency_list(rangesTest)\n",
    "else:\n",
    "    with open('data/dump/adjListTest', \"rb\") as file:\n",
    "        adjacencyListTest = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7ef966f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'embed/u_prime_BERT_test.pkl'\n",
    "\n",
    "# Load the list from the file using pickle\n",
    "with open(file_path, 'rb') as file:\n",
    "    contextualEmbeddingsTest = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17973a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "edgeIndicesTest = get_all_adjacency_list(rangesTest)\n",
    "edgeTypesTest = get_all_edge_type_list(edgeIndicesTest, encodedSpeakersTest)\n",
    "edgeIndicesTest = get_all_adjacency_list(rangesTest, key=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d14cedb",
   "metadata": {},
   "source": [
    "<h4> Creating graph features from Test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2ffa59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO repeat the one above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a44f59",
   "metadata": {},
   "source": [
    "<h3> Get GAT output from each set of data (train, test, validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c36c94f",
   "metadata": {},
   "source": [
    "<h4> Instantiating the GAT (1st implementation) for 1 sample train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cacafa9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_in_features = len(contextualEmbeddingsTrain[0][0])\n",
    "num_out_features = len(contextualEmbeddingsTrain[0][0])\n",
    "num_heads = 4\n",
    "num_edge_types = 3\n",
    "gat_layer = GATLayerWithEdgeType(num_in_features, num_out_features, num_heads, num_edge_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98a8775c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_prime shape:  torch.Size([14, 50]) attention_coef shape:  torch.Size([14, 768, 50])\n"
     ]
    }
   ],
   "source": [
    "i = 0  # dialogue id\n",
    "relationalEmbedding, attentionCoef = gat_layer((contextualEmbeddingsTrain[i], edgeIndicesTrain[i]), edgeTypesTrain[i])\n",
    "print(\"h_prime shape: \", relationalEmbedding.shape, \"attention_coef shape: \", attentionCoef.shape)\n",
    "\n",
    "targetNodes = edgeIndicesTrain[i][1].tolist()\n",
    "\n",
    "sample = {}\n",
    "sampleEdgetypes = []\n",
    "\n",
    "for target_i in sorted(set(targetNodes)):\n",
    "    sample[target_i] = []\n",
    "\n",
    "for targetNode, idx in zip(targetNodes, range(len(targetNodes))):\n",
    "    sample[targetNode].append([idx, relationalEmbedding[targetNode][idx].tolist()])\n",
    "\n",
    "listEdgeIdxTrain, inferredEdgeTypes = get_inferred_edgetypes_GAT(sample, edgeTypesTrain[i])\n",
    "sampleEdgetypes.append(inferredEdgeTypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "258b7da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anger', 'disgust', 'fear', 'joy', 'neutral', 'sadness', 'surprise']\n"
     ]
    }
   ],
   "source": [
    "file = open('data/dump/label_decoder.pkl', 'rb')\n",
    "label_decoder = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "label_decoder = list(label_decoder.values())\n",
    "print(label_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4ed00de",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkFile = os.path.isfile(\"data/dump/labels_train.pkl\")\n",
    "\n",
    "if checkFile is False:\n",
    "    print(\"Please run the contextEncoder2 notebook to save the label file\")\n",
    "else:\n",
    "    file = open('data/dump/labels_train.pkl', 'rb')\n",
    "    y_train = pickle.load(file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5394940",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkFile = os.path.isfile(\"data/dump/labels_test.pkl\")\n",
    "\n",
    "if checkFile is False:\n",
    "    print(\"Please run the contextEncoder2 notebook to save the label file\")\n",
    "else:\n",
    "    file = open('data/dump/labels_test.pkl', 'rb')\n",
    "    y_test = pickle.load(file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42223125",
   "metadata": {},
   "source": [
    "<h4> Visualize 1 instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1a41a39",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# # Assuming h_prime contains the node embeddings\n",
    "# utt_size = 13\n",
    "# labels = torch.tensor(y_train[:utt_size + 1])\n",
    "\n",
    "# cherrypicked_nodes = []\n",
    "# for src_idx, edge_idx in zip(range(len(list_edge_idx)), list_edge_idx):\n",
    "#     cherrypicked_nodes.append(attention_coef[src_idx, :, edge_idx].tolist())\n",
    "# cherrypicked_nodes = torch.tensor(cherrypicked_nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47a97231",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# h_prime_np = cherrypicked_nodes.detach().numpy()\n",
    "\n",
    "# # Perform dimensionality reduction using t-SNE\n",
    "# tsne = TSNE(n_components=3, perplexity=5, random_state=42)\n",
    "# h_prime_tsne = tsne.fit_transform(h_prime_np)\n",
    "\n",
    "# # Plot the node embeddings with different colors for each label\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# for label, emotion in zip(range(len(label_decoder)), label_decoder): \n",
    "#     indices = (labels == label).nonzero().squeeze()\n",
    "#     plt.scatter(h_prime_tsne[indices, 0], h_prime_tsne[indices, 1], label=f'{emotion}')\n",
    "# plt.title('Node Embeddings Visualization (t-SNE)', color=\"white\")\n",
    "# plt.xlabel('Dimension 1', color=\"white\")\n",
    "# plt.ylabel('Dimension 2', color=\"white\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8043a6a",
   "metadata": {},
   "source": [
    "<h4>Now get new representations of all train, test, validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "588776d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filePath = data/dump/h_prime_BERT-GAT_train.pkl\n",
    "#            data/dump/h_prime_BERT-GAT_test.pkl\n",
    "#            data/dump/h_prime_BERT-GAT_valid.pkl\n",
    "\n",
    "def get_GAT_representation(filePath, contextualEmbeddings, edgeIndices, edgeTypes):\n",
    "#     checkFile = os.path.isfile(\"data/dump/h_prime_BERT-GAT_train.pkl\") #replace it with key when deployed\n",
    "    if key:\n",
    "        print(\"Start of getting output of 1st GAT\")\n",
    "        allInferredEdgetypes = []\n",
    "        listAllEdgeIdx = []\n",
    "        cherrypickedNodes = []\n",
    "        for dialog, dialog_id in zip(contextualEmbeddings, range(len(contextualEmbeddings))):\n",
    "            h_prime, attention_coef = gat_layer((dialog, edgeIndices[dialog_id]), edgeTypes[dialog_id])\n",
    "            target_nodes = edgeIndices[dialog_id][1].tolist() # first idx represents dialogue id\n",
    "\n",
    "            sample_edgetypes = {}\n",
    "            for i in set(target_nodes):\n",
    "                sample_edgetypes[i] = []\n",
    "\n",
    "            for target_node, edge_idx in zip(target_nodes, range(len(target_nodes))):\n",
    "                sample_edgetypes[target_node].append([edge_idx, h_prime[target_node][edge_idx].tolist()])\n",
    "\n",
    "            list_edge_idx, inferred_edgetypes = get_inferred_edgetypes_GAT(sample_edgetypes,  edgeTypes[dialog_id])\n",
    "            listAllEdgeIdx.append(list_edge_idx)\n",
    "            allInferredEdgetypes.append(inferred_edgetypes)\n",
    "\n",
    "            for src_idx, edge_idx in zip(range(len(list_edge_idx)), list_edge_idx):\n",
    "                cherrypickedNodes.append(attention_coef[src_idx, :, edge_idx].tolist())\n",
    "\n",
    "        cherrypickedNodes = torch.tensor(cherrypickedNodes)\n",
    "        cherrypickedNodes.shape\n",
    "        print(\"End of getting output of 1st GAT\")\n",
    "\n",
    "        pickle.dump([cherrypickedNodes, allInferredEdgetypes],\n",
    "                    open(filePath, 'wb'))\n",
    "\n",
    "    else:\n",
    "        file = open(filePath, 'rb')\n",
    "        cherrypickedNodes, allInferredEdgetypes = pickle.load(file)\n",
    "        file.close()\n",
    "\n",
    "    return cherrypickedNodes, allInferredEdgetypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "65d7c89a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of getting output of 1st GAT\n",
      "End of getting output of 1st GAT\n",
      "Start of getting output of 1st GAT\n",
      "End of getting output of 1st GAT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[0.1640, 0.1822, 0.1596,  ..., 0.1970, 0.1354, 0.1902],\n",
       "         [0.1745, 0.1744, 0.1186,  ..., 0.1942, 0.1157, 0.1762],\n",
       "         [0.2323, 0.0918, 0.1859,  ..., 0.1874, 0.1797, 0.2020],\n",
       "         ...,\n",
       "         [0.0460, 0.0633, 0.0562,  ..., 0.0548, 0.0345, 0.0650],\n",
       "         [0.0509, 0.0439, 0.0935,  ..., 0.0525, 0.0407, 0.0641],\n",
       "         [0.0467, 0.0600, 0.0455,  ..., 0.0684, 0.0288, 0.0701]]),\n",
       " [[0, 0, 2],\n",
       "  [0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "  [0, 0, 2, 2, 2, 2],\n",
       "  [0, 0],\n",
       "  [0, 0, 2, 2, 2],\n",
       "  [0, 0, 2, 2],\n",
       "  [0, 0, 2, 0],\n",
       "  [0, 0, 2, 2, 2, 2, 2, 2],\n",
       "  [0, 2, 2, 2],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0, 2, 2],\n",
       "  [0, 0],\n",
       "  [0, 0, 2, 0, 0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0, 2],\n",
       "  [0, 0],\n",
       "  [0, 2, 2, 2],\n",
       "  [0, 0],\n",
       "  [0, 2],\n",
       "  [0, 2],\n",
       "  [0, 2],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0, 2, 2, 0],\n",
       "  [0, 0, 2],\n",
       "  [0, 0],\n",
       "  [0, 0, 2, 0],\n",
       "  [0, 2, 0, 2, 2],\n",
       "  [0, 0, 2, 2, 2, 2, 0, 0, 2, 2, 2, 0],\n",
       "  [0, 0, 2, 2, 2, 0, 2, 0, 2, 0, 2, 2, 2],\n",
       "  [0, 0, 0, 2, 2],\n",
       "  [0, 0, 2, 2, 0, 2, 2, 2],\n",
       "  [0, 0, 2, 2, 2, 2, 2, 2],\n",
       "  [0, 0, 2, 0, 2, 2, 2],\n",
       "  [0, 0, 2],\n",
       "  [0, 0, 2, 2],\n",
       "  [0, 0, 2, 2],\n",
       "  [0, 2, 2, 2, 2],\n",
       "  [0, 2, 2, 0],\n",
       "  [0, 0, 2, 2],\n",
       "  [0, 2, 2, 2, 2],\n",
       "  [0, 2, 2, 2, 0, 2, 0, 2, 2],\n",
       "  [0, 2, 2, 2, 2],\n",
       "  [0, 2, 0, 2, 0, 2],\n",
       "  [0, 0, 0, 2, 0, 2],\n",
       "  [0, 2, 0, 2],\n",
       "  [0, 2, 0, 2],\n",
       "  [0, 0, 2, 2, 0, 2, 2, 2],\n",
       "  [0, 2, 0, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2],\n",
       "  [0, 2, 2, 2, 2, 0, 2, 2],\n",
       "  [0, 0, 2, 2, 2, 2, 2, 2, 0, 2],\n",
       "  [0, 2, 2],\n",
       "  [0, 0, 2, 2, 2, 2, 0, 2],\n",
       "  [0, 2, 2, 2, 2, 0, 2],\n",
       "  [0, 0, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 0, 0, 2, 2, 2, 0, 2, 0, 2, 0],\n",
       "  [0, 0, 2],\n",
       "  [0, 2, 0, 2],\n",
       "  [0, 2, 0, 2, 2, 2, 2, 2, 0, 0, 2, 2],\n",
       "  [0, 0, 2, 2],\n",
       "  [0, 0, 2, 2, 2, 2, 0, 2, 2, 2],\n",
       "  [0, 0],\n",
       "  [0, 2, 0, 0, 2, 2, 0, 2, 2, 2, 0, 2, 0, 2, 2, 2],\n",
       "  [0, 0, 2, 0, 0, 2, 2],\n",
       "  [0, 2, 0, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2],\n",
       "  [0, 0, 2, 2, 2, 2],\n",
       "  [0, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2],\n",
       "  [0, 0, 2, 2, 0],\n",
       "  [0, 0, 2, 0, 0, 0, 2, 2],\n",
       "  [0, 0, 2, 2, 0, 2, 2, 2, 2, 0, 2, 0, 0, 2, 2, 2, 2, 2, 2],\n",
       "  [0, 2],\n",
       "  [0, 0, 2],\n",
       "  [0, 2],\n",
       "  [0, 0],\n",
       "  [0, 0, 2, 0, 0, 2, 2, 2],\n",
       "  [0, 2, 2, 0, 2],\n",
       "  [0, 0, 2, 0, 2],\n",
       "  [0, 2],\n",
       "  [0, 0],\n",
       "  [0, 0, 0],\n",
       "  [0, 2],\n",
       "  [0, 0, 2],\n",
       "  [0, 2],\n",
       "  [0, 2],\n",
       "  [0, 0, 2, 2],\n",
       "  [0, 0, 2, 2, 2, 2, 2, 0],\n",
       "  [0, 2, 2],\n",
       "  [0, 0, 2, 2, 0, 2],\n",
       "  [0, 0, 0, 2, 0],\n",
       "  [0, 0, 2, 2, 0, 2],\n",
       "  [0, 0, 2, 2, 2, 2],\n",
       "  [0, 2, 0, 2, 2],\n",
       "  [0, 2, 2],\n",
       "  [0, 2],\n",
       "  [0, 0, 2, 2],\n",
       "  [0, 2, 2, 2, 2, 0, 2, 2, 2],\n",
       "  [0, 0, 2, 2, 2, 2, 2, 2],\n",
       "  [0, 2],\n",
       "  [0, 2, 2, 2, 0, 0, 2, 2, 2, 0],\n",
       "  [0, 2, 0, 2, 2, 2],\n",
       "  [0, 2, 0, 2, 0, 2, 2],\n",
       "  [0, 0, 2],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 2, 0],\n",
       "  [0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2],\n",
       "  [0, 0, 2, 2, 0, 0, 0, 0],\n",
       "  [0, 0, 2, 2],\n",
       "  [0, 0],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 2],\n",
       "  [0, 0, 2, 2, 2, 2, 2, 2, 0, 2, 0, 2],\n",
       "  [0, 0, 2, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2],\n",
       "  [0, 2, 2, 2, 2],\n",
       "  [0, 2, 2, 0, 2, 2],\n",
       "  [0, 0, 2, 2, 0, 0],\n",
       "  [0, 2, 0],\n",
       "  [0, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2],\n",
       "  [0, 2, 2, 0, 2, 2],\n",
       "  [0, 0, 2, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 2, 2, 0, 2],\n",
       "  [0, 2, 0],\n",
       "  [0, 0, 0, 0, 2, 2, 2],\n",
       "  [0, 2, 2],\n",
       "  [0, 2],\n",
       "  [0, 2],\n",
       "  [0, 2, 2, 2, 2, 0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0, 2, 2, 2, 2, 2, 0, 0, 2],\n",
       "  [0, 0, 2, 2, 2, 2, 2, 2],\n",
       "  [0, 0, 0, 2, 2, 2, 2],\n",
       "  [0, 0],\n",
       "  [0, 0, 0, 2],\n",
       "  [0, 0, 2, 2],\n",
       "  [0, 2],\n",
       "  [0, 2, 0],\n",
       "  [0, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 0],\n",
       "  [0, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 0],\n",
       "  [0, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 2, 2],\n",
       "  [0, 0, 2, 2, 2, 2],\n",
       "  [0, 0, 2, 2, 2, 2, 2, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0, 2, 2, 2, 2, 0, 0, 0, 2, 2, 2, 2],\n",
       "  [0, 2],\n",
       "  [0, 0, 2, 2, 2, 2, 0, 2, 2, 2],\n",
       "  [0, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2],\n",
       "  [0, 0, 2, 2, 0, 2, 2, 2, 0, 2, 2, 2, 2],\n",
       "  [0, 0, 0, 2, 2, 0, 0, 2, 2, 0, 2, 0, 2],\n",
       "  [0, 0, 2, 2, 2, 2],\n",
       "  [0, 0],\n",
       "  [0, 0, 2],\n",
       "  [0, 0, 2],\n",
       "  [0, 2, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 2],\n",
       "  [0, 0],\n",
       "  [0, 0, 2, 0, 2, 0],\n",
       "  [0, 2, 2, 2, 0, 2, 2, 0, 0],\n",
       "  [0, 0, 2, 0, 2, 2, 2, 2],\n",
       "  [0, 2],\n",
       "  [0, 0, 0, 0, 0, 2, 2],\n",
       "  [0, 0, 2, 2],\n",
       "  [0, 2],\n",
       "  [0, 0, 2, 2],\n",
       "  [0, 0, 2, 2],\n",
       "  [0, 0, 2, 0, 2],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0, 0, 0, 2],\n",
       "  [0, 2, 0, 2, 2, 0, 2],\n",
       "  [0, 0, 2, 0],\n",
       "  [0, 0],\n",
       "  [0, 2, 0, 2, 2],\n",
       "  [0, 0],\n",
       "  [0, 0, 2, 2],\n",
       "  [0, 0, 2],\n",
       "  [0, 0, 2],\n",
       "  [0, 0, 2],\n",
       "  [0, 2, 0, 2, 2, 2],\n",
       "  [0, 0, 2, 2, 2, 2],\n",
       "  [0, 2, 2],\n",
       "  [0, 0],\n",
       "  [0, 0, 2, 2],\n",
       "  [0, 0],\n",
       "  [0, 2],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 2],\n",
       "  [0, 2, 2],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 2, 2, 2, 0],\n",
       "  [0, 2, 0, 2, 2],\n",
       "  [0, 2, 2, 0, 2],\n",
       "  [0, 2, 2, 2, 2, 2, 2, 2, 2, 0],\n",
       "  [0, 0, 2, 2, 0, 2, 2, 2, 0],\n",
       "  [0, 0],\n",
       "  [0, 2, 0],\n",
       "  [0, 0, 2, 0, 0, 0, 2, 2, 0, 0],\n",
       "  [0, 0],\n",
       "  [0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 0],\n",
       "  [0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 0],\n",
       "  [0, 0, 2, 0, 2, 0, 0],\n",
       "  [0, 0, 2, 2, 2, 2, 2, 2],\n",
       "  [0, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2],\n",
       "  [0, 2, 2, 0],\n",
       "  [0, 0, 2, 0, 2, 2, 2, 2, 2],\n",
       "  [0, 0, 2, 2, 2, 2, 2, 0, 2, 0, 0, 2],\n",
       "  [0, 0, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "  [0, 0, 0, 2, 2, 2, 2, 2, 0],\n",
       "  [0, 0, 2, 2, 2, 0, 2, 2, 2, 2],\n",
       "  [0, 0, 0, 2],\n",
       "  [0, 0, 2, 2, 2, 2, 2, 2, 0, 0],\n",
       "  [0, 0, 2, 2, 2, 2],\n",
       "  [0, 0, 2],\n",
       "  [0, 0, 2],\n",
       "  [0, 2],\n",
       "  [0, 2, 2],\n",
       "  [0, 0, 0, 0, 2, 2, 2, 0, 0, 2, 0, 2, 2],\n",
       "  [0, 0, 2, 0, 2, 2, 2, 2],\n",
       "  [0, 2],\n",
       "  [0, 2, 0, 2, 0],\n",
       "  [0, 0, 2, 2],\n",
       "  [0, 2],\n",
       "  [0, 0, 2, 0, 2, 2],\n",
       "  [0, 0, 2, 2, 0, 2, 2],\n",
       "  [0, 0, 2, 2, 2, 2, 0, 2, 0, 2, 0],\n",
       "  [0, 0],\n",
       "  [0, 0, 2, 2],\n",
       "  [0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2],\n",
       "  [0, 0],\n",
       "  [0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2],\n",
       "  [0, 2, 2, 2, 0, 2, 0],\n",
       "  [0, 0, 2, 0, 2, 2, 2],\n",
       "  [0, 0, 0, 2],\n",
       "  [0, 0, 2, 2],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0, 0, 0, 2],\n",
       "  [0, 0, 2],\n",
       "  [0, 2],\n",
       "  [0, 2, 2, 0, 2],\n",
       "  [0, 0, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2],\n",
       "  [0, 2, 0, 2, 2, 2, 2, 2, 2],\n",
       "  [0, 2, 0, 2, 2, 2, 0, 0, 2, 0, 2, 2],\n",
       "  [0, 0, 2, 2],\n",
       "  [0, 2],\n",
       "  [0, 0, 2],\n",
       "  [0, 2, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 0],\n",
       "  [0, 2, 0, 0, 2, 2],\n",
       "  [0, 0, 2, 2, 2],\n",
       "  [0, 0, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0],\n",
       "  [0, 0, 2, 2, 2, 0],\n",
       "  [0, 0, 0, 0, 2, 2, 2, 0, 2, 2, 0, 2, 2, 2],\n",
       "  [0, 2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 0, 2, 2],\n",
       "  [0, 0, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2],\n",
       "  [0, 0, 2, 2],\n",
       "  [0, 2, 2, 0, 2, 2, 0, 0, 2, 0, 0, 0, 2],\n",
       "  [0, 0, 2, 2, 2],\n",
       "  [0, 0, 2, 0, 2],\n",
       "  [0, 0, 2],\n",
       "  [0, 2, 2, 0, 2, 2, 2, 2, 0, 2],\n",
       "  [0, 2, 0, 2, 2, 2, 2, 2],\n",
       "  [0, 0, 2, 2, 2, 2, 2, 0, 0, 2, 2, 0, 2, 0, 2, 0, 0, 2],\n",
       "  [0, 0, 2, 2],\n",
       "  [0, 0, 2, 2],\n",
       "  [0, 0, 0],\n",
       "  [0, 2, 0],\n",
       "  [0, 0, 2, 0, 0, 2],\n",
       "  [0, 0, 2, 2, 0, 0, 2, 2, 2, 2, 0],\n",
       "  [0, 0, 2, 2, 2, 0, 0, 2, 2, 0, 2, 2],\n",
       "  [0, 0, 2, 2, 2, 2],\n",
       "  [0, 2],\n",
       "  [0, 0, 0, 2, 2, 0, 2, 2, 2],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 2, 2, 2, 2, 2, 2, 2],\n",
       "  [0, 2, 2, 0],\n",
       "  [0, 0, 2, 2, 2, 2],\n",
       "  [0, 2, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2],\n",
       "  [0, 0, 2, 2, 2, 2, 2],\n",
       "  [0, 0],\n",
       "  [0, 0, 2],\n",
       "  [0, 0],\n",
       "  [0, 0, 2],\n",
       "  [0, 0, 0, 2],\n",
       "  [0, 0, 0, 2, 2],\n",
       "  [0, 0, 2, 2, 2, 2, 0, 2, 2, 0, 2, 2, 0, 0, 2, 2, 2],\n",
       "  [0, 0, 2, 0, 2],\n",
       "  [0, 0, 2, 2, 0, 2, 2, 2, 0],\n",
       "  [0, 0, 2, 2, 0, 2, 2, 0, 0, 2, 0, 2],\n",
       "  [0, 2, 2, 2],\n",
       "  [0, 0, 2, 2, 2, 0, 2, 2],\n",
       "  [0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0],\n",
       "  [0, 2, 0, 2, 2, 2, 2],\n",
       "  [0, 2, 2, 2, 2, 2, 0, 2, 0],\n",
       "  [0, 0, 0, 0, 2, 2, 2],\n",
       "  [0, 0, 2, 2],\n",
       "  [0, 0, 0],\n",
       "  [0, 2, 2, 2, 0],\n",
       "  [0, 2],\n",
       "  [0, 2, 2, 2],\n",
       "  [0, 0, 0, 0, 2],\n",
       "  [0, 0],\n",
       "  [0, 0, 2, 2, 2, 2, 2, 2, 2, 0],\n",
       "  [0, 2, 2, 2, 0, 2, 2],\n",
       "  [0, 0],\n",
       "  [0, 2, 0, 0, 0, 2, 2, 2, 0, 2, 0, 0, 0, 2, 2, 2, 2, 2],\n",
       "  [0, 2, 2, 0, 0, 0],\n",
       "  [0, 0, 2, 2],\n",
       "  [0, 2],\n",
       "  [0, 0, 0, 0],\n",
       "  [0, 0, 2, 2, 2, 2, 2, 2, 2],\n",
       "  [0, 0, 2, 2, 2, 2, 2, 2, 0, 2, 0, 2, 0, 0, 2, 2],\n",
       "  [0, 0, 2, 2, 2, 0, 2, 2],\n",
       "  [0, 0, 2, 0, 2, 0],\n",
       "  [0, 0, 2],\n",
       "  [0, 0, 2, 2, 2, 2, 2, 0],\n",
       "  [0, 2, 0, 2, 2, 2, 2, 2, 2, 0, 2, 0],\n",
       "  [0, 0, 2, 2, 2, 2],\n",
       "  [0, 2, 2, 2, 0, 0, 0, 2, 2],\n",
       "  [0, 0, 2, 2, 0, 0, 2, 2, 2],\n",
       "  [0, 2, 0, 2, 0, 0],\n",
       "  [0, 2, 2, 0, 2, 2, 2, 2, 2, 2],\n",
       "  [0, 0, 0, 0, 2, 0],\n",
       "  [0, 2, 0, 2, 2, 2, 0],\n",
       "  [0, 2],\n",
       "  [0, 0, 2, 2, 2],\n",
       "  [0, 0, 2, 2, 0, 2, 2, 0, 2, 2, 0, 0, 2, 2],\n",
       "  [0, 2, 0, 2, 0, 2, 2, 2, 0, 2, 0, 0, 0],\n",
       "  [0, 0, 2, 2, 2, 2, 2],\n",
       "  [0, 0, 2, 2, 2],\n",
       "  [0, 0, 0, 2, 0],\n",
       "  [0, 0, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "  [0, 0, 2, 2, 2, 2, 2, 2, 2, 0],\n",
       "  [0, 2],\n",
       "  [0, 2, 0, 2, 0, 2, 2, 2, 2, 2, 2],\n",
       "  [0, 0, 2, 0, 2, 0, 0, 2, 2, 2, 2, 0],\n",
       "  [0, 0, 2, 2, 2, 2, 2],\n",
       "  [0, 2, 2, 0, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2],\n",
       "  [0, 0, 2, 2],\n",
       "  [0, 2, 0, 2],\n",
       "  [0, 0, 2, 2],\n",
       "  [0, 0],\n",
       "  [0, 2, 2],\n",
       "  [0, 2, 0],\n",
       "  [0, 0, 2],\n",
       "  [0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 0, 0],\n",
       "  [0, 2, 2, 2, 2, 0],\n",
       "  [0, 0, 2, 2, 0, 2, 2, 2, 2, 0],\n",
       "  [0, 0, 2, 0, 0],\n",
       "  [0, 0, 2, 2, 2, 0],\n",
       "  [0, 0, 2, 2, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 0, 2, 0],\n",
       "  [0, 2],\n",
       "  [0, 2, 0],\n",
       "  [0, 0, 2],\n",
       "  [0, 2, 0, 2, 0, 0, 2],\n",
       "  [0, 0, 2, 2, 2, 0],\n",
       "  [0, 0, 2, 0],\n",
       "  [0, 0, 2, 2, 2, 2, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 2, 2, 0, 2, 2, 2],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 2, 2],\n",
       "  [0, 2],\n",
       "  [0, 0, 0, 0, 2, 2, 2, 2, 2],\n",
       "  [0, 0, 2, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2],\n",
       "  [0, 0, 0, 2, 2, 0, 2, 2],\n",
       "  [0, 0, 2],\n",
       "  [0, 2],\n",
       "  [0, 0, 2, 0, 2, 0, 0, 0],\n",
       "  [0, 0, 2, 2, 2],\n",
       "  [0, 0],\n",
       "  [0, 0, 2, 2, 2, 2, 2],\n",
       "  [0, 0, 2, 2, 0, 2],\n",
       "  [0, 2, 2, 0, 2, 2, 2, 2, 2, 0],\n",
       "  [0, 0, 2, 0, 2],\n",
       "  [0, 0, 0, 2, 2],\n",
       "  [0, 0],\n",
       "  [0, 0, 2, 2, 2, 0],\n",
       "  [0, 0, 2, 2, 2, 0],\n",
       "  [0, 0, 2, 0, 0, 2],\n",
       "  [0, 0, 2, 0, 2],\n",
       "  [0, 0, 2, 2],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 2, 2, 2, 2, 0, 0, 2, 0, 2, 2],\n",
       "  [0, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 0, 2, 2],\n",
       "  [0, 0],\n",
       "  [0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 2, 0, 2, 0],\n",
       "  [0, 0, 2, 2, 2],\n",
       "  [0, 0],\n",
       "  [0, 0, 2, 2, 2, 2, 0],\n",
       "  [0, 0, 2, 2, 2, 2, 2],\n",
       "  [0, 0, 2, 2, 0, 2, 2],\n",
       "  [0, 0, 0, 2, 2, 2, 2, 2, 0, 2, 2, 0, 2],\n",
       "  [0, 2, 0, 2, 2, 2, 2, 2],\n",
       "  [0, 0],\n",
       "  [0, 0, 2, 2, 2, 2, 2, 0, 0, 0, 2, 0],\n",
       "  [0, 0, 2, 2, 2, 2],\n",
       "  [0, 2, 2, 2, 0],\n",
       "  [0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 0, 2],\n",
       "  [0, 0, 2, 2, 2, 2, 2, 0, 2, 0],\n",
       "  [0, 2],\n",
       "  [0, 0],\n",
       "  [0, 0, 2],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 2, 2],\n",
       "  [0, 0],\n",
       "  [0, 2],\n",
       "  [0, 0, 2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "  [0, 0],\n",
       "  [0, 2, 2, 0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0, 2, 2, 2],\n",
       "  [0, 0, 2, 2, 0, 0],\n",
       "  [0, 2, 2, 2],\n",
       "  [0, 2],\n",
       "  [0, 2, 2, 2, 2, 2, 2],\n",
       "  [0, 2, 2],\n",
       "  [0, 2, 2, 2, 0],\n",
       "  [0, 0, 2, 2],\n",
       "  [0, 0],\n",
       "  [0, 2],\n",
       "  [0, 2],\n",
       "  [0, 2, 0, 2, 0, 2, 0, 2],\n",
       "  [0, 0, 2, 2, 0, 0, 0, 2, 2, 2, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2],\n",
       "  [0, 2],\n",
       "  [0, 0],\n",
       "  [0, 2],\n",
       "  [0, 2],\n",
       "  [0, 0, 2, 2, 2],\n",
       "  [0, 2, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 0],\n",
       "  [0, 2, 2, 0],\n",
       "  [0, 0, 2, 2],\n",
       "  [0, 2, 0],\n",
       "  [0, 0],\n",
       "  [0, 0, 2, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0, 0, 0, 2, 2, 2],\n",
       "  [0, 0],\n",
       "  [0, 0, 2, 2, 2],\n",
       "  [0, 0],\n",
       "  [0, 0, 2],\n",
       "  [0, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0],\n",
       "  [0, 0, 0, 2, 0, 2, 2, 2, 2],\n",
       "  [0, 0, 0, 2, 2, 0, 2, 2, 2, 0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 2, 0, 2],\n",
       "  [0, 2],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0, 2, 2, 2, 2, 0, 0, 0, 2, 2, 2, 2, 2],\n",
       "  [0, 0, 2, 2, 2, 2],\n",
       "  [0, 0],\n",
       "  [0, 0, 2, 2, 2],\n",
       "  [0, 2],\n",
       "  [0, 2, 0, 2, 2, 0, 2, 0, 0, 2, 2, 2, 2, 0],\n",
       "  [0, 2, 0, 2, 2, 0, 2, 2],\n",
       "  [0, 0, 2, 2, 2, 2, 0, 2, 2, 0],\n",
       "  [0, 2, 0],\n",
       "  [0, 0, 2, 2, 2, 2, 2],\n",
       "  [0, 0, 2, 2],\n",
       "  [0, 2],\n",
       "  [0, 0, 2, 2, 2],\n",
       "  [0, 0, 2, 0],\n",
       "  [0, 0],\n",
       "  [0, 0, 2, 2],\n",
       "  [0, 0, 2, 2, 2],\n",
       "  [0, 0, 2, 2, 2, 2, 2],\n",
       "  [0, 2, 0, 2, 2, 2, 2, 0, 0],\n",
       "  [0, 0, 2, 0, 2, 2, 0],\n",
       "  [0, 2, 2, 2],\n",
       "  [0, 2],\n",
       "  [0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "  [0, 2],\n",
       "  [0, 0],\n",
       "  [0, 0, 2, 2, 2, 2],\n",
       "  [0, 0, 2, 0, 0, 2, 2, 2, 0, 2, 2],\n",
       "  [0, 2],\n",
       "  [0, 0, 2, 2, 2],\n",
       "  [0, 0, 2, 2, 2, 2, 2, 2],\n",
       "  [0, 0, 0, 0, 2, 0],\n",
       "  [0, 2, 2, 2, 2],\n",
       "  [0, 0, 0, 0, 2, 2, 2, 2, 2, 0, 2],\n",
       "  [0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2],\n",
       "  [0, 0, 2, 2, 2, 2, 2, 2],\n",
       "  [0, 0, 2, 2],\n",
       "  [0, 2, 0, 2, 0],\n",
       "  [0, 2, 0, 2, 2, 2, 2, 2, 2, 0, 0, 0],\n",
       "  [0, 0, 2],\n",
       "  [0, 0, 2, 2, 2, 2, 2, 2, 2],\n",
       "  [0, 2, 2, 2, 2],\n",
       "  [0, 2, 0, 2, 2, 2, 0, 2],\n",
       "  [0, 0, 2, 2, 2, 0, 2, 2],\n",
       "  [0, 0],\n",
       "  [0, 0, 2, 0],\n",
       "  [0, 0, 2, 2, 2],\n",
       "  [0, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2],\n",
       "  [0, 0, 2, 2, 2, 2, 0, 0, 0, 2, 2, 2, 2, 2, 0, 2],\n",
       "  [0, 2, 2, 2, 2, 2],\n",
       "  [0, 0, 2, 2, 2, 2],\n",
       "  [0, 2, 2, 2, 2, 2, 2],\n",
       "  [0, 0, 0, 2],\n",
       "  [0, 2, 2, 0, 0, 0, 2, 2],\n",
       "  [0, 0, 2, 0],\n",
       "  [0, 2, 2, 0, 0, 2, 2, 2],\n",
       "  [0, 2, 2, 2],\n",
       "  [0, 0, 2, 2, 2],\n",
       "  [0, 0],\n",
       "  [0, 2, 2, 2],\n",
       "  [0, 0],\n",
       "  [0, 2],\n",
       "  [0, 0, 2, 2],\n",
       "  [0, 0, 2],\n",
       "  [0, 2],\n",
       "  [0, 2, 0, 2, 0],\n",
       "  [0, 0, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2],\n",
       "  [0, 0, 2, 2, 2, 2, 2, 2, 2, 0],\n",
       "  [0, 2, 0, 2, 2, 0, 0],\n",
       "  [0, 0, 2, 2, 2, 0, 0, 2, 2, 2, 0, 2, 2, 2],\n",
       "  [0, 2, 0],\n",
       "  [0, 0, 2],\n",
       "  [0, 0, 2, 2, 2, 2, 2, 2],\n",
       "  [0, 0, 2, 2, 0, 2, 2, 2, 2],\n",
       "  [0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2],\n",
       "  [0, 2, 2, 2, 2, 2, 0],\n",
       "  [0, 0, 2, 0, 2, 0],\n",
       "  [0, 0, 2, 2],\n",
       "  [0, 0],\n",
       "  [0, 2, 2, 0, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2],\n",
       "  [0, 0, 2, 2, 2, 2, 2, 2, 0, 2, 2],\n",
       "  [0, 2, 2, 0, 2, 2, 2],\n",
       "  [0, 0, 0, 2, 2, 2],\n",
       "  [0, 2, 2, 2, 2, 2, 0, 2],\n",
       "  [0, 0, 0],\n",
       "  [0, 0],\n",
       "  [0, 2, 0, 2],\n",
       "  [0, 2, 0, 2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2, 0],\n",
       "  [0, 2],\n",
       "  [0, 2, 0, 2, 2],\n",
       "  [0, 0, 2, 2, 2, 2],\n",
       "  [0, 0],\n",
       "  [0, 0, 2],\n",
       "  [0, 0],\n",
       "  [0, 2],\n",
       "  [0, 0, 2],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0],\n",
       "  [0, 0, 2, 2, 2, 2],\n",
       "  [0, 2, 0, 2, 0, 2, 2, 2, 2, 2, 0],\n",
       "  [0, 0, 0, 2, 0],\n",
       "  [0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "  [0, 2, 2, 2, 2, 2, 2],\n",
       "  [0, 2, 2, 0, 2, 0]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train data\n",
    "cherrypickedNodesTrain, allInferredEdgetypesTrain = get_GAT_representation(\n",
    "                                                    \"data/dump/h_prime_BERT-GAT_train.pkl\",\n",
    "                                                    contextualEmbeddingsTrain,\n",
    "                                                    edgeIndicesTrain,\n",
    "                                                    edgeTypesTrain)\n",
    "# only save the pickle data for test and validation\n",
    "_, _ = get_GAT_representation(\"data/dump/h_prime_BERT-GAT_test.pkl\",\n",
    "                        contextualEmbeddingsTest,\n",
    "                        edgeIndicesTest,\n",
    "                        edgeTypesTest)\n",
    "# TODO add valid set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5fbe0a",
   "metadata": {},
   "source": [
    "<h5> Visualize Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "548c237c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.tensor(y_train)\n",
    "h_prime_np = cherrypickedNodesTrain.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "74050dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "runTSNE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5d86332b",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "if runTSNE:\n",
    "    # List of perplexity values to loop over\n",
    "    perplexity_values = [30, 100]\n",
    "\n",
    "    # Loop over each perplexity value\n",
    "    for perplexity in perplexity_values:\n",
    "        # Initialize t-SNE with the current perplexity value\n",
    "        tsne = TSNE(n_components=2, perplexity=perplexity, random_state=42)\n",
    "\n",
    "        # Fit and transform the data using t-SNE\n",
    "        h_prime_tsne = tsne.fit_transform(h_prime_np)\n",
    "\n",
    "        # Plot the node embeddings with different colors for each label\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        for label, emotion in zip(range(len(label_decoder)), label_decoder): \n",
    "            indices = (labels == label).nonzero().squeeze()\n",
    "            plt.scatter(h_prime_tsne[indices, 0], h_prime_tsne[indices, 1], label=f'{emotion}')\n",
    "        plt.title(f'Node Embeddings Visualization (t-SNE) - Perplexity {perplexity}', color=\"white\")\n",
    "        plt.xlabel('Dimension 1', color=\"white\")\n",
    "        plt.ylabel('Dimension 2', color=\"white\")\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5caea68",
   "metadata": {},
   "source": [
    "<h5> Analyze the edgetypes of all train nodes in the context of a dialog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c236b455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `all_inferred_edgetypes` and `y_train` are defined\n",
    "df_eda = pd.DataFrame(\n",
    "    {'edgetype': flatten_extend(allInferredEdgetypesTrain),\n",
    "     'label': y_train,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "46b7f357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crosstab Result:\n",
      "label        0    1    2     3     4    5    6\n",
      "edgetype                                      \n",
      "0          407  117   97   941  2218  277  591\n",
      "2         1093  247  241  1371  3742  599  899\n",
      "\n",
      "The P-Value of the Chi-Squared Test is: 6.372109133776597e-20\n",
      "Two variables are correlated\n"
     ]
    }
   ],
   "source": [
    "# Assuming `df_eda` and `CrosstabResult` are defined\n",
    "CrosstabResult = pd.crosstab(index=df_eda['edgetype'], columns=df_eda['label'])\n",
    "\n",
    "print(\"Crosstab Result:\")\n",
    "print(CrosstabResult)\n",
    "print()\n",
    "\n",
    "# Performing Chi-squared test\n",
    "ChiSqResult = chi2_contingency(CrosstabResult)\n",
    "\n",
    "# P-Value is the Probability of H0 being True\n",
    "# If P-Value > 0.05 then only we Accept the assumption(H0)\n",
    "# H0: The variables are not correlated with each other.\n",
    "\n",
    "print('The P-Value of the Chi-Squared Test is:', ChiSqResult[1])\n",
    "\n",
    "if ChiSqResult[1] > 0.05:\n",
    "    print(\"Variables are not correlated with each other\")\n",
    "else:\n",
    "    print(\"Two variables are correlated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540cb0a7",
   "metadata": {},
   "source": [
    "<h3> Get EGAT output from each set of data (train, test, validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "60061c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "egat = EGATConv(in_node_feats=len(contextualEmbeddingsTrain[0][0]),\n",
    "                    in_edge_feats=3,\n",
    "                    out_node_feats=len(contextualEmbeddingsTrain[0][0]),\n",
    "                    out_edge_feats=3,\n",
    "                    num_heads=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cc9167ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filePath = data/dump/h_prime_BERT-GAT_train.pkl\n",
    "#            data/dump/h_prime_BERT-GAT_test.pkl\n",
    "#            data/dump/h_prime_BERT-GAT_valid.pkl\n",
    "def get_EGAT_representations(filePath, contextualEmbeddings, edgeIndices, edgeTypes):\n",
    "#     checkFile = os.path.isfile(\"data/dump/h_prime_BERT-EGAT_train.pkl\")\n",
    "    if key:\n",
    "        print(\"Start of getting output of 2nd GAT\")\n",
    "        inferredEdgetypes = []\n",
    "        allNodeFeats = []\n",
    "\n",
    "        # Iterate over each dialogue\n",
    "        for dialog_id in range(len(contextualEmbeddings)):\n",
    "            # Create a DGL graph\n",
    "            graph = dgl.graph((edgeIndices[dialog_id][0], edgeIndices[dialog_id][1]))\n",
    "\n",
    "            # Get one-hot encoded edge features\n",
    "            edge_feats = get_ohe(edgeTypes[dialog_id])\n",
    "\n",
    "            # Get outputs from the second GAT layer\n",
    "            egat_output = egat(graph, contextualEmbeddings[dialog_id], edge_feats)\n",
    "            new_node_feats, new_edge_feats = egat_output\n",
    "\n",
    "            # Compute mean edge features\n",
    "            mean_edge_feats = new_edge_feats.mean(dim=1)\n",
    "            allNodeFeats.append(new_node_feats.mean(dim=1).tolist())\n",
    "\n",
    "            # Prepare edge features for inference\n",
    "            target_nodes = edgeIndices[dialog_id][1].tolist()\n",
    "            sample_edgetypes = {}\n",
    "            for i in set(target_nodes):\n",
    "                sample_edgetypes[i] = []\n",
    "            for target_node, edge_idx in zip(target_nodes, range(len(target_nodes))):\n",
    "                sample_edgetypes[target_node].append([edge_idx, \n",
    "                                                      mean_edge_feats[edge_idx].tolist()])\n",
    "\n",
    "            # Infer edge types\n",
    "            sample_edgetypes = get_inferred_edgetypes_EGAT(sample_edgetypes, edgeTypes[dialog_id], \n",
    "                                                           len(contextualEmbeddings[dialog_id]), \n",
    "                                                           dialog_id)\n",
    "            inferredEdgetypes.append(sample_edgetypes)\n",
    "\n",
    "        # Flatten and convert node features to tensor\n",
    "        allNodeFeats = torch.tensor(flatten_extend(allNodeFeats))\n",
    "\n",
    "        print(\"End of getting output of 2nd GAT\")\n",
    "\n",
    "        # Save the data to a pickle file\n",
    "        pickle.dump([allNodeFeats, inferredEdgetypes], open(filePath, 'wb'))\n",
    "    else:\n",
    "        # Load data from the existing pickle file\n",
    "        file = open(filePath, 'rb')\n",
    "        all_node_feats, inferredEdgetypes = pickle.load(file)\n",
    "        file.close()\n",
    "\n",
    "    return allNodeFeats, inferredEdgetypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1a685431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of getting output of 2nd GAT\n",
      "End of getting output of 2nd GAT\n",
      "Start of getting output of 2nd GAT\n",
      "End of getting output of 2nd GAT\n"
     ]
    }
   ],
   "source": [
    "allNodeFeatsTrain, inferredEdgetypesTrain = get_EGAT_representations(\n",
    "                                        \"data/dump/h_prime_BERT-EGAT_train.pkl\",\n",
    "                                        contextualEmbeddingsTrain,\n",
    "                                        edgeIndicesTrain,\n",
    "                                        edgeTypesTrain\n",
    "                                )\n",
    "_, _ = get_EGAT_representations(\n",
    "        \"data/dump/h_prime_BERT-EGAT_test.pkl\",\n",
    "        contextualEmbeddingsTest,\n",
    "        edgeIndicesTest,\n",
    "        edgeTypesTest\n",
    ")\n",
    "#TODO do for the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "938645cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eda2 = pd.DataFrame(\n",
    "    {'edgetype': flatten_extend(inferredEdgetypesTrain),\n",
    "     'label': y_train,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2d83d383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crosstab Result:\n",
      " label        0    1    2     3     4    5     6\n",
      "edgetype                                       \n",
      "0           25    8    7    38   132   17    27\n",
      "1         1470  356  330  2261  5800  857  1457\n",
      "2            5    0    1    13    28    2     6\n",
      "The P-Value of the ChiSq Test is: 0.7689164857892765\n",
      "Variables are not correlated with each other\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame from your data (df_eda2)\n",
    "# Assuming df_eda2 is already defined\n",
    "\n",
    "# Crosstabulation\n",
    "CrosstabResult2 = pd.crosstab(index=df_eda2['edgetype'], columns=df_eda2['label'])\n",
    "print(\"Crosstab Result:\\n\", CrosstabResult2)\n",
    "\n",
    "# Performing Chi-squared test\n",
    "ChiSqResult2 = chi2_contingency(CrosstabResult2)\n",
    "\n",
    "# Print the p-value of the Chi-squared test\n",
    "print('The P-Value of the ChiSq Test is:', ChiSqResult2[1])\n",
    "\n",
    "# Interpret the p-value\n",
    "if ChiSqResult2[1] > 0.05:\n",
    "    print(\"Variables are not correlated with each other\")\n",
    "else:\n",
    "    print(\"Two variables are correlated\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0213c68a",
   "metadata": {},
   "source": [
    "Testing on 1 dialog data before scaling up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "84641d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Node Features Shape: torch.Size([14, 4, 768])\n",
      "New Edge Features Shape: torch.Size([50, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "dialog_id = 0\n",
    "\n",
    "# Create a DGL graph\n",
    "graph = dgl.graph((edgeIndicesTrain[dialog_id][0], edgeIndicesTrain[dialog_id][1]))\n",
    "\n",
    "# Obtain one-hot encoded edge features\n",
    "edge_feats = get_ohe(edgeTypesTrain[dialog_id])\n",
    "\n",
    "# Pass the graph, node representations, and edge features through the EGAT model\n",
    "newNodeFeats, newEdgeFeats = egat(graph, contextualEmbeddingsTrain[dialog_id], edge_feats)\n",
    "\n",
    "# Print the shapes of the new node and edge features\n",
    "print(\"New Node Features Shape:\", newNodeFeats.shape)\n",
    "print(\"New Edge Features Shape:\", newEdgeFeats.shape)\n",
    "\n",
    "# Calculate the mean of node features along the second dimension (number of nodes)\n",
    "h_prime_mean = newNodeFeats.mean(dim=1)\n",
    "\n",
    "# Assuming you want to select only a subset of labels for visualization\n",
    "utt_size = 13\n",
    "labels = torch.tensor(y_train[:utt_size+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0bbcf4d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert tensor to numpy array\n",
    "h_prime_np = h_prime_mean.detach().numpy()\n",
    "# Perform dimensionality reduction using t-SNE\n",
    "tsne = TSNE(n_components=2, perplexity=5, random_state=42)\n",
    "h_prime_tsne = tsne.fit_transform(h_prime_np)\n",
    "\n",
    "# Plot the node embeddings with different colors for each label\n",
    "plt.figure(figsize=(10, 8))\n",
    "for label, emotion in zip(range(len(label_decoder)), label_decoder): \n",
    "    indices = (labels == label).nonzero().squeeze()\n",
    "    plt.scatter(h_prime_tsne[indices, 0], h_prime_tsne[indices, 1], label=f'{emotion}')\n",
    "plt.title('Node Embeddings Visualization (t-SNE)', color=\"white\")\n",
    "plt.xlabel('Dimension 1', color=\"white\")\n",
    "plt.ylabel('Dimension 2', color=\"white\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9e75975a",
   "metadata": {},
   "outputs": [],
   "source": [
    "runTSNE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "851a250c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if runTSNE:\n",
    "    # Convert tensor to numpy array\n",
    "    h_prime_np = allNodeFeatsTrain.detach().numpy()\n",
    "    labels = torch.tensor(y_train)\n",
    "    \n",
    "    # List of perplexity values to loop over\n",
    "    perplexity_values = [30, 100]\n",
    "\n",
    "    # Loop over each perplexity value\n",
    "    for perplexity in perplexity_values:\n",
    "        # Initialize t-SNE with the current perplexity value\n",
    "        tsne = TSNE(n_components=2, perplexity=perplexity, random_state=42)\n",
    "\n",
    "        # Fit and transform the data using t-SNE\n",
    "        h_prime_tsne = tsne.fit_transform(h_prime_np)\n",
    "        print(h_prime_tsne.shape)\n",
    "        \n",
    "        # Plot the node embeddings with different colors for each label\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        for label, emotion in zip(range(len(label_decoder)), label_decoder): \n",
    "            indices = (labels == label).nonzero().squeeze()\n",
    "            plt.scatter(h_prime_tsne[indices, 0], h_prime_tsne[indices, 1], label=f'{emotion}')\n",
    "        plt.title(f'Node Embeddings Visualization (t-SNE) - Perplexity {perplexity}', color=\"white\")\n",
    "        plt.xlabel('Dimension 1', color=\"white\")\n",
    "        plt.ylabel('Dimension 2', color=\"white\")\n",
    "        plt.legend()\n",
    "        plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
