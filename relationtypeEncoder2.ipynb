{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c64aa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, os, pickle, sys, dgl\n",
    "import torch.nn.init as init\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Parameter\n",
    "from collections import Counter\n",
    "import dgl.function as fn\n",
    "from dgl.nn.functional import edge_softmax\n",
    "import pandas as pd\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.nn import RGCNConv, GraphConv\n",
    "from model import DialogueGCN_MELDModel, GraphNetwork_RGCN, GraphNetwork_GAT, \\\n",
    "GraphNetwork_GAT_EdgeFeat, GraphNetwork_GATv2, GraphNetwork_GATv2_EdgeFeat, GraphNetwork_RGAT\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from graph_context_dataset import GraphContextDataset\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f920f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "key=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db3f1f1",
   "metadata": {},
   "source": [
    "<b>Make sure to specify which dataset to use\n",
    "<br>\n",
    " - dataset_original\n",
    "<br>\n",
    " - dataset_drop_noise\n",
    "<br>\n",
    " - dataset_smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51747523",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"dataset_original\"\n",
    "dataset_path = \"dataset_drop_noise\"\n",
    "dataset_path = \"dataset_smote\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92939a4a",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# class GATLayerWithEdgeType(nn.Module):\n",
    "#     def __init__(self, num_in_features_per_head, num_out_features_per_head, num_heads, num_edge_types):\n",
    "#         super(GATLayerWithEdgeType, self).__init__()\n",
    "#         self.num_in_features_per_head = num_in_features_per_head\n",
    "#         self.num_out_features_per_head = num_out_features_per_head\n",
    "#         self.num_heads = num_heads\n",
    "#         self.num_edge_types = num_edge_types\n",
    "\n",
    "#         # Linear projection for node features\n",
    "#         torch.manual_seed(42)\n",
    "#         self.linear_proj = nn.Linear(self.num_in_features_per_head, self.num_heads * self.num_out_features_per_head)\n",
    "        \n",
    "#         # Edge type embeddings\n",
    "#         torch.manual_seed(42)\n",
    "#         self.edge_type_embedding = nn.Embedding(self.num_edge_types, self.num_heads)\n",
    "        \n",
    "#     def forward(self, input_data, edge_type):\n",
    "#         node_features, edge_indices = input_data\n",
    "\n",
    "#         # Linear projection for node features\n",
    "#         h_linear = self.linear_proj(node_features.view(-1, self.num_in_features_per_head))\n",
    "#         h_linear = h_linear.view(-1, self.num_heads, self.num_out_features_per_head)\n",
    "#         h_linear = h_linear.permute(0, 2, 1)\n",
    "\n",
    "#         # Edge type embedding\n",
    "#         edge_type_embedding = self.edge_type_embedding(edge_type).transpose(0, 1)\n",
    "\n",
    "#         # Perform matrix multiplication\n",
    "#         attention_scores = torch.matmul(h_linear, edge_type_embedding).squeeze(-1)\n",
    "\n",
    "#         # Softmax to get attention coefficients\n",
    "#         attention_coefficients = F.softmax(attention_scores, dim=-1)\n",
    "\n",
    "#         # Weighted sum of neighbor node representations\n",
    "#         updated_representation = torch.matmul(attention_coefficients.transpose(1, 2), h_linear).mean(dim=2)\n",
    "\n",
    "#         return updated_representation, attention_coefficients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8aa9fe91",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class EGATConv(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_node_feats,\n",
    "                 in_edge_feats,\n",
    "                 out_node_feats,\n",
    "                 out_edge_feats,\n",
    "                 num_heads,\n",
    "                 bias=True,\n",
    "                 **kw_args):\n",
    "\n",
    "        super().__init__()\n",
    "        self._num_heads = num_heads\n",
    "        self._out_node_feats = out_node_feats\n",
    "        self._out_edge_feats = out_edge_feats\n",
    "        \n",
    "        self.fc_node = nn.Linear(in_node_feats, out_node_feats * num_heads, bias=bias)\n",
    "        self.fc_ni = nn.Linear(in_node_feats, out_edge_feats * num_heads, bias=False)\n",
    "        self.fc_fij = nn.Linear(in_edge_feats, out_edge_feats * num_heads, bias=False)\n",
    "        self.fc_nj = nn.Linear(in_node_feats, out_edge_feats * num_heads, bias=False)\n",
    "        \n",
    "        # Attention parameter\n",
    "        self.attn = nn.Parameter(torch.FloatTensor(size=(1, num_heads, out_edge_feats)))\n",
    "        \n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.FloatTensor(size=(num_heads * out_edge_feats,)))\n",
    "        else:\n",
    "            self.register_buffer('bias', None)\n",
    "        \n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        torch.manual_seed(42)\n",
    "        gain = init.calculate_gain('relu')\n",
    "        init.xavier_normal_(self.fc_node.weight, gain=gain)\n",
    "        init.xavier_normal_(self.fc_ni.weight, gain=gain)\n",
    "        init.xavier_normal_(self.fc_fij.weight, gain=gain)\n",
    "        init.xavier_normal_(self.fc_nj.weight, gain=gain)\n",
    "        init.xavier_normal_(self.attn, gain=gain)\n",
    "        \n",
    "        if self.bias is not None:\n",
    "            nn.init.constant_(self.bias, 0)\n",
    "\n",
    "    def forward(self, graph, nfeats, efeats, get_attention=False):\n",
    "        with graph.local_scope():\n",
    "            graph.edata['f'] = efeats\n",
    "            graph.ndata['h'] = nfeats\n",
    "            \n",
    "            f_ni = self.fc_ni(nfeats)\n",
    "            f_nj = self.fc_nj(nfeats)\n",
    "            f_fij = self.fc_fij(efeats)\n",
    "            graph.srcdata.update({'f_ni' : f_ni})\n",
    "            graph.dstdata.update({'f_nj' : f_nj})\n",
    "            \n",
    "            graph.apply_edges(fn.u_add_v('f_ni', 'f_nj', 'f_tmp'))\n",
    "            f_out = graph.edata.pop('f_tmp') + f_fij\n",
    "            \n",
    "            if self.bias is not None:\n",
    "                f_out += self.bias\n",
    "            f_out = nn.functional.leaky_relu(f_out)\n",
    "            f_out = f_out.view(-1, self._num_heads, self._out_edge_feats)\n",
    "            \n",
    "            e = (f_out * self.attn).sum(dim=-1).unsqueeze(-1)\n",
    "            graph.edata['a'] = edge_softmax(graph, e)\n",
    "            graph.ndata['h_out'] = self.fc_node(nfeats).view(-1, self._num_heads, self._out_node_feats)\n",
    "            \n",
    "            graph.update_all(fn.u_mul_e('h_out', 'a', 'm'), fn.sum('m', 'h_out'))\n",
    "\n",
    "            h_out = graph.ndata['h_out'].view(-1, self._num_heads, self._out_node_feats)\n",
    "            if get_attention:\n",
    "                return h_out, f_out, graph.edata.pop('a')\n",
    "            else:\n",
    "                return h_out, f_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7adf37e",
   "metadata": {
    "code_folding": [
     0,
     11,
     37,
     68
    ]
   },
   "outputs": [],
   "source": [
    "def get_ohe(edge_types):\n",
    "    one_hot_encoding = []\n",
    "    for edge_type in edge_types:\n",
    "        if edge_type == 0:\n",
    "            one_hot_encoding.append([1., 0., 0.])\n",
    "        elif edge_type == 1:\n",
    "            one_hot_encoding.append([0., 1., 0.])\n",
    "        elif edge_type == 2:\n",
    "            one_hot_encoding.append([0., 0., 1.])\n",
    "    return torch.tensor(one_hot_encoding)\n",
    "\n",
    "def get_inferred_edgetypes_GAT(dialog, edge_types):\n",
    "    inferred_edge_types = []\n",
    "    inferred_edge_indices = []\n",
    "    delta_t = []\n",
    "    for target_node in dialog.values():\n",
    "        if len(target_node) == 1:\n",
    "            inferred_edge_types.append(0)\n",
    "            inferred_edge_indices.append(0)\n",
    "            delta_t.append(0)\n",
    "        else:\n",
    "            edge_index = target_node[0][0]\n",
    "            highest_attention = target_node[0][1]\n",
    "            \n",
    "            i=0\n",
    "            t=i\n",
    "            for src_node in target_node[1:]:\n",
    "                if highest_attention < src_node[1]:\n",
    "                    highest_attention = src_node[1]\n",
    "                    edge_index = src_node[0]\n",
    "                    t=i\n",
    "                i=1+1\n",
    "            delta_t.append(t)\n",
    "            inferred_edge_indices.append(edge_index)\n",
    "            inferred_edge_types.append(edge_types[edge_index].tolist())\n",
    "    return inferred_edge_indices, inferred_edge_types, delta_t\n",
    "\n",
    "def get_inferred_edgetypes_EGAT(edges_target_nodes, sample_edge_types, size_dialog, dialog_id):\n",
    "    inferred_edge_types = []\n",
    "    delta_t = []\n",
    "    for target_idx in range(size_dialog):\n",
    "        num_edges = len(edges_target_nodes[target_idx])\n",
    "        if num_edges == 1:\n",
    "            edgetype_idx = np.argmax(edges_target_nodes[target_idx][0][1])\n",
    "            edge_idx = edges_target_nodes[target_idx][0][0]\n",
    "            inferred_edge_types.append(edgetype_idx)\n",
    "            delta_t.append(0)\n",
    "\n",
    "        else:\n",
    "            highest_attn_score = max(edges_target_nodes[target_idx][0][1])\n",
    "            edgetype_idx = np.argmax(edges_target_nodes[target_idx][0][1])\n",
    "            edge_idx = edges_target_nodes[target_idx][0][0]\n",
    "            \n",
    "            i=0\n",
    "            t=i\n",
    "            for sample_edge in range(1, num_edges):\n",
    "                cur_highest_attn_score = max(edges_target_nodes[target_idx][sample_edge][1])\n",
    "                if cur_highest_attn_score > highest_attn_score:\n",
    "                    highest_attn_score = cur_highest_attn_score\n",
    "                    edgetype_idx = np.argmax(edges_target_nodes[target_idx][sample_edge][1])\n",
    "                    edge_idx = edges_target_nodes[target_idx][sample_edge][0]\n",
    "                    t=i\n",
    "                i=1+i\n",
    "                \n",
    "            delta_t.append(t)        \n",
    "            inferred_edge_types.append(edgetype_idx)\n",
    "    return inferred_edge_types, delta_t\n",
    "\n",
    "def flatten_extend(matrix):\n",
    "    flat_list = []\n",
    "    for row in matrix:\n",
    "        flat_list.extend(row)\n",
    "    return flat_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7639e77",
   "metadata": {
    "code_folding": [
     0,
     15,
     25,
     40
    ]
   },
   "outputs": [],
   "source": [
    "def create_node_pairs_list(start_idx, end_idx):\n",
    "    list_node_i = []\n",
    "    list_node_j = []\n",
    "    end_idx = end_idx - start_idx\n",
    "    start_idx = 0\n",
    "    for i in range(start_idx, end_idx+1):\n",
    "        val = 0\n",
    "        while (val <= 3) and (i+val <= end_idx):\n",
    "            target_idx = i+val\n",
    "            if target_idx >= 0:\n",
    "                list_node_i.append(i)\n",
    "                list_node_j.append(target_idx)\n",
    "            val = val+1\n",
    "    return [list_node_i, list_node_j]\n",
    "\n",
    "def create_adjacency_dict(node_pairs):\n",
    "    adjacency_list_dict = {}\n",
    "    for i in range(0, len(node_pairs[0])):\n",
    "        source_node, target_node = node_pairs[0][i], node_pairs[1][i]\n",
    "        if source_node not in adjacency_list_dict:\n",
    "            adjacency_list_dict[source_node] = [target_node]\n",
    "        else:\n",
    "            adjacency_list_dict[source_node].append(target_node)\n",
    "    return adjacency_list_dict\n",
    "\n",
    "def get_all_adjacency_list(ranges, key=0):\n",
    "    all_adjacency_list = []\n",
    "    for range_pair in ranges:\n",
    "        start_idx, end_idx = range_pair\n",
    "        if key == 0:\n",
    "            output = create_node_pairs_list(start_idx, end_idx)\n",
    "            output = create_adjacency_dict(output)\n",
    "        elif key == 1:\n",
    "            output = create_node_pairs_list(start_idx, end_idx)\n",
    "            output = torch.tensor(output)\n",
    "        else:\n",
    "            print(\"N/A\")\n",
    "        all_adjacency_list.append(output)\n",
    "    return all_adjacency_list\n",
    "\n",
    "def get_all_edge_type_list(edge_indices, encoded_speaker_list):\n",
    "    dialogs_len = len(edge_indices)\n",
    "    whole_edge_type_list = []\n",
    "    for i in range(dialogs_len):\n",
    "        dialog_nodes_pairs = edge_indices[i]\n",
    "        dialog_speakers = list(encoded_speaker_list[i])\n",
    "        dialog_len = len(dialog_nodes_pairs.keys())\n",
    "        edge_type_list = []\n",
    "        for j in range(dialog_len):\n",
    "            src_node = dialog_nodes_pairs[j]\n",
    "            node_i_idx = j\n",
    "            win_len = len(src_node)\n",
    "            for k in range(win_len):\n",
    "                node_j_idx = src_node[k]\n",
    "                if node_i_idx == node_j_idx:\n",
    "                    edge_type_list.append(0)\n",
    "                else:\n",
    "                    if dialog_speakers[node_i_idx] != dialog_speakers[node_j_idx]:\n",
    "                        edge_type_list.append(1)\n",
    "                    else:\n",
    "                        edge_type_list.append(2)\n",
    "        whole_edge_type_list.append(torch.tensor(edge_type_list).to(torch.int64))\n",
    "    return whole_edge_type_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4cf0f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=100):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91faed3",
   "metadata": {},
   "source": [
    "<h3> Data Preparetion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0006630b",
   "metadata": {},
   "source": [
    "<h4> Creating graph features from Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d8a8f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkFile = os.path.isfile(\"data/dump/speaker_encoder_train.pkl\")\n",
    "encodedSpeakersTrain = []\n",
    "rangesTrain = []\n",
    "\n",
    "if not checkFile:\n",
    "    print(\"Run first the contextEncoder2 to generate this file\")\n",
    "else:\n",
    "    with open('data/dump/speaker_encoder_train.pkl', \"rb\") as file:\n",
    "        encodedSpeakersTrain, rangesTrain = pickle.load(file)\n",
    "\n",
    "checkFile = os.path.isfile(\"data/dump/adjListTrain.pkl\")\n",
    "adjacencyListTrain = []\n",
    "\n",
    "if key:\n",
    "    adjacencyListTrain = get_all_adjacency_list(rangesTrain)\n",
    "else:\n",
    "    with open('data/dump/adjListTrain', \"rb\") as file:\n",
    "        adjacencyListTrain = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "771b8350",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'embed/u_prime_BERT_train.pkl'\n",
    "\n",
    "# Load the list from the file using pickle\n",
    "with open(file_path, 'rb') as file:\n",
    "    contextualEmbeddingsTrain = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6055971",
   "metadata": {},
   "outputs": [],
   "source": [
    "edgeIndicesTrain = get_all_adjacency_list(rangesTrain)\n",
    "edgeTypesTrain = get_all_edge_type_list(edgeIndicesTrain, encodedSpeakersTrain)\n",
    "edgeIndicesTrain = get_all_adjacency_list(rangesTrain, key=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469c67ff",
   "metadata": {},
   "source": [
    "<h4> Creating graph features from Test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df15e1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkFile = os.path.isfile(\"data/dump/speaker_encoder_test.pkl\")\n",
    "encodedSpeakersTest = []\n",
    "rangesTest = []\n",
    "\n",
    "if not checkFile:\n",
    "    print(\"Run first the contextEncoder2 to generate this file\")\n",
    "else:\n",
    "    with open('data/dump/speaker_encoder_test.pkl', \"rb\") as file:\n",
    "        encodedSpeakersTest, rangesTest = pickle.load(file)\n",
    "\n",
    "checkFile = os.path.isfile(\"data/dump/adjListTest.pkl\")\n",
    "adjacencyListTest = []\n",
    "\n",
    "if key:\n",
    "    adjacencyListTest = get_all_adjacency_list(rangesTest)\n",
    "else:\n",
    "    with open('data/dump/adjListTest', \"rb\") as file:\n",
    "        adjacencyListTest = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7ef966f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'embed/u_prime_BERT_test.pkl'\n",
    "\n",
    "# Load the list from the file using pickle\n",
    "with open(file_path, 'rb') as file:\n",
    "    contextualEmbeddingsTest = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17973a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "edgeIndicesTest = get_all_adjacency_list(rangesTest)\n",
    "edgeTypesTest = get_all_edge_type_list(edgeIndicesTest, encodedSpeakersTest)\n",
    "edgeIndicesTest = get_all_adjacency_list(rangesTest, key=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d14cedb",
   "metadata": {},
   "source": [
    "<h4> Creating graph features from Test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2ffa59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO repeat the one above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a44f59",
   "metadata": {},
   "source": [
    "<h3> Get GAT output from each set of data (train, test, validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c36c94f",
   "metadata": {},
   "source": [
    "<h4> Instantiating the GAT (1st implementation) for 1 sample train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6efaf2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contextualEmbeddingsTrain:  torch.Size([14, 768])\n",
      "edgeIndicesTrain:  torch.Size([2, 50])\n",
      "edgeTypesTrain:  torch.Size([50])\n"
     ]
    }
   ],
   "source": [
    "print(\"contextualEmbeddingsTrain: \", contextualEmbeddingsTrain[0].size())\n",
    "print(\"edgeIndicesTrain: \", edgeIndicesTrain[0].size())\n",
    "print(\"edgeTypesTrain: \", edgeTypesTrain[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a62de7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98a8775c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_in_features = len(contextualEmbeddingsTrain[0][0])\n",
    "# num_out_features = len(contextualEmbeddingsTrain[0][0])\n",
    "# num_heads = 4\n",
    "# num_edge_types = 3\n",
    "# print(\"num_in_features length: \",num_in_features)\n",
    "# print(\"num_out_features length: \",num_out_features)\n",
    "# print(\"num_heads: \", num_heads)\n",
    "# print(\"num_edge_types: \",num_edge_types)\n",
    "# gat_layer = GATLayerWithEdgeType(num_in_features, num_out_features, num_heads, num_edge_types)\n",
    "\n",
    "# i = 0  # dialogue id\n",
    "# print(\"contextualEmbeddingsTrain[i].shape: \",contextualEmbeddingsTrain[i].shape) \n",
    "# print(\"edgeIndicesTrain[0].shape: \", edgeIndicesTrain[i].shape)\n",
    "# print(\"edgeTypesTrain[0].shape: \", edgeTypesTrain[i].shape)\n",
    "# relationalEmbedding, attentionCoef = gat_layer((contextualEmbeddingsTrain[i], edgeIndicesTrain[i]), edgeTypesTrain[i])\n",
    "# print(\"relationalEmbedding.shape: \", relationalEmbedding.shape, \"attentionCoef.shape: \", attentionCoef.shape)\n",
    "\n",
    "# targetNodes = edgeIndicesTrain[i][1].tolist()\n",
    "\n",
    "# sample = {}\n",
    "# sampleEdgetypes = []\n",
    "\n",
    "# for target_i in sorted(set(targetNodes)):\n",
    "#     sample[target_i] = []\n",
    "\n",
    "# for targetNode, idx in zip(targetNodes, range(len(targetNodes))):\n",
    "#     sample[targetNode].append([idx, relationalEmbedding[targetNode][idx].tolist()])\n",
    "\n",
    "# listEdgeIdxTrain, inferredEdgeTypes, delta_t = get_inferred_edgetypes_GAT(sample, edgeTypesTrain[i])\n",
    "# sampleEdgetypes.append(inferredEdgeTypes)\n",
    "# print(delta_t)\n",
    "# # Therefore, the expected shapes are indeed correct: \n",
    "# # relationalEmbedding with shape [14, 768] and attentionCoef with shape [14, 4, 50]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce59c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# edgeIndicesTrain[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48560f8d",
   "metadata": {},
   "source": [
    "0, 0, 2, 2, 2, 2, 2, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdac7e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "258b7da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anger', 'disgust', 'fear', 'joy', 'neutral', 'sadness', 'surprise']\n"
     ]
    }
   ],
   "source": [
    "file = open('data/dump/label_decoder.pkl', 'rb')\n",
    "label_decoder = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "label_decoder = list(label_decoder.values())\n",
    "print(label_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4ed00de",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkFile = os.path.isfile(\"data/dump/labels_train.pkl\")\n",
    "\n",
    "if checkFile is False:\n",
    "    print(\"Please run the contextEncoder2 notebook to save the label file\")\n",
    "else:\n",
    "    file = open('data/dump/labels_train.pkl', 'rb')\n",
    "    y_train = pickle.load(file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5394940",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkFile = os.path.isfile(\"data/dump/labels_test.pkl\")\n",
    "\n",
    "if checkFile is False:\n",
    "    print(\"Please run the contextEncoder2 notebook to save the label file\")\n",
    "else:\n",
    "    file = open('data/dump/labels_test.pkl', 'rb')\n",
    "    y_test = pickle.load(file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42223125",
   "metadata": {},
   "source": [
    "<h4> Visualize 1 instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a41a39",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# # Assuming h_prime contains the node embeddings\n",
    "# utt_size = 13\n",
    "# labels = torch.tensor(y_train[:utt_size + 1])\n",
    "\n",
    "# cherrypicked_nodes = []\n",
    "# for src_idx, edge_idx in zip(range(len(list_edge_idx)), list_edge_idx):\n",
    "#     cherrypicked_nodes.append(attention_coef[src_idx, :, edge_idx].tolist())\n",
    "# cherrypicked_nodes = torch.tensor(cherrypicked_nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a97231",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# h_prime_np = cherrypicked_nodes.detach().numpy()\n",
    "\n",
    "# # Perform dimensionality reduction using t-SNE\n",
    "# tsne = TSNE(n_components=3, perplexity=5, random_state=42)\n",
    "# h_prime_tsne = tsne.fit_transform(h_prime_np)\n",
    "\n",
    "# # Plot the node embeddings with different colors for each label\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# for label, emotion in zip(range(len(label_decoder)), label_decoder): \n",
    "#     indices = (labels == label).nonzero().squeeze()\n",
    "#     plt.scatter(h_prime_tsne[indices, 0], h_prime_tsne[indices, 1], label=f'{emotion}')\n",
    "# plt.title('Node Embeddings Visualization (t-SNE)', color=\"white\")\n",
    "# plt.xlabel('Dimension 1', color=\"white\")\n",
    "# plt.ylabel('Dimension 2', color=\"white\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8043a6a",
   "metadata": {},
   "source": [
    "<h4>Now get new representations of all train, test, validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588776d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # filePath = data/dump/h_prime_BERT-GAT_train.pkl\n",
    "# #            data/dump/h_prime_BERT-GAT_test.pkl\n",
    "# #            data/dump/h_prime_BERT-GAT_valid.pkl\n",
    "\n",
    "# def get_GAT_representation(filePath, contextualEmbeddings, edgeIndices, edgeTypes):\n",
    "# #     checkFile = os.path.isfile(\"data/dump/h_prime_BERT-GAT_train.pkl\") #replace it with key when deployed\n",
    "#     if key:\n",
    "#         print(\"Start of getting output of 1st GAT\")\n",
    "#         allInferredEdgetypes = []\n",
    "#         listAllEdgeIdx = []\n",
    "#         cherrypickedNodes = []\n",
    "#         for dialog, dialog_id in zip(contextualEmbeddings, range(len(contextualEmbeddings))):\n",
    "#             h_prime, attention_coef = gat_layer((dialog, edgeIndices[dialog_id]), edgeTypes[dialog_id])\n",
    "#             target_nodes = edgeIndices[dialog_id][1].tolist() # first idx represents dialogue id\n",
    "\n",
    "#             sample_edgetypes = {}\n",
    "#             for i in set(target_nodes):\n",
    "#                 sample_edgetypes[i] = []\n",
    "\n",
    "#             for target_node, edge_idx in zip(target_nodes, range(len(target_nodes))):\n",
    "#                 sample_edgetypes[target_node].append([edge_idx, h_prime[target_node][edge_idx].tolist()])\n",
    "\n",
    "#             list_edge_idx, inferred_edgetypes, _ = get_inferred_edgetypes_GAT(sample_edgetypes,  edgeTypes[dialog_id])\n",
    "#             listAllEdgeIdx.append(list_edge_idx)\n",
    "#             allInferredEdgetypes.append(inferred_edgetypes)\n",
    "\n",
    "#             for src_idx, edge_idx in zip(range(len(list_edge_idx)), list_edge_idx):\n",
    "#                 cherrypickedNodes.append(attention_coef[src_idx, :, edge_idx].tolist())\n",
    "\n",
    "#         cherrypickedNodes = torch.tensor(cherrypickedNodes)\n",
    "#         cherrypickedNodes.shape\n",
    "#         print(\"End of getting output of 1st GAT\")\n",
    "\n",
    "#         pickle.dump([cherrypickedNodes, allInferredEdgetypes],\n",
    "#                     open(filePath, 'wb'))\n",
    "\n",
    "#     else:\n",
    "#         file = open(filePath, 'rb')\n",
    "#         cherrypickedNodes, allInferredEdgetypes = pickle.load(file)\n",
    "#         file.close()\n",
    "\n",
    "#     return cherrypickedNodes, allInferredEdgetypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d7c89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train data\n",
    "# cherrypickedNodesTrain, allInferredEdgetypesTrain = get_GAT_representation(\n",
    "#                                                     \"embed/h_prime_BERT-GAT_train.pkl\",\n",
    "#                                                     contextualEmbeddingsTrain,\n",
    "#                                                     edgeIndicesTrain,\n",
    "#                                                     edgeTypesTrain)\n",
    "# # only save the pickle data for test and validation\n",
    "# _, _ = get_GAT_representation(\"embed/h_prime_BERT-GAT_test.pkl\",\n",
    "#                         contextualEmbeddingsTest,\n",
    "#                         edgeIndicesTest,\n",
    "#                         edgeTypesTest)\n",
    "# # TODO add valid set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5fbe0a",
   "metadata": {},
   "source": [
    "<h5> Visualize Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "548c237c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = torch.tensor(y_train)\n",
    "# h_prime_np = cherrypickedNodesTrain.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "74050dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# runTSNE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d86332b",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# if runTSNE:\n",
    "#     # List of perplexity values to loop over\n",
    "#     perplexity_values = [30, 100]\n",
    "\n",
    "#     # Loop over each perplexity value\n",
    "#     for perplexity in perplexity_values:\n",
    "#         # Initialize t-SNE with the current perplexity value\n",
    "#         tsne = TSNE(n_components=2, perplexity=perplexity, random_state=42)\n",
    "\n",
    "#         # Fit and transform the data using t-SNE\n",
    "#         h_prime_tsne = tsne.fit_transform(h_prime_np)\n",
    "\n",
    "#         # Plot the node embeddings with different colors for each label\n",
    "#         plt.figure(figsize=(10, 8))\n",
    "#         for label, emotion in zip(range(len(label_decoder)), label_decoder): \n",
    "#             indices = (labels == label).nonzero().squeeze()\n",
    "#             plt.scatter(h_prime_tsne[indices, 0], h_prime_tsne[indices, 1], label=f'{emotion}')\n",
    "#         plt.title(f'Node Embeddings Visualization (t-SNE) - Perplexity {perplexity}', color=\"white\")\n",
    "#         plt.xlabel('Dimension 1', color=\"white\")\n",
    "#         plt.ylabel('Dimension 2', color=\"white\")\n",
    "#         plt.legend()\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5caea68",
   "metadata": {},
   "source": [
    "<h5> Analyze the edgetypes of all train nodes in the context of a dialog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c236b455",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# # Assuming `all_inferred_edgetypes` and `y_train` are defined\n",
    "# df_eda = pd.DataFrame(\n",
    "#     {'edgetype': flatten_extend(allInferredEdgetypesTrain),\n",
    "#      'label': y_train,\n",
    "#     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "46b7f357",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# # Assuming `df_eda` and `CrosstabResult` are defined\n",
    "# CrosstabResult = pd.crosstab(index=df_eda['edgetype'], columns=df_eda['label'])\n",
    "\n",
    "# print(\"Crosstab Result:\")\n",
    "# print(CrosstabResult)\n",
    "# print()\n",
    "\n",
    "# # Performing Chi-squared test\n",
    "# ChiSqResult = chi2_contingency(CrosstabResult)\n",
    "\n",
    "# # P-Value is the Probability of H0 being True\n",
    "# # If P-Value > 0.05 then only we Accept the assumption(H0)\n",
    "# # H0: The variables are not correlated with each other.\n",
    "\n",
    "# print('The P-Value of the Chi-Squared Test is:', ChiSqResult[1])\n",
    "\n",
    "# if ChiSqResult[1] > 0.05:\n",
    "#     print(\"Variables are not correlated with each other\")\n",
    "# else:\n",
    "#     print(\"Two variables are correlated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540cb0a7",
   "metadata": {},
   "source": [
    "<h3> Get EGAT output from each set of data (train, test, validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "60061c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "egat = EGATConv(in_node_feats=len(contextualEmbeddingsTrain[0][0]),\n",
    "                    in_edge_feats=3,\n",
    "                    out_node_feats=len(contextualEmbeddingsTrain[0][0]),\n",
    "                    out_edge_feats=3,\n",
    "                    num_heads=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cc9167ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filePath = data/dump/h_prime_BERT-GAT_train.pkl\n",
    "#            data/dump/h_prime_BERT-GAT_test.pkl\n",
    "#            data/dump/h_prime_BERT-GAT_valid.pkl\n",
    "def get_EGAT_representations(filePath, contextualEmbeddings, edgeIndices, edgeTypes):\n",
    "#     checkFile = os.path.isfile(\"data/dump/h_prime_BERT-EGAT_train.pkl\")\n",
    "    if key:\n",
    "        print(\"Start of getting output of 2nd GAT\")\n",
    "        inferredEdgetypes = []\n",
    "        allNodeFeats = []\n",
    "\n",
    "        # Iterate over each dialogue\n",
    "        for dialog_id in range(len(contextualEmbeddings)):\n",
    "            # Create a DGL graph\n",
    "            graph = dgl.graph((edgeIndices[dialog_id][0], edgeIndices[dialog_id][1]))\n",
    "\n",
    "            # Get one-hot encoded edge features\n",
    "            edge_feats = get_ohe(edgeTypes[dialog_id])\n",
    "\n",
    "            # Get outputs from the second GAT layer\n",
    "            egat_output = egat(graph, contextualEmbeddings[dialog_id], edge_feats)\n",
    "            new_node_feats, new_edge_feats = egat_output\n",
    "\n",
    "            # Compute mean edge features\n",
    "            mean_edge_feats = new_edge_feats.mean(dim=1)\n",
    "            allNodeFeats.append(new_node_feats.mean(dim=1).tolist())\n",
    "\n",
    "            # Prepare edge features for inference\n",
    "            target_nodes = edgeIndices[dialog_id][1].tolist()\n",
    "            sample_edgetypes = {}\n",
    "            for i in set(target_nodes):\n",
    "                sample_edgetypes[i] = []\n",
    "            for target_node, edge_idx in zip(target_nodes, range(len(target_nodes))):\n",
    "                sample_edgetypes[target_node].append([edge_idx, \n",
    "                                                      mean_edge_feats[edge_idx].tolist()])\n",
    "\n",
    "            # Infer edge types\n",
    "            sample_edgetypes, _ = get_inferred_edgetypes_EGAT(sample_edgetypes, edgeTypes[dialog_id], \n",
    "                                                           len(contextualEmbeddings[dialog_id]), \n",
    "                                                           dialog_id)\n",
    "            inferredEdgetypes.append(sample_edgetypes)\n",
    "\n",
    "        # Flatten and convert node features to tensor\n",
    "        allNodeFeats = torch.tensor(flatten_extend(allNodeFeats))\n",
    "\n",
    "        print(\"End of getting output of 2nd GAT\")\n",
    "\n",
    "        # Save the data to a pickle file\n",
    "        pickle.dump([allNodeFeats, inferredEdgetypes], open(filePath, 'wb'))\n",
    "    else:\n",
    "        # Load data from the existing pickle file\n",
    "        file = open(filePath, 'rb')\n",
    "        all_node_feats, inferredEdgetypes = pickle.load(file)\n",
    "        file.close()\n",
    "\n",
    "    return allNodeFeats, inferredEdgetypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "90375255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2160\n",
      "2160\n",
      "2160\n"
     ]
    }
   ],
   "source": [
    "print(len(contextualEmbeddingsTrain))\n",
    "print(len(edgeIndicesTrain))\n",
    "print(len(edgeTypesTrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1a685431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of getting output of 2nd GAT\n",
      "End of getting output of 2nd GAT\n",
      "Start of getting output of 2nd GAT\n",
      "End of getting output of 2nd GAT\n"
     ]
    }
   ],
   "source": [
    "allNodeFeatsTrain, inferredEdgetypesTrain = get_EGAT_representations(\n",
    "                                        \"embed/h_prime_BERT-EGAT_train.pkl\",\n",
    "                                        contextualEmbeddingsTrain,\n",
    "                                        edgeIndicesTrain,\n",
    "                                        edgeTypesTrain\n",
    "                                )\n",
    "_, _ = get_EGAT_representations(\n",
    "        \"embed/h_prime_BERT-EGAT_test.pkl\",\n",
    "        contextualEmbeddingsTest,\n",
    "        edgeIndicesTest,\n",
    "        edgeTypesTest\n",
    ")\n",
    "#TODO do for the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "938645cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eda2 = pd.DataFrame(\n",
    "    {'edgetype': flatten_extend(inferredEdgetypesTrain),\n",
    "     'label': y_train,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2d83d383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crosstab Result:\n",
      " label        0    1    2     3     4    5     6\n",
      "edgetype                                       \n",
      "0            1    0    0     2     5    2     2\n",
      "1         1499  364  338  2310  5955  874  1488\n",
      "The P-Value of the ChiSq Test is: 0.8318329952175869\n",
      "Variables are not correlated with each other\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame from your data (df_eda2)\n",
    "# Assuming df_eda2 is already defined\n",
    "\n",
    "# Crosstabulation\n",
    "CrosstabResult2 = pd.crosstab(index=df_eda2['edgetype'], columns=df_eda2['label'])\n",
    "print(\"Crosstab Result:\\n\", CrosstabResult2)\n",
    "\n",
    "# Performing Chi-squared test\n",
    "ChiSqResult2 = chi2_contingency(CrosstabResult2)\n",
    "\n",
    "# Print the p-value of the Chi-squared test\n",
    "print('The P-Value of the ChiSq Test is:', ChiSqResult2[1])\n",
    "\n",
    "# Interpret the p-value\n",
    "if ChiSqResult2[1] > 0.05:\n",
    "    print(\"Variables are not correlated with each other\")\n",
    "else:\n",
    "    print(\"Two variables are correlated\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0213c68a",
   "metadata": {},
   "source": [
    "Testing on 1 dialog data before scaling up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "84641d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Node Features Shape: torch.Size([14, 4, 768])\n",
      "New Edge Features Shape: torch.Size([50, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "dialog_id = 0\n",
    "\n",
    "# Create a DGL graph\n",
    "graph = dgl.graph((edgeIndicesTrain[dialog_id][0], edgeIndicesTrain[dialog_id][1]))\n",
    "\n",
    "# Obtain one-hot encoded edge features\n",
    "edge_feats = get_ohe(edgeTypesTrain[dialog_id])\n",
    "\n",
    "# Pass the graph, node representations, and edge features through the EGAT model\n",
    "newNodeFeats, newEdgeFeats = egat(graph, contextualEmbeddingsTrain[dialog_id], edge_feats)\n",
    "\n",
    "# Print the shapes of the new node and edge features\n",
    "print(\"New Node Features Shape:\", newNodeFeats.shape)\n",
    "print(\"New Edge Features Shape:\", newEdgeFeats.shape)\n",
    "\n",
    "# Calculate the mean of node features along the second dimension (number of nodes)\n",
    "h_prime_mean = newNodeFeats.mean(dim=1)\n",
    "\n",
    "# Assuming you want to select only a subset of labels for visualization\n",
    "utt_size = 13\n",
    "labels = torch.tensor(y_train[:utt_size+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbcf4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert tensor to numpy array\n",
    "h_prime_np = h_prime_mean.detach().numpy()\n",
    "# Perform dimensionality reduction using t-SNE\n",
    "tsne = TSNE(n_components=2, perplexity=5, random_state=42)\n",
    "h_prime_tsne = tsne.fit_transform(h_prime_np)\n",
    "\n",
    "# Plot the node embeddings with different colors for each label\n",
    "plt.figure(figsize=(10, 8))\n",
    "for label, emotion in zip(range(len(label_decoder)), label_decoder): \n",
    "    indices = (labels == label).nonzero().squeeze()\n",
    "    plt.scatter(h_prime_tsne[indices, 0], h_prime_tsne[indices, 1], label=f'{emotion}')\n",
    "plt.title('Node Embeddings Visualization (t-SNE)', color=\"white\")\n",
    "plt.xlabel('Dimension 1', color=\"white\")\n",
    "plt.ylabel('Dimension 2', color=\"white\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e75975a",
   "metadata": {},
   "outputs": [],
   "source": [
    "runTSNE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851a250c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if runTSNE:\n",
    "    # Convert tensor to numpy array\n",
    "    h_prime_np = allNodeFeatsTrain.detach().numpy()\n",
    "    labels = torch.tensor(y_train)\n",
    "    \n",
    "    # List of perplexity values to loop over\n",
    "    perplexity_values = [30, 100]\n",
    "\n",
    "    # Loop over each perplexity value\n",
    "    for perplexity in perplexity_values:\n",
    "        # Initialize t-SNE with the current perplexity value\n",
    "        tsne = TSNE(n_components=2, perplexity=perplexity, random_state=42)\n",
    "\n",
    "        # Fit and transform the data using t-SNE\n",
    "        h_prime_tsne = tsne.fit_transform(h_prime_np)\n",
    "        print(h_prime_tsne.shape)\n",
    "        \n",
    "        # Plot the node embeddings with different colors for each label\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        for label, emotion in zip(range(len(label_decoder)), label_decoder): \n",
    "            indices = (labels == label).nonzero().squeeze()\n",
    "            plt.scatter(h_prime_tsne[indices, 0], h_prime_tsne[indices, 1], label=f'{emotion}')\n",
    "        plt.title(f'Node Embeddings Visualization (t-SNE) - Perplexity {perplexity}', color=\"white\")\n",
    "        plt.xlabel('Dimension 1', color=\"white\")\n",
    "        plt.ylabel('Dimension 2', color=\"white\")\n",
    "        plt.legend()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9acbcd7",
   "metadata": {},
   "source": [
    "<h5> Sample debugging the GAT code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940e387c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATLayerWithEdgeType(nn.Module):\n",
    "    def __init__(self, num_in_features_per_head, num_out_features_per_head, num_heads, num_edge_types):\n",
    "        super(GATLayerWithEdgeType, self).__init__()\n",
    "        self.num_in_features_per_head = num_in_features_per_head\n",
    "        self.num_out_features_per_head = num_out_features_per_head\n",
    "        self.num_heads = num_heads\n",
    "        self.num_edge_types = num_edge_types\n",
    "\n",
    "        # Linear projection for node features\n",
    "        self.linear_proj = nn.Linear(self.num_in_features_per_head, self.num_heads * self.num_out_features_per_head)\n",
    "        \n",
    "        # Edge type embeddings\n",
    "        self.edge_type_embedding = nn.Embedding(self.num_edge_types, self.num_heads)\n",
    "\n",
    "    def forward(self, input_data, edge_type):\n",
    "        node_features, edge_indices = input_data\n",
    "\n",
    "        # Linear projection for node features\n",
    "        h_linear = self.linear_proj(node_features)\n",
    "        h_linear = h_linear.view(-1, self.num_heads, self.num_out_features_per_head)\n",
    "        h_linear = h_linear.permute(0, 2, 1)\n",
    "\n",
    "        # Edge type embedding\n",
    "        edge_type_embedding = self.edge_type_embedding(edge_type).unsqueeze(-1)  # Add singleton dimension\n",
    "        edge_type_embedding = edge_type_embedding.permute(2, 1, 0)  # Transpose to match h_linear\n",
    "\n",
    "        # Perform matrix multiplication\n",
    "        print(\"h_linear: \",h_linear.shape,\n",
    "             \"edge_type_embedding: \", edge_type_embedding.shape)\n",
    "        attention_scores = torch.matmul(h_linear, edge_type_embedding).squeeze(-1)\n",
    "\n",
    "        # Softmax to get attention coefficients\n",
    "        attention_coefficients = F.softmax(attention_scores, dim=-1)\n",
    "\n",
    "        # Weighted sum of neighbor node representations\n",
    "        updated_representation = torch.matmul(attention_coefficients.transpose(1, 2), h_linear).mean(dim=2)\n",
    "\n",
    "        return updated_representation, attention_coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f3fa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the GAT layer\n",
    "num_in_features = 768\n",
    "num_out_features = 768\n",
    "num_heads = 4\n",
    "num_edge_types = 3\n",
    "gat = GATLayerWithEdgeType(num_in_features, #768\n",
    "                           num_out_features, #768\n",
    "                           num_heads, #4\n",
    "                           num_edge_types #3\n",
    "                          )\n",
    "\n",
    "# 1st param\n",
    "contextualEmbeddingsTrain = torch.randn(14, 768)\n",
    "\n",
    "# 2nd param\n",
    "num_node_pairs = 50\n",
    "max_node_index = 50  # Adjust this based on your actual node index range\n",
    "# Generate random node indices for source and target nodes\n",
    "source_indices = np.random.randint(0, max_node_index, size=num_node_pairs)\n",
    "target_indices = np.random.randint(0, max_node_index, size=num_node_pairs)\n",
    "# Create edgeIndicesTrain tensor\n",
    "edgeIndicesTrain = torch.tensor([source_indices, target_indices])\n",
    "\n",
    "# 3rd param\n",
    "# Generate random tensor\n",
    "edgeTypesTrain = torch.randn(50)\n",
    "# Round the tensor to the nearest integer\n",
    "torch.manual_seed(42)\n",
    "edgeTypesTrain_rounded = torch.round(edgeTypesTrain).long()\n",
    "# Clamp the values to ensure they are between 0 and 2\n",
    "edgeTypesTrain = torch.clamp(edgeTypesTrain_rounded, min=0, max=3)\n",
    "\n",
    "# pass\n",
    "relationalEmbedding, attentionCoef = gat((contextualEmbeddingsTrain, #shape:(14, 768), float/double\n",
    "                                          edgeIndicesTrain), #shape: (2, 50), whole number\n",
    "                                         edgeTypesTrain_clamped) #shape: (50, ), whole number\n",
    "\n",
    "print(\"relationalEmbedding:\", relationalEmbedding.shape)\n",
    "print(\"attentionCoef:\", attentionCoef.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
