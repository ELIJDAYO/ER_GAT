{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35a857cc",
   "metadata": {},
   "source": [
    "\"FC layers referenced from https://towardsdatascience.com/math-neural-network-from-scratch-in-python-d6da9f29ce65\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "176f72e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch, time, os, pickle\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, precision_recall_fscore_support\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, chi2\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import plotly.graph_objs as go\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.io as pio\n",
    "from sklearn.utils import class_weight\n",
    "import tqdm as notebook_tqdm\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "from graph_context_dataset import FeatureEngineeredDataset\n",
    "import warnings\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "import random\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166b22dd",
   "metadata": {},
   "source": [
    "Make sure to specify which dataset to use\n",
    "\n",
    " - dataset_original\n",
    " - dataset_drop_noise\n",
    " - dataset_smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6565cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"dataset_original\"\n",
    "# dataset_path = \"dataset_drop_noise\"\n",
    "# dataset_path = \"dataset_smote\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1470c3",
   "metadata": {},
   "source": [
    "<h3> Declare functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a68406d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims, output_dim, dropout_rate):\n",
    "        super(MyNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dims[0])\n",
    "        self.activation1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dims[0], hidden_dims[1])\n",
    "        self.activation2 = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc3 = nn.Linear(hidden_dims[1], output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.activation1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.activation2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a4fb045",
   "metadata": {
    "code_folding": [
     0,
     9,
     18,
     21,
     24,
     27
    ]
   },
   "outputs": [],
   "source": [
    "# class FCLayer(nn.Module):\n",
    "#     def __init__(self, input_dim, output_dim):\n",
    "#         super(FCLayer, self).__init__()\n",
    "#         self.fc = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.fc(x)\n",
    "#         return x\n",
    "\n",
    "# class ActivationLayer(nn.Module):\n",
    "#     def __init__(self, activation_fn):\n",
    "#         super(ActivationLayer, self).__init__()\n",
    "#         self.activation_fn = activation_fn\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.activation_fn(x)\n",
    "#         return x\n",
    "\n",
    "# def tanh(x):\n",
    "#     return torch.tanh(x)\n",
    "\n",
    "# def sigmoid(x):\n",
    "#     return torch.sigmoid(x)\n",
    "# # loss function and its derivative\n",
    "# def mse(y_true, y_pred):\n",
    "#     return np.mean(np.power(y_true - y_pred, 2))\n",
    "\n",
    "# def mse_prime(y_true, y_pred):\n",
    "#     return 2 * (y_pred - y_true) / y_true.size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "246bf76e",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def oversample_data(X_train, Y_train, num_classes):\n",
    "    # Determine the class with the maximum number of instances\n",
    "    max_class_count = np.max(np.bincount(Y_train))\n",
    "    # Generate indices for oversampling each class\n",
    "    indices_list = [np.where(Y_train == i)[0] for i in range(num_classes)]\n",
    "    # Oversample minority classes to match the count of the majority class\n",
    "    for i, indices in enumerate(indices_list):\n",
    "        if len(indices) < max_class_count:\n",
    "            # Calculate the number of instances to oversample for this class\n",
    "            num_to_oversample = max_class_count - len(indices)\n",
    "            # Randomly select instances with replacement to oversample\n",
    "            oversampled_indices = np.random.choice(indices, size=num_to_oversample, replace=True)\n",
    "            # Append the oversampled instances to the original data\n",
    "            X_train = np.concatenate((X_train, X_train[oversampled_indices]), axis=0)\n",
    "            Y_train = np.concatenate((Y_train, Y_train[oversampled_indices]), axis=0)\n",
    "    return torch.tensor(X_train), torch.tensor(Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8349606b",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def concatenate_tensors(tensor_list):\n",
    "    if not tensor_list:\n",
    "        raise ValueError(\"The tensor list is empty\")\n",
    "\n",
    "    feature_dim = tensor_list[0].shape[1]\n",
    "    for tensor in tensor_list:\n",
    "        if tensor.shape[1] != feature_dim:\n",
    "            raise ValueError(\"All tensors must have the same feature dimension\")\n",
    "    \n",
    "    concatenated_tensor = torch.cat(tensor_list, dim=0)\n",
    "    \n",
    "    return concatenated_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7503aae",
   "metadata": {},
   "source": [
    "<h4> Import labels and label decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72c216ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"data/dump/\" + dataset_path + \"/labels_train.pkl\"\n",
    "with open(file_path, 'rb') as file:\n",
    "    y_train = pickle.load(file)\n",
    "y_train = torch.tensor(y_train)\n",
    "\n",
    "file_path = \"data/dump/\" + dataset_path + \"/labels_test.pkl\"\n",
    "with open(file_path, 'rb') as file:\n",
    "    y_test = pickle.load(file)\n",
    "y_test = torch.tensor(y_test)\n",
    "\n",
    "file_path = \"data/dump/\" + dataset_path + \"/labels_dev.pkl\"\n",
    "with open(file_path, 'rb') as file:\n",
    "    y_val = pickle.load(file)\n",
    "y_val = torch.tensor(y_val)\n",
    "    \n",
    "file_path = 'data/dump/' + dataset_path + '/label_decoder.pkl'\n",
    "with open(file_path, 'rb') as file:\n",
    "    label_decoder = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f3e716",
   "metadata": {},
   "source": [
    "<h4> Import the CNNBiLSTM base-node outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757c53ba",
   "metadata": {},
   "source": [
    "first we disregard the u' and directly train the h'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "396cc340",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_paths = [\n",
    "    \"embed/\" + dataset_path + \"/u_prime_CNNBiLSTM_train.pkl\",\n",
    "    \"embed/\" + dataset_path + \"/h_prime_CNNBiLSTM_DGCN_train.pkl\",\n",
    "    \"embed/\" + dataset_path + \"/h_prime_CNNBiLSTM_GATv1_train.pkl\",\n",
    "    \"embed/\" + dataset_path + \"/h_prime_CNNBiLSTM_GATv1_edgeAttr_train.pkl\",\n",
    "    \"embed/\" + dataset_path + \"/h_prime_CNNBiLSTM_GATv2_edgeAttr_train.pkl\",\n",
    "    \"embed/\" + dataset_path + \"/h_prime_CNNBiLSTM_RGAT_train.pkl\",\n",
    "    \"embed/\" + dataset_path + \"/h_prime_CNNBiLSTM-EGAT_train.pkl\",\n",
    "]\n",
    "\n",
    "test_file_paths = [\n",
    "    \"embed/\" + dataset_path + \"/u_prime_CNNBiLSTM_test.pkl\",\n",
    "    \"embed/\" + dataset_path + \"/h_prime_CNNBiLSTM_DGCN_test.pkl\",\n",
    "    \"embed/\" + dataset_path + \"/h_prime_CNNBiLSTM_GATv1_test.pkl\",\n",
    "    \"embed/\" + dataset_path + \"/h_prime_CNNBiLSTM_GATv1_edgeAttr_test.pkl\",\n",
    "    \"embed/\" + dataset_path + \"/h_prime_CNNBiLSTM_GATv2_edgeAttr_test.pkl\",\n",
    "    \"embed/\" + dataset_path + \"/h_prime_CNNBiLSTM_RGAT_test.pkl\",\n",
    "    \"embed/\" + dataset_path + \"/h_prime_CNNBiLSTM-EGAT_test.pkl\",\n",
    "]\n",
    "\n",
    "val_file_paths = [\n",
    "    \"embed/\" + dataset_path + \"/u_prime_CNNBiLSTM_dev.pkl\",\n",
    "    \"embed/\" + dataset_path + \"/h_prime_CNNBiLSTM_DGCN_dev.pkl\",\n",
    "    \"embed/\" + dataset_path + \"/h_prime_CNNBiLSTM_GATv1_dev.pkl\",\n",
    "    \"embed/\" + dataset_path + \"/h_prime_CNNBiLSTM_GATv1_edgeAttr_dev.pkl\",\n",
    "    \"embed/\" + dataset_path + \"/h_prime_CNNBiLSTM_GATv2_edgeAttr_dev.pkl\",\n",
    "    \"embed/\" + dataset_path + \"/h_prime_CNNBiLSTM_RGAT_dev.pkl\",\n",
    "    \"embed/\" + dataset_path + \"/h_prime_CNNBiLSTM-EGAT_dev.pkl\",\n",
    "]\n",
    "\n",
    "dictKey = {\n",
    "    0 : 'cnnbilstm',\n",
    "    1 : 'cnnbilstm-select-few',\n",
    "    2 : 'cnnbilstm-select-mod',\n",
    "    3 : 'cnnbilstm-select-more',\n",
    "    4 : 'dgcn',\n",
    "    5 : 'dgcn-select',\n",
    "    6 : 'gatv1',\n",
    "    7 : 'gatv1-select',\n",
    "    8 : 'gatv1-edge',\n",
    "    9 : 'gatv1-edge-select',\n",
    "    10 : 'gatv2-edge',\n",
    "    11 : 'gatv2-edge-select',\n",
    "    12 : 'rgat',\n",
    "    13 : 'rgat-select',\n",
    "    14 : 'egat',\n",
    "    15 : 'egat-select',\n",
    "    16 : 'cnnbilstm-select-mod-dgcn',\n",
    "    17 : 'cnnbilstm-select-mod-gatv1',\n",
    "    18 : 'cnnbilstm-select-mod-gatv1-edge',\n",
    "    19 : 'cnnbilstm-select-mod-gatv2-edge',\n",
    "    20 : 'cnnbilstm-select-mod-rgat',\n",
    "    21 : 'cnnbilstm-select-mod-egat',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ff1721",
   "metadata": {},
   "source": [
    "<h4> Getting CNNBiLSTM and GAT outputs for all sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "387dbd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_and_concatenate(tensor_list):\n",
    "    # Flatten the list if it contains nested lists\n",
    "    flat_list = []\n",
    "    for item in tensor_list:\n",
    "        if isinstance(item, list):\n",
    "            flat_list.extend(item)\n",
    "        else:\n",
    "            flat_list.append(item)\n",
    "    \n",
    "    # Ensure all items in the flat_list are tensors\n",
    "    tensor_items = [torch.tensor(item) if not isinstance(item, torch.Tensor) else item for item in flat_list]\n",
    "\n",
    "    # Concatenate all tensors along the first dimension\n",
    "    return torch.cat(tensor_items, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fc04ea",
   "metadata": {},
   "source": [
    "<b>Continue from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12784cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = train_file_paths[1] \n",
    "# with open(file_path, 'rb') as file:\n",
    "#     data = pickle.load(file)\n",
    "\n",
    "# flattened_data = flatten_and_concatenate(data)\n",
    "# trainFeaturesList.append(flattened_data)\n",
    "\n",
    "# trainFeaturesList[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7e3426c4",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def concatenate_tensors(tensor_list):\n",
    "    return torch.cat(tensor_list, dim=0)\n",
    "\n",
    "trainFeaturesList = []\n",
    "testFeaturesList = []\n",
    "valFeaturesList = []\n",
    "\n",
    "for file_path in train_file_paths:\n",
    "    with open(file_path, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "        if (isinstance(data, list) and file_path != train_file_paths[-1]):\n",
    "            data = concatenate_tensors(data)\n",
    "        elif file_path != train_file_paths[-1]:\n",
    "            data = data.squeeze(1)\n",
    "        else:\n",
    "            data = data[0]\n",
    "            \n",
    "    trainFeaturesList.append(data)\n",
    "            \n",
    "for file_path in test_file_paths:\n",
    "    with open(file_path, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "        if (isinstance(data, list) and file_path != test_file_paths[-1]):\n",
    "            data = concatenate_tensors(data)\n",
    "        elif file_path != test_file_paths[-1]:\n",
    "            data = data.squeeze(1)\n",
    "        else:\n",
    "            data = data[0]\n",
    "            \n",
    "    testFeaturesList.append(data)\n",
    "            \n",
    "for file_path in val_file_paths:\n",
    "    with open(file_path, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "        if (isinstance(data, list) and file_path != val_file_paths[-1]):\n",
    "            data = concatenate_tensors(data)\n",
    "        elif file_path != val_file_paths[-1]:\n",
    "            data = data.squeeze(1)\n",
    "        else:\n",
    "            data = data[0]\n",
    "            \n",
    "    valFeaturesList.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2260a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "875e7687",
   "metadata": {},
   "source": [
    "EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e174164",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# # Checking the structure of graph\n",
    "# for n in range(10):\n",
    "#     tensor_data_np = tensor_utterances[n].detach().numpy()\n",
    "\n",
    "#     # Plot the data\n",
    "#     plt.figure(figsize=(10, 5))\n",
    "#     plt.plot(range(len(tensor_data_np)), tensor_data_np)\n",
    "#     plt.title('Line Graph of Tensor Data')\n",
    "#     plt.xlabel('Index')\n",
    "#     plt.ylabel('Value')\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479a3b1f",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# # Normalize the h' (1st GAT)\n",
    "# data = cherry_picked_nodes.detach().numpy()\n",
    "# data_normalized = data / np.linalg.norm(data, axis=1, keepdims=True)\n",
    "\n",
    "# # Compute pairwise cosine similarities\n",
    "# similarities = cosine_similarity(data_normalized)\n",
    "\n",
    "# # Print or analyze the similarity matrix\n",
    "# # print(similarities)\n",
    "# plt.hist(similarities.flatten(), bins=50, density=True)\n",
    "# plt.title('Distribution of Cosine Similarities')\n",
    "# plt.xlabel('Cosine Similarity')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a070ce4",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# # Normalize the h' (2nd GAT)\n",
    "# data = all_node_feats.detach().numpy()\n",
    "# data_normalized = data / np.linalg.norm(data, axis=1, keepdims=True)\n",
    "\n",
    "# # Compute pairwise cosine similarities\n",
    "# similarities = cosine_similarity(data_normalized)\n",
    "\n",
    "# # Print or analyze the similarity matrix\n",
    "# # print(similarities)\n",
    "# plt.hist(similarities.flatten(), bins=50, density=True)\n",
    "# plt.title('Distribution of Cosine Similarities')\n",
    "# plt.xlabel('Cosine Similarity')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43fa315",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# # Normalize the u' or updated_representations\n",
    "# data = tensor_utterances.detach().numpy()\n",
    "# data_normalized = data / np.linalg.norm(data, axis=1, keepdims=True)\n",
    "\n",
    "# # Compute pairwise cosine similarities\n",
    "# similarities = cosine_similarity(data_normalized)\n",
    "\n",
    "# plt.hist(similarities.flatten(), bins=50, density=True)\n",
    "# plt.title('Distribution of Cosine Similarities')\n",
    "# plt.xlabel('Cosine Similarity')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40320052",
   "metadata": {},
   "source": [
    "<h3> Feature Selection and creating data combination for classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510f143f",
   "metadata": {},
   "source": [
    "Define select feature function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6501b577",
   "metadata": {
    "code_folding": [
     0,
     6
    ]
   },
   "outputs": [],
   "source": [
    "def get_norm_features(encoded_features):\n",
    "    scaler = MinMaxScaler()\n",
    "#       \"FeatureSelected+CNNBiLSTM+GAT: \", concatenatedRepresentationTrain2.shape, \"\\n\",\n",
    "    features_scaled = scaler.fit_transform(encoded_features)\n",
    "    return torch.tensor(features_scaled)\n",
    "\n",
    "def get_selected_features(encoded_features, labels, top_n):\n",
    "    if torch.is_tensor(encoded_features):\n",
    "        encoded_features = encoded_features.detach().cpu().numpy()\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    features_scaled = scaler.fit_transform(encoded_features)\n",
    "\n",
    "    selector = SelectKBest(score_func=f_classif, k=100)\n",
    "\n",
    "    top_features_by_class = {}\n",
    "    top_scores = {}\n",
    "\n",
    "    for label in range(7):\n",
    "        # Create a binary mask indicating instances belonging to the current class\n",
    "        mask = (labels == label)\n",
    "\n",
    "        # SelectKBest with chi2 as the scoring function\n",
    "        selector = SelectKBest(score_func=chi2, k=top_n)  # Select top 20 features\n",
    "        selector.fit(features_scaled, mask)  # Fit SelectKBest to the data\n",
    "        # Get the indices of the top 20 features\n",
    "        top_features_indices = np.argsort(selector.scores_)[-top_n:]\n",
    "        scores = selector.scores_[top_features_indices]\n",
    "        # Store the indices in the dictionary\n",
    "        top_features_by_class[label] = top_features_indices\n",
    "        top_scores[label] = scores\n",
    "\n",
    "    concatenated_features_set = set()\n",
    "    for label, indices in top_features_by_class.items():\n",
    "        concatenated_features_set.update(indices)\n",
    "\n",
    "    concatenated_features_indices = list(concatenated_features_set)\n",
    "\n",
    "    concatenated_features_indices = np.array(concatenated_features_indices)\n",
    "\n",
    "    # Select the desired features\n",
    "    selected_features = encoded_features[:, concatenated_features_indices]\n",
    "#     print(selected_features.shape)\n",
    "    return selected_features, concatenated_features_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d79a94",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# pca = PCA(n_components=2)\n",
    "# pca_result = pca.fit_transform(selected_features.detach().numpy())\n",
    "\n",
    "# # Plot the PCA result with color-coded labels\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# for label in np.unique(Y_train):\n",
    "#     indices = Y_train == label\n",
    "#     plt.scatter(pca_result[indices, 0], pca_result[indices, 1], label=f'{label_decoder[label]}', alpha=0.5)\n",
    "#     plt.title('PCA Visualization of Selected Utterance Embeddings (Train) with Color-Coded Labels')\n",
    "#     plt.xlabel('Principal Component 1')\n",
    "#     plt.ylabel('Principal Component 2')\n",
    "#     plt.legend()\n",
    "#     plt.grid(True)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9891e235",
   "metadata": {},
   "source": [
    "3d plottly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efccc17d",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# X_train = selected_features\n",
    "# X_train = X_train / np.linalg.norm(X_train, axis=1, keepdims=True)\n",
    "# # Perform T-SNE dimensionality reduction\n",
    "# tsne = TSNE(n_components=3, random_state=42)\n",
    "# X_tsne = tsne.fit_transform(X_train)\n",
    "\n",
    "# # Create a Plotly scatter plot\n",
    "# fig = go.Figure(data=[go.Scatter3d(\n",
    "#     x=X_tsne[:, 0],\n",
    "#     y=X_tsne[:, 1],\n",
    "#     z=X_tsne[:, 2],\n",
    "#     mode='markers',\n",
    "#     marker=dict(\n",
    "#         size=3,\n",
    "#         color=Y_train,  # Assuming Y_train contains labels for coloring\n",
    "#         colorscale='Viridis',  # You can choose a different colorscale\n",
    "#         opacity=0.8\n",
    "#     )\n",
    "# )])\n",
    "\n",
    "# # Update layout\n",
    "# fig.update_layout(title='3D T-SNE Plot', autosize=False,\n",
    "#                   width=800, height=800)\n",
    "\n",
    "# # Show the plot\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca73f7e2",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Save the plot as an HTML file\n",
    "# pio.write_html(fig, '3d_tsne_plot.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0feaf772",
   "metadata": {},
   "source": [
    "Now prepare the data that will be ued to train the classifier, there are 20 combinations. And pick top 7 combinations yielding top F1 weighted-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "61905fb7",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "trainList = []\n",
    "testList = []\n",
    "valList = []\n",
    "\n",
    "file_path1 = \"data/dump/\" + dataset_path + \"/CNNBiLSTM_data_for_classifier/trainList.pkl\"\n",
    "file_path2 = \"data/dump/\" + dataset_path + \"/CNNBiLSTM_data_for_classifier/testList.pkl\"\n",
    "file_path3 = \"data/dump/\" + dataset_path + \"/CNNBiLSTM_data_for_classifier/valList.pkl\"\n",
    "\n",
    "checkFile1 = os.path.isfile(file_path1)\n",
    "checkFile2 = os.path.isfile(file_path2)\n",
    "checkFile3 = os.path.isfile(file_path3)\n",
    "\n",
    "if checkFile1 and checkFile2 and checkFile3: \n",
    "    with open(file_path1, \"rb\") as file:\n",
    "        trainList = pickle.load(file)\n",
    "    with open(file_path2, \"rb\") as file:\n",
    "        testList = pickle.load(file)\n",
    "    with open(file_path3, \"rb\") as file:\n",
    "        valList = pickle.load(file)\n",
    "else:\n",
    "    trainFeaturesList.append(data)\n",
    "    #1\n",
    "    trainList.append(trainFeaturesList[0])\n",
    "    testList.append(testFeaturesList[0])\n",
    "    valList.append(valFeaturesList[0])\n",
    "    #2\n",
    "    selectedTrainFeatures1a, indicesFeatures1a = get_selected_features(trainFeaturesList[0], y_train, 16)\n",
    "    selectedTestFeatures1a = testFeaturesList[0][:, indicesFeatures1a]\n",
    "    selectedValFeatures1a = valFeaturesList[0][:, indicesFeatures1a]\n",
    "    trainList.append(selectedTrainFeatures1a)\n",
    "    testList.append(selectedTestFeatures1a)\n",
    "    valList.append(selectedValFeatures1a)\n",
    "    #3\n",
    "    selectedTrainFeatures1b, indicesFeatures1b = get_selected_features(trainFeaturesList[0], y_train, 32)\n",
    "    selectedTestFeatures1b = testFeaturesList[0][:, indicesFeatures1b]\n",
    "    selectedValFeatures1b = valFeaturesList[0][:, indicesFeatures1b]\n",
    "    trainList.append(selectedTrainFeatures1b)\n",
    "    testList.append(selectedTestFeatures1b)\n",
    "    valList.append(selectedValFeatures1b)\n",
    "    #4\n",
    "    selectedTrainFeatures1c, indicesFeatures1c = get_selected_features(trainFeaturesList[0], y_train, 64)\n",
    "    selectedTestFeatures1c = testFeaturesList[0][:, indicesFeatures1c]\n",
    "    selectedValFeatures1c = valFeaturesList[0][:, indicesFeatures1c]\n",
    "    trainList.append(selectedTrainFeatures1c)\n",
    "    testList.append(selectedTestFeatures1c)\n",
    "    valList.append(selectedValFeatures1c)\n",
    "    #5\n",
    "    trainList.append(trainFeaturesList[1])\n",
    "    testList.append(testFeaturesList[1])\n",
    "    valList.append(valFeaturesList[1])\n",
    "    #6\n",
    "    selectedTrainFeatures2, indicesFeatures2 = get_selected_features(trainFeaturesList[1], y_train, 12)\n",
    "    selectedTestFeatures2 = testFeaturesList[1][:, indicesFeatures2]\n",
    "    selectedValFeatures2 = valFeaturesList[1][:, indicesFeatures2]\n",
    "    trainList.append(selectedTrainFeatures2)\n",
    "    testList.append(selectedTestFeatures2)\n",
    "    valList.append(selectedValFeatures2)\n",
    "    #7\n",
    "    trainList.append(trainFeaturesList[2])\n",
    "    testList.append(testFeaturesList[2])\n",
    "    valList.append(valFeaturesList[2])\n",
    "    #8\n",
    "    selectedTrainFeatures3, indicesFeatures3 = get_selected_features(trainFeaturesList[2], y_train, 12)\n",
    "    selectedTestFeatures3 = testFeaturesList[2][:, indicesFeatures3]\n",
    "    selectedValFeatures3 = valFeaturesList[2][:, indicesFeatures3]\n",
    "    trainList.append(selectedTrainFeatures3)\n",
    "    testList.append(selectedTestFeatures3)\n",
    "    valList.append(selectedValFeatures3)\n",
    "    #9\n",
    "    trainList.append(trainFeaturesList[3])\n",
    "    testList.append(testFeaturesList[3])\n",
    "    valList.append(valFeaturesList[3])\n",
    "    #10\n",
    "    selectedTrainFeatures4, indicesFeatures4 = get_selected_features(trainFeaturesList[3], y_train, 12)\n",
    "    selectedTestFeatures4 = testFeaturesList[3][:, indicesFeatures4]\n",
    "    selectedValFeatures4 = valFeaturesList[3][:, indicesFeatures4]\n",
    "    trainList.append(selectedTrainFeatures4)\n",
    "    testList.append(selectedTestFeatures4)\n",
    "    valList.append(selectedValFeatures4)\n",
    "    #11\n",
    "    trainList.append(trainFeaturesList[4])\n",
    "    testList.append(testFeaturesList[4])\n",
    "    valList.append(valFeaturesList[4])\n",
    "    #12\n",
    "    selectedTrainFeatures5, indicesFeatures5 = get_selected_features(trainFeaturesList[4], y_train, 12)\n",
    "    selectedTestFeatures5 = testFeaturesList[4][:, indicesFeatures5]\n",
    "    selectedValFeatures5 = valFeaturesList[4][:, indicesFeatures5]\n",
    "    trainList.append(selectedTrainFeatures5)\n",
    "    testList.append(selectedTestFeatures5)\n",
    "    valList.append(selectedValFeatures5)\n",
    "    #13\n",
    "    trainList.append(trainFeaturesList[5])\n",
    "    testList.append(testFeaturesList[5])\n",
    "    valList.append(valFeaturesList[5])\n",
    "    #14\n",
    "    selectedTrainFeatures6, indicesFeatures6 = get_selected_features(trainFeaturesList[5], y_train, 12)\n",
    "    selectedTestFeatures6 = testFeaturesList[5][:, indicesFeatures6]\n",
    "    selectedValFeatures6 = valFeaturesList[5][:, indicesFeatures6]\n",
    "    trainList.append(selectedTrainFeatures6)\n",
    "    testList.append(selectedTestFeatures6)\n",
    "    valList.append(selectedValFeatures6)\n",
    "    #15\n",
    "    trainList.append(trainFeaturesList[6])\n",
    "    testList.append(testFeaturesList[6])\n",
    "    valList.append(valFeaturesList[6])\n",
    "    #16\n",
    "    selectedTrainFeatures7, indicesFeatures7 = get_selected_features(trainFeaturesList[6], y_train, 12)\n",
    "    selectedTestFeatures7 = testFeaturesList[6][:, indicesFeatures7]\n",
    "    selectedValFeatures7 = testFeaturesList[6][:, indicesFeatures7]\n",
    "    trainList.append(selectedTrainFeatures7)\n",
    "    testList.append(selectedTestFeatures7)\n",
    "    valList.append(selectedValFeatures7)\n",
    "    selectedNormTrainFeatures1 = get_norm_features(selectedTrainFeatures1b)\n",
    "    selectedNormTestFeatures1 = get_norm_features(selectedTestFeatures1b.detach().numpy())\n",
    "    selectedNormValFeatures1 = get_norm_features(selectedValFeatures1b.detach().numpy())\n",
    "\n",
    "    #17\n",
    "    trainNormFeatures2 = get_norm_features(trainFeaturesList[1].detach().numpy())\n",
    "    testNormFeatures2 = get_norm_features(testFeaturesList[1].detach().numpy())\n",
    "    valNormFeatures2 = get_norm_features(valFeaturesList[1].detach().numpy())\n",
    "    concatenatedTrainFeatures2 = torch.cat((selectedNormTrainFeatures1, trainNormFeatures2), dim=1)\n",
    "    concatenatedTestFeatures2 = torch.cat((selectedNormTestFeatures1, testNormFeatures2), dim=1)\n",
    "    concatenatedValFeatures2 = torch.cat((selectedNormValFeatures1, valNormFeatures2), dim=1)\n",
    "    trainList.append(concatenatedTrainFeatures2)\n",
    "    testList.append(concatenatedTestFeatures2)\n",
    "    valList.append(concatenatedValFeatures2)\n",
    "    #18\n",
    "    trainNormFeatures3 = get_norm_features(trainFeaturesList[2].detach().numpy())\n",
    "    testNormFeatures3 = get_norm_features(testFeaturesList[2].detach().numpy())\n",
    "    valNormFeatures3 = get_norm_features(valFeaturesList[2].detach().numpy())\n",
    "    concatenatedTrainFeatures3 = torch.cat((selectedNormTrainFeatures1, trainNormFeatures3), dim=1)\n",
    "    concatenatedTestFeatures3 = torch.cat((selectedNormTestFeatures1, testNormFeatures3), dim=1)\n",
    "    concatenatedValFeatures3 = torch.cat((selectedNormValFeatures1, valNormFeatures3), dim=1)\n",
    "    trainList.append(concatenatedTrainFeatures3)\n",
    "    testList.append(concatenatedTestFeatures3)\n",
    "    valList.append(concatenatedValFeatures3)\n",
    "    #19\n",
    "    trainNormFeatures4 = get_norm_features(trainFeaturesList[3].detach().numpy())\n",
    "    testNormFeatures4 = get_norm_features(testFeaturesList[3].detach().numpy())\n",
    "    valNormFeatures4 = get_norm_features(valFeaturesList[3].detach().numpy())\n",
    "    concatenatedTrainFeatures4 = torch.cat((selectedNormTrainFeatures1, trainNormFeatures4), dim=1)\n",
    "    concatenatedTestFeatures4 = torch.cat((selectedNormTestFeatures1, testNormFeatures4), dim=1)\n",
    "    concatenatedValFeatures4 = torch.cat((selectedNormValFeatures1, valNormFeatures4), dim=1)\n",
    "    trainList.append(concatenatedTrainFeatures4)\n",
    "    testList.append(concatenatedTestFeatures4)\n",
    "    valList.append(concatenatedValFeatures4)\n",
    "    #20\n",
    "    trainNormFeatures5 = get_norm_features(trainFeaturesList[4].detach().numpy())\n",
    "    testNormFeatures5 = get_norm_features(testFeaturesList[4].detach().numpy())\n",
    "    valNormFeatures5 = get_norm_features(valFeaturesList[4].detach().numpy())\n",
    "    concatenatedTrainFeatures5 = torch.cat((selectedNormTrainFeatures1, trainNormFeatures5), dim=1)\n",
    "    concatenatedTestFeatures5 = torch.cat((selectedNormTestFeatures1, testNormFeatures5), dim=1)\n",
    "    concatenatedValFeatures5 = torch.cat((selectedNormValFeatures1, valNormFeatures5), dim=1)\n",
    "    trainList.append(concatenatedTrainFeatures5)\n",
    "    testList.append(concatenatedTestFeatures5)\n",
    "    valList.append(concatenatedValFeatures5)\n",
    "\n",
    "    #21\n",
    "    trainNormFeatures6 = get_norm_features(trainFeaturesList[5].detach().numpy())\n",
    "    testNormFeatures6 = get_norm_features(testFeaturesList[5].detach().numpy())\n",
    "    valNormFeatures6 = get_norm_features(valFeaturesList[5].detach().numpy())\n",
    "    concatenatedTrainFeatures6 = torch.cat((selectedNormTrainFeatures1, trainNormFeatures6), dim=1)\n",
    "    concatenatedTestFeatures6 = torch.cat((selectedNormTestFeatures1, testNormFeatures6), dim=1)\n",
    "    concatenatedValFeatures6 = torch.cat((selectedNormValFeatures1, valNormFeatures6), dim=1)\n",
    "    trainList.append(concatenatedTrainFeatures6)\n",
    "    testList.append(concatenatedTestFeatures6)\n",
    "    valList.append(concatenatedValFeatures6)\n",
    "\n",
    "    #22\n",
    "    trainNormFeatures7 = get_norm_features(trainFeaturesList[6].detach().numpy())\n",
    "    testNormFeatures7 = get_norm_features(testFeaturesList[6].detach().numpy())\n",
    "    valNormFeatures7 = get_norm_features(valFeaturesList[6].detach().numpy())\n",
    "    concatenatedTrainFeatures7 = torch.cat((selectedNormTrainFeatures1, trainNormFeatures7), dim=1)\n",
    "    concatenatedTestFeatures7 = torch.cat((selectedNormTestFeatures1, testNormFeatures7), dim=1)\n",
    "    concatenatedValFeatures7 = torch.cat((selectedNormValFeatures1, valNormFeatures7), dim=1)\n",
    "    trainList.append(concatenatedTrainFeatures7)\n",
    "    testList.append(concatenatedTestFeatures7)\n",
    "    valList.append(concatenatedValFeatures7)\n",
    "\n",
    "    with open(file_path1, 'wb') as file:\n",
    "        pickle.dump(trainList, file)\n",
    "    with open(file_path2, 'wb') as file:\n",
    "        pickle.dump(testList, file)\n",
    "    with open(file_path3, 'wb') as file:\n",
    "        pickle.dump(valList, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265dc4c4",
   "metadata": {},
   "source": [
    "1. Prep data - normalize and create data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ebb893e7",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def prep_data(features, labels, isOversample):\n",
    "    num_instances = len(features)\n",
    "    num_classes = 7\n",
    "\n",
    "    # Rescale input features\n",
    "    # selected_features = concatenated_representation / np.linalg.norm(concatenated_representation, axis=1, keepdims=True)\n",
    "\n",
    "    # Apply data resampling (oversampling) to balance class distribution\n",
    "    if isOversample:\n",
    "        X_set, Y_set = oversample_data(features, labels, num_classes)\n",
    "    else:\n",
    "        X_set, Y_set = features, labels\n",
    "\n",
    "    # Calculate class weights for class weighting\n",
    "#     class_counts = np.bincount(labels)\n",
    "#     total_instances = np.sum(class_counts)\n",
    "    # class_weights = torch.tensor([total_instances / (num_classes * count) for count in class_counts], dtype=torch.float32)\n",
    "\n",
    "    # Convert data to PyTorch tensors\n",
    "    X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
    "    Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
    "    # print(X_train_tensor.shape, Y_train_tensor.shape)\n",
    "    # X_train_tensor = torch.tensor(selected_features)\n",
    "    # Y_train_tensor = torch.tensor(y_train)\n",
    "\n",
    "    unique_labels, label_counts = np.unique(Y_set, return_counts=True)\n",
    "\n",
    "    # Print the counts for each unique label\n",
    "#     for label, count in zip(unique_labels, label_counts):\n",
    "#         print(f\"Label {label_decoder[label]}: {count} occurrences\")\n",
    "\n",
    "#     print(X_tensor.shape, Y_tensor.shape)\n",
    "    # Create a TensorDataset\n",
    "    dataset = TensorDataset(X_tensor, Y_tensor)\n",
    "\n",
    "    return X_tensor, Y_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861ebf30",
   "metadata": {},
   "source": [
    "2. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9a71c886",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def model_train1(X_set, Y_set, num_epochs=20, batch_size=64, loss_difference_threshold=0.01, \n",
    "                 hidden_dims=[256, 128], dropout_rate=0.5, lr=0.0001, optimizer_class=optim.Adam, criterion_class=nn.CrossEntropyLoss):\n",
    "    output_dim = 7  # Number of classes\n",
    "    model = MyNetwork(len(X_set[0]), hidden_dims, output_dim, dropout_rate)\n",
    "    criterion = criterion_class()\n",
    "    optimizer = optimizer_class(model.parameters(), lr=lr)\n",
    "    loss_history = []\n",
    "    accuracy_history = []\n",
    "    print_interval = 1  # Print tqdm every epoch\n",
    "    previous_loss = float('inf')\n",
    "\n",
    "    # Create dataset and dataloader\n",
    "    dataset = TensorDataset(X_set, Y_set)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    epoch_num = num_epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_instances = 0\n",
    "        with tqdm(total=len(dataloader), desc=f'Epoch {epoch+1}/{num_epochs}', leave=False) as pbar:\n",
    "            for inputs, labels in dataloader:\n",
    "                inputs = inputs.float()  # Ensure inputs are float32\n",
    "                labels = labels.long()   # Ensure labels are long\n",
    "                outputs = model(inputs)\n",
    "                outputs = outputs.squeeze()\n",
    "                labels = labels.squeeze()\n",
    "                loss = criterion(outputs, labels)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, dim=1)\n",
    "                correct_predictions += (predicted == labels).sum().item()\n",
    "                total_instances += labels.size(0)\n",
    "                pbar.update(1)\n",
    "\n",
    "        epoch_loss = total_loss / total_instances\n",
    "        epoch_accuracy = correct_predictions / total_instances\n",
    "        loss_history.append(epoch_loss)\n",
    "        accuracy_history.append(epoch_accuracy)\n",
    "\n",
    "        if epoch > 0 and abs(epoch_loss - previous_loss) < loss_difference_threshold:\n",
    "            epoch_num = epoch\n",
    "            break\n",
    "\n",
    "        previous_loss = epoch_loss\n",
    "\n",
    "    return model, epoch_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "635c4f57",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def model_train2(X_set, y_set, num_epochs=20, batch_size=128, early_stopping_threshold=0.01,\n",
    "                 hidden_dim=128, dropout_prob=0.5, learning_rate=0.0005, optimizer_class=optim.Adam, criterion_class=nn.CrossEntropyLoss):\n",
    "    input_dim = len(X_set[0])  # Size of the input features\n",
    "    output_dim = 7  # Number of classes\n",
    "\n",
    "    model = FCClassifier(input_dim, hidden_dim, output_dim, dropout_prob)\n",
    "    criterion = criterion_class()\n",
    "    optimizer = optimizer_class(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Create DataLoader for batching\n",
    "    dataset = TensorDataset(X_set, y_set)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    epoch_losses = []  # List to store loss values for each epoch\n",
    "    epoch_num = num_epochs\n",
    "    # Training loop\n",
    "    with tqdm(total=num_epochs, unit=\"epoch\", desc=\"Training\") as tepoch:\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "\n",
    "            for batch_features, batch_labels in dataloader:\n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(batch_features)\n",
    "                loss = criterion(outputs, batch_labels)\n",
    "\n",
    "                # Backward pass and optimize\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # Update running loss\n",
    "                running_loss += loss.item()\n",
    "\n",
    "            # Calculate and store average loss for the epoch\n",
    "            epoch_loss = running_loss / len(dataloader)\n",
    "            epoch_losses.append(epoch_loss)\n",
    "\n",
    "            # Update tqdm description\n",
    "            tepoch.set_postfix(loss=epoch_loss)\n",
    "            tepoch.update()\n",
    "\n",
    "            # Check for early stopping\n",
    "            if epoch > 0 and abs(epoch_losses[-2] - epoch_losses[-1]) < early_stopping_threshold:\n",
    "                epoch_num = epoch\n",
    "                break\n",
    "\n",
    "    return model, epoch_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b435c98b",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def classify_emotions(model, X_tensor, Y_tensor, typeSet, isSimpleFC, i_dict):\n",
    "    # Set the model to evaluation mode\n",
    "    if X_tensor.dtype != torch.float32:\n",
    "        X_tensor = X_tensor.float()\n",
    "        \n",
    "    model.eval()\n",
    "\n",
    "    # Predict on the data\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_tensor)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    # Convert predicted tensor to numpy array\n",
    "    predicted = predicted.cpu().numpy()\n",
    "    Y_tensor = Y_tensor.cpu().numpy()\n",
    "\n",
    "    # Calculate classification report\n",
    "    report = classification_report(Y_tensor, predicted, target_names=label_decoder.values(), output_dict=True, zero_division=0)\n",
    "\n",
    "    # Extract metrics\n",
    "    accuracy = report['accuracy']\n",
    "    recall = report['weighted avg']['recall']\n",
    "    weighted_f1 = report['weighted avg']['f1-score']\n",
    "    f1_micro = report.get('micro avg', {}).get('f1-score', accuracy)\n",
    "    f1_macro = report.get('macro avg', {}).get('f1-score', 0.0) \n",
    "    \n",
    "    if typeSet == \"validation\":\n",
    "        print(\"Classified: \", dictKey[i_dict])\n",
    "    \n",
    "    return dictKey[i_dict], typeSet, isSimpleFC, accuracy, recall, weighted_f1, f1_micro, f1_macro\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "52d8752b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = FeatureEngineeredDataset(trainList, testList, valList)\n",
    "dataLoader = DataLoader(dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5b35df7e",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding Progress: 100%|███████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 286.00batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <class 'torch.Tensor'>\n",
      "torch.Size([12840, 200])\n",
      "1 <class 'torch.Tensor'>\n",
      "torch.Size([12840, 61])\n",
      "2 <class 'torch.Tensor'>\n",
      "torch.Size([12840, 100])\n",
      "3 <class 'torch.Tensor'>\n",
      "torch.Size([12840, 155])\n",
      "4 <class 'torch.Tensor'>\n",
      "torch.Size([12840, 64])\n",
      "5 <class 'torch.Tensor'>\n",
      "torch.Size([12840, 26])\n",
      "6 <class 'torch.Tensor'>\n",
      "torch.Size([12840, 64])\n",
      "7 <class 'torch.Tensor'>\n",
      "torch.Size([12840, 45])\n",
      "8 <class 'torch.Tensor'>\n",
      "torch.Size([12840, 64])\n",
      "9 <class 'torch.Tensor'>\n",
      "torch.Size([12840, 44])\n",
      "10 <class 'torch.Tensor'>\n",
      "torch.Size([12840, 64])\n",
      "11 <class 'torch.Tensor'>\n",
      "torch.Size([12840, 43])\n",
      "12 <class 'torch.Tensor'>\n",
      "torch.Size([12840, 64])\n",
      "13 <class 'torch.Tensor'>\n",
      "torch.Size([12840, 35])\n",
      "14 <class 'torch.Tensor'>\n",
      "torch.Size([12840, 64])\n",
      "15 <class 'torch.Tensor'>\n",
      "torch.Size([12840, 33])\n",
      "16 <class 'torch.Tensor'>\n",
      "torch.Size([12840, 164])\n",
      "17 <class 'torch.Tensor'>\n",
      "torch.Size([12840, 164])\n",
      "18 <class 'torch.Tensor'>\n",
      "torch.Size([12840, 164])\n",
      "19 <class 'torch.Tensor'>\n",
      "torch.Size([12840, 164])\n",
      "20 <class 'torch.Tensor'>\n",
      "torch.Size([12840, 164])\n",
      "21 <class 'torch.Tensor'>\n",
      "torch.Size([12840, 164])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for trainSet, testSet, valSet in tqdm(dataLoader, desc=\"Encoding Progress\", unit=\"batch\"):\n",
    "    print(i, type(trainSet))\n",
    "    if isinstance(trainSet, list):\n",
    "        print(type(trainSet[0]))\n",
    "        sample = trainSet[0]\n",
    "        print(sample.shape)\n",
    "    else:\n",
    "        print(trainSet.squeeze(0).shape)\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8e99ea",
   "metadata": {},
   "source": [
    "<b> This is where value for isSimpleFC is decided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3c6a93e4",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "Training:   6%|███▌                                                       | 3/50 [00:01<00:16,  2.85epoch/s, loss=1.56]\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "Training:   6%|███▌                                                       | 3/50 [00:00<00:13,  3.39epoch/s, loss=1.55]\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|███▌                                                       | 3/50 [00:00<00:14,  3.15epoch/s, loss=1.56]\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "Training:   6%|███▌                                                       | 3/50 [00:01<00:16,  2.92epoch/s, loss=1.56]\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "Training:   6%|███▌                                                       | 3/50 [00:00<00:14,  3.20epoch/s, loss=1.55]\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "Training:   8%|████▋                                                      | 4/50 [00:01<00:13,  3.29epoch/s, loss=1.55]\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "Training:   6%|███▌                                                       | 3/50 [00:00<00:14,  3.29epoch/s, loss=1.55]\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "Training:   6%|███▌                                                       | 3/50 [00:00<00:13,  3.40epoch/s, loss=1.55]\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|███▌                                                       | 3/50 [00:00<00:13,  3.56epoch/s, loss=1.56]\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "Training:   6%|███▌                                                       | 3/50 [00:00<00:13,  3.44epoch/s, loss=1.56]\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "Training:   6%|███▌                                                       | 3/50 [00:00<00:14,  3.28epoch/s, loss=1.56]\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "Training:   6%|███▌                                                       | 3/50 [00:00<00:14,  3.27epoch/s, loss=1.55]\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "Training:   6%|███▌                                                       | 3/50 [00:00<00:14,  3.14epoch/s, loss=1.55]\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "Training:   6%|███▌                                                       | 3/50 [00:00<00:13,  3.40epoch/s, loss=1.55]\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|███▌                                                       | 3/50 [00:00<00:14,  3.27epoch/s, loss=1.55]\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "Training:   6%|███▌                                                       | 3/50 [00:00<00:12,  3.62epoch/s, loss=1.56]\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "Training:   6%|███▌                                                       | 3/50 [00:00<00:15,  3.02epoch/s, loss=1.56]\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "Training:   6%|███▌                                                       | 3/50 [00:00<00:15,  3.05epoch/s, loss=1.56]\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "Training:   6%|███▌                                                       | 3/50 [00:01<00:16,  2.90epoch/s, loss=1.56]\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "Training:   6%|███▌                                                       | 3/50 [00:01<00:15,  2.95epoch/s, loss=1.56]\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|███▌                                                       | 3/50 [00:01<00:15,  2.95epoch/s, loss=1.56]\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
      "Training:   6%|███▌                                                       | 3/50 [00:00<00:14,  3.16epoch/s, loss=1.55]\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_11068\\2313527096.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/dump/dataset_original/CNNBiLSTM_data_for_classifier/results/classifier_test_no_tuning_Df.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [52]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     59\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(results, columns\u001b[38;5;241m=\u001b[39mcolumns)\n\u001b[0;32m     60\u001b[0m df_results_sorted \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWeighted-F1\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 62\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m     63\u001b[0m     pickle\u001b[38;5;241m.\u001b[39mdump(df_results_sorted, file)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/dump/dataset_original/CNNBiLSTM_data_for_classifier/results/classifier_test_no_tuning_Df.pkl'"
     ]
    }
   ],
   "source": [
    "file_path = \"data/dump/\" + dataset_path + \"/CNNBiLSTM_data_for_classifier/results/classifier_test_no_tuning_Df.pkl\"\n",
    "checkFile = os.path.isfile(file_path)\n",
    "\n",
    "if checkFile: \n",
    "    with open(file_path, \"rb\") as file:\n",
    "        df_results_sorted = pickle.load(file)\n",
    "else:\n",
    "    results = []\n",
    "    num_epochs = 50\n",
    "    batch_size = 64\n",
    "    i = 0\n",
    "\n",
    "    for trainSet, testSet, valSet in dataLoader:\n",
    "        if isinstance(trainSet, list):\n",
    "            trainSet = trainSet[0].squeeze(0)\n",
    "            testSet = testSet[0].squeeze(0)\n",
    "            valSet = valSet[0].squeeze(0)\n",
    "        else:\n",
    "            trainSet = trainSet.squeeze(0)\n",
    "            testSet = testSet.squeeze(0)\n",
    "            valSet = valSet.squeeze(0)\n",
    "\n",
    "        X_tensor, Y_tensor = prep_data(trainSet.clone().detach(), y_train, False)\n",
    "#         deepFC\n",
    "        model, _ = model_train1(X_tensor, Y_tensor, num_epochs, batch_size)\n",
    "        result = classify_emotions(model, X_tensor.clone().detach(), Y_tensor.clone().detach(), 'train', False, i)\n",
    "#         results.append(result)\n",
    "\n",
    "        X_tensor, Y_tensor = prep_data(testSet.clone().detach(), y_test, False)\n",
    "        result = classify_emotions(model, X_tensor.clone().detach(), Y_tensor.clone().detach(), 'test', False, i)\n",
    "        results.append(result)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    i = 0\n",
    "    for trainSet, testSet, valSet in dataLoader:\n",
    "        if isinstance(trainSet, list):\n",
    "            trainSet = trainSet[0].squeeze(0)\n",
    "            testSet = testSet[0].squeeze(0)\n",
    "            valSet = valSet[0].squeeze(0)\n",
    "        else:\n",
    "            trainSet = trainSet.squeeze(0)\n",
    "            testSet = testSet.squeeze(0)\n",
    "            valSet = valSet.squeeze(0)\n",
    "\n",
    "        X_tensor, Y_tensor = prep_data(trainSet, y_train, False)\n",
    "#         simpleFC\n",
    "        model, _ = model_train2(X_tensor, Y_tensor, num_epochs, batch_size)\n",
    "\n",
    "        result = classify_emotions(model, X_tensor, Y_tensor, 'train', True, i)\n",
    "#         results.append(result)\n",
    "\n",
    "        X_tensor, Y_tensor = prep_data(testSet, y_test, False)\n",
    "        result = classify_emotions(model, X_tensor, Y_tensor, 'test', True, i)\n",
    "        results.append(result)\n",
    "        i += 1\n",
    "\n",
    "    columns = ['data_combination', 'typeSet', 'isSimpleFC', 'Accuracy', 'Recall', 'Weighted-F1', 'F1-micro', 'F1-macro']\n",
    "    df = pd.DataFrame(results, columns=columns)\n",
    "    df_results_sorted = df.sort_values(by='Weighted-F1', ascending=False)\n",
    "\n",
    "    with open(file_path, 'wb') as file:\n",
    "        pickle.dump(df_results_sorted, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ed1d0610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_combination</th>\n",
       "      <th>typeSet</th>\n",
       "      <th>isSimpleFC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Weighted-F1</th>\n",
       "      <th>F1-micro</th>\n",
       "      <th>F1-macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cnnbilstm</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.305932</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.09201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cnnbilstm-select-few</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.305932</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.09201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>cnnbilstm-select-mod</td>\n",
       "      <td>test</td>\n",
       "      <td>True</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.305932</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.09201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>cnnbilstm-select-more</td>\n",
       "      <td>test</td>\n",
       "      <td>True</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.305932</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.09201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>dgcn</td>\n",
       "      <td>test</td>\n",
       "      <td>True</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.305932</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.09201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>dgcn-select</td>\n",
       "      <td>test</td>\n",
       "      <td>True</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.305932</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.09201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>gatv1</td>\n",
       "      <td>test</td>\n",
       "      <td>True</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.305932</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.09201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>gatv1-select</td>\n",
       "      <td>test</td>\n",
       "      <td>True</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.305932</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.09201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>gatv1-edge</td>\n",
       "      <td>test</td>\n",
       "      <td>True</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.305932</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.09201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>gatv1-edge-select</td>\n",
       "      <td>test</td>\n",
       "      <td>True</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.305932</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.09201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>gatv2-edge</td>\n",
       "      <td>test</td>\n",
       "      <td>True</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.305932</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.09201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>gatv2-edge-select</td>\n",
       "      <td>test</td>\n",
       "      <td>True</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.305932</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.09201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>rgat</td>\n",
       "      <td>test</td>\n",
       "      <td>True</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.305932</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.09201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>rgat-select</td>\n",
       "      <td>test</td>\n",
       "      <td>True</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.305932</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.09201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>egat</td>\n",
       "      <td>test</td>\n",
       "      <td>True</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.305932</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.09201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>egat-select</td>\n",
       "      <td>test</td>\n",
       "      <td>True</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.305932</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.09201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>cnnbilstm-select-mod-dgcn</td>\n",
       "      <td>test</td>\n",
       "      <td>True</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.305932</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.09201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>cnnbilstm-select-mod-gatv1</td>\n",
       "      <td>test</td>\n",
       "      <td>True</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.305932</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.09201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>cnnbilstm-select-mod-gatv1-edge</td>\n",
       "      <td>test</td>\n",
       "      <td>True</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.305932</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.09201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>cnnbilstm-select-mod-gatv2-edge</td>\n",
       "      <td>test</td>\n",
       "      <td>True</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.305932</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.09201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>cnnbilstm-select-mod-rgat</td>\n",
       "      <td>test</td>\n",
       "      <td>True</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.305932</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.09201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>cnnbilstm-select-few</td>\n",
       "      <td>test</td>\n",
       "      <td>True</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.305932</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.09201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>cnnbilstm</td>\n",
       "      <td>test</td>\n",
       "      <td>True</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.305932</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.09201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>cnnbilstm-select-mod-egat</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.305932</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.09201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gatv2-edge</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.305932</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.09201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cnnbilstm-select-mod</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.305932</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.09201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cnnbilstm-select-more</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.305932</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.09201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dgcn</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.305932</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.09201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dgcn-select</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.305932</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.09201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gatv1</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.305932</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.09201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gatv1-select</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.305932</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.09201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gatv1-edge</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.305932</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.09201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gatv1-edge-select</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.305932</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.09201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gatv2-edge-select</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.305932</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.09201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>cnnbilstm-select-mod-rgat</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.305932</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.09201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>rgat</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.305932</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.09201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>rgat-select</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.305932</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.09201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>egat</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.305932</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.09201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>egat-select</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.305932</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.09201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>cnnbilstm-select-mod-dgcn</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.305932</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.09201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>cnnbilstm-select-mod-gatv1</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.305932</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.09201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>cnnbilstm-select-mod-gatv1-edge</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.305932</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.09201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>cnnbilstm-select-mod-gatv2-edge</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.305932</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.09201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>cnnbilstm-select-mod-egat</td>\n",
       "      <td>test</td>\n",
       "      <td>True</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.305932</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.09201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   data_combination typeSet  isSimpleFC  Accuracy  Recall  \\\n",
       "0                         cnnbilstm    test       False     0.475   0.475   \n",
       "1              cnnbilstm-select-few    test       False     0.475   0.475   \n",
       "24             cnnbilstm-select-mod    test        True     0.475   0.475   \n",
       "25            cnnbilstm-select-more    test        True     0.475   0.475   \n",
       "26                             dgcn    test        True     0.475   0.475   \n",
       "27                      dgcn-select    test        True     0.475   0.475   \n",
       "28                            gatv1    test        True     0.475   0.475   \n",
       "29                     gatv1-select    test        True     0.475   0.475   \n",
       "30                       gatv1-edge    test        True     0.475   0.475   \n",
       "31                gatv1-edge-select    test        True     0.475   0.475   \n",
       "32                       gatv2-edge    test        True     0.475   0.475   \n",
       "33                gatv2-edge-select    test        True     0.475   0.475   \n",
       "34                             rgat    test        True     0.475   0.475   \n",
       "35                      rgat-select    test        True     0.475   0.475   \n",
       "36                             egat    test        True     0.475   0.475   \n",
       "37                      egat-select    test        True     0.475   0.475   \n",
       "38        cnnbilstm-select-mod-dgcn    test        True     0.475   0.475   \n",
       "39       cnnbilstm-select-mod-gatv1    test        True     0.475   0.475   \n",
       "40  cnnbilstm-select-mod-gatv1-edge    test        True     0.475   0.475   \n",
       "41  cnnbilstm-select-mod-gatv2-edge    test        True     0.475   0.475   \n",
       "42        cnnbilstm-select-mod-rgat    test        True     0.475   0.475   \n",
       "23             cnnbilstm-select-few    test        True     0.475   0.475   \n",
       "22                        cnnbilstm    test        True     0.475   0.475   \n",
       "21        cnnbilstm-select-mod-egat    test       False     0.475   0.475   \n",
       "10                       gatv2-edge    test       False     0.475   0.475   \n",
       "2              cnnbilstm-select-mod    test       False     0.475   0.475   \n",
       "3             cnnbilstm-select-more    test       False     0.475   0.475   \n",
       "4                              dgcn    test       False     0.475   0.475   \n",
       "5                       dgcn-select    test       False     0.475   0.475   \n",
       "6                             gatv1    test       False     0.475   0.475   \n",
       "7                      gatv1-select    test       False     0.475   0.475   \n",
       "8                        gatv1-edge    test       False     0.475   0.475   \n",
       "9                 gatv1-edge-select    test       False     0.475   0.475   \n",
       "11                gatv2-edge-select    test       False     0.475   0.475   \n",
       "20        cnnbilstm-select-mod-rgat    test       False     0.475   0.475   \n",
       "12                             rgat    test       False     0.475   0.475   \n",
       "13                      rgat-select    test       False     0.475   0.475   \n",
       "14                             egat    test       False     0.475   0.475   \n",
       "15                      egat-select    test       False     0.475   0.475   \n",
       "16        cnnbilstm-select-mod-dgcn    test       False     0.475   0.475   \n",
       "17       cnnbilstm-select-mod-gatv1    test       False     0.475   0.475   \n",
       "18  cnnbilstm-select-mod-gatv1-edge    test       False     0.475   0.475   \n",
       "19  cnnbilstm-select-mod-gatv2-edge    test       False     0.475   0.475   \n",
       "43        cnnbilstm-select-mod-egat    test        True     0.475   0.475   \n",
       "\n",
       "    Weighted-F1  F1-micro  F1-macro  \n",
       "0      0.305932     0.475   0.09201  \n",
       "1      0.305932     0.475   0.09201  \n",
       "24     0.305932     0.475   0.09201  \n",
       "25     0.305932     0.475   0.09201  \n",
       "26     0.305932     0.475   0.09201  \n",
       "27     0.305932     0.475   0.09201  \n",
       "28     0.305932     0.475   0.09201  \n",
       "29     0.305932     0.475   0.09201  \n",
       "30     0.305932     0.475   0.09201  \n",
       "31     0.305932     0.475   0.09201  \n",
       "32     0.305932     0.475   0.09201  \n",
       "33     0.305932     0.475   0.09201  \n",
       "34     0.305932     0.475   0.09201  \n",
       "35     0.305932     0.475   0.09201  \n",
       "36     0.305932     0.475   0.09201  \n",
       "37     0.305932     0.475   0.09201  \n",
       "38     0.305932     0.475   0.09201  \n",
       "39     0.305932     0.475   0.09201  \n",
       "40     0.305932     0.475   0.09201  \n",
       "41     0.305932     0.475   0.09201  \n",
       "42     0.305932     0.475   0.09201  \n",
       "23     0.305932     0.475   0.09201  \n",
       "22     0.305932     0.475   0.09201  \n",
       "21     0.305932     0.475   0.09201  \n",
       "10     0.305932     0.475   0.09201  \n",
       "2      0.305932     0.475   0.09201  \n",
       "3      0.305932     0.475   0.09201  \n",
       "4      0.305932     0.475   0.09201  \n",
       "5      0.305932     0.475   0.09201  \n",
       "6      0.305932     0.475   0.09201  \n",
       "7      0.305932     0.475   0.09201  \n",
       "8      0.305932     0.475   0.09201  \n",
       "9      0.305932     0.475   0.09201  \n",
       "11     0.305932     0.475   0.09201  \n",
       "20     0.305932     0.475   0.09201  \n",
       "12     0.305932     0.475   0.09201  \n",
       "13     0.305932     0.475   0.09201  \n",
       "14     0.305932     0.475   0.09201  \n",
       "15     0.305932     0.475   0.09201  \n",
       "16     0.305932     0.475   0.09201  \n",
       "17     0.305932     0.475   0.09201  \n",
       "18     0.305932     0.475   0.09201  \n",
       "19     0.305932     0.475   0.09201  \n",
       "43     0.305932     0.475   0.09201  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617e36b6",
   "metadata": {},
   "source": [
    "<h4> Select top 10 unique data combinations then tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36973bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e8a881",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iterations = 10\n",
    "counter = 0\n",
    "combination1 = []\n",
    "combination2 = []\n",
    "seen_combinations = set()\n",
    "\n",
    "for idx, row in df_results_sorted.iterrows():\n",
    "    if counter >= max_iterations:\n",
    "        break\n",
    "\n",
    "    if row['data_combination'] in seen_combinations:\n",
    "        continue\n",
    "\n",
    "    if row['isSimpleFC']:\n",
    "        combination2.append(row['data_combination'])\n",
    "    else:\n",
    "        combination1.append(row['data_combination'])\n",
    "\n",
    "    seen_combinations.add(row['data_combination'])\n",
    "    counter += 1\n",
    "\n",
    "# Display the results\n",
    "print(\"Combination 1 (isSimpleFC=False):\", combination1)\n",
    "print(\"Combination 2 (isSimpleFC=True):\", combination2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54513411",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices1 = [key for key, value in dictKey.items() if value in combination1]\n",
    "indices2 = [key for key, value in dictKey.items() if value in combination2]\n",
    "\n",
    "print(\"Indices for isSimpleFC=False:\", indices1)\n",
    "print(\"Indices for isSimpleFC=True:\", indices2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a5e4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedTrainDeepList = [trainList[i] for i in indices1]\n",
    "selectedTestDeepList = [testList[i] for i in indices1]\n",
    "selectedValDeepList = [valList[i] for i in indices1]\n",
    "\n",
    "len(selectedTrainDeepList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccae3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a1b98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for trainSet in selectedTrainList:\n",
    "    print(type(trainSet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fee3a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedTrainList = [trainList[i] for i in indices2]\n",
    "selectedTestList = [testList[i] for i in indices2]\n",
    "selectedValList = [valList[i] for i in indices2]\n",
    "\n",
    "len(selectedTrainList)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c266050",
   "metadata": {},
   "source": [
    "<h4> Tuning using random parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2dc3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it should call both model_train1 and 2\n",
    "\n",
    "def objective_func(X_train, X_test, X_val, \n",
    "               y_train, y_test, y_val, hyperparams, i_dict, isSimpleFC):\n",
    "    results = []\n",
    "    hyperparams_string = (\n",
    "        f'num_epochs={hyperparams[\"num_epochs\"]} '\n",
    "        f'batch_size={hyperparams[\"batch_size\"]} '\n",
    "        f'loss_difference_threshold={hyperparams[\"loss_difference_threshold\"]} '\n",
    "        f'hidden_dims={hyperparams[\"hidden_dims\"]} '\n",
    "        f'dropout_rate={hyperparams[\"dropout_rate\"]} '\n",
    "        f'learning_rate={hyperparams[\"learning_rate\"]} '\n",
    "        f'optimizers={hyperparams[\"optimizers\"]} '\n",
    "        f'criteria={hyperparams[\"criteria\"]}'\n",
    "    )    \n",
    "    print(hyperparams_string)\n",
    "    def to_tensor(data):\n",
    "        if isinstance(data, torch.Tensor):\n",
    "            return data\n",
    "        elif isinstance(data, np.ndarray):\n",
    "            return torch.tensor(data)\n",
    "        else:\n",
    "            raise TypeError(f\"Unsupported data type: {type(data)}\")\n",
    "            \n",
    "#     X_tensor, Y_tensor = prep_data(X_train.clone().detach(), y_train, False)\n",
    "    X_train_tensor = to_tensor(X_train)\n",
    "    y_train_tensor = to_tensor(y_train).long()\n",
    "    X_val_tensor = to_tensor(X_val)\n",
    "    y_val_tensor = to_tensor(y_val).long()\n",
    "    X_test_tensor = to_tensor(X_test)\n",
    "    y_test_tensor = to_tensor(y_test).long()\n",
    "# train\n",
    "    start_time = time.time()\n",
    "    if isSimpleFC:\n",
    "        model, num_epoch = model_train2(X_train_tensor, y_train_tensor, hyperparams[\"num_epochs\"],\n",
    "                            hyperparams[\"batch_size\"], hyperparams[\"loss_difference_threshold\"], \n",
    "                            hyperparams[\"hidden_dims\"], hyperparams[\"dropout_rate\"],\n",
    "                            hyperparams[\"learning_rate\"], hyperparams[\"optimizers\"], hyperparams[\"criteria\"])        \n",
    "    else:\n",
    "        model, num_epoch = model_train1(X_train_tensor, y_train_tensor, hyperparams[\"num_epochs\"],\n",
    "                            hyperparams[\"batch_size\"], hyperparams[\"loss_difference_threshold\"], \n",
    "                            hyperparams[\"hidden_dims\"], hyperparams[\"dropout_rate\"],\n",
    "                            hyperparams[\"learning_rate\"], hyperparams[\"optimizers\"], hyperparams[\"criteria\"])\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "# val\n",
    "#     X_tensor, Y_tensor = prep_data(X_val.clone().detach(), y_val, False)\n",
    "    result = classify_emotions(model, X_val_tensor, y_val_tensor, \\\n",
    "                               'validation', isSimpleFC, i_dict)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    result = list(result)\n",
    "    hyperparams_string = f'num_epochs={hyperparams[\"num_epochs\"]}-batch_size={hyperparams[\"batch_size\"]}-loss_difference_threshold={hyperparams[\"loss_difference_threshold\"]}-hidden_dims={hyperparams[\"hidden_dims\"]}-dropout_rate={hyperparams[\"dropout_rate\"]}-learning_rate={hyperparams[\"learning_rate\"]}-optimizers={hyperparams[\"optimizers\"]}-criteria={hyperparams[\"criteria\"]}'\n",
    "    result.append(elapsed_time)\n",
    "    result.append(hyperparams_string)\n",
    "    result.append(num_epoch)\n",
    "    results.append(result)\n",
    "    \n",
    "# test\n",
    "#     X_tensor, Y_tensor = prep_data(X_test.clone().detach(), y_test, False)\n",
    "    result = classify_emotions(model, X_test_tensor, y_test_tensor, \\\n",
    "                               'test', isSimpleFC, i_dict)\n",
    "    \n",
    "    result = list(result)\n",
    "    result.append(elapsed_time)\n",
    "    result.append(hyperparams_string)\n",
    "    result.append(num_epoch)\n",
    "    results.append(result)\n",
    "    \n",
    "    columns = ['data_combination', 'typeSet', 'isSimpleFC', 'Accuracy', 'Recall', \\\n",
    "               'Weighted-F1', 'F1-micro', 'F1-macro', 'train_time', 'hyperparams', 'num_epoch']\n",
    "    df = pd.DataFrame(results, columns=columns)\n",
    "    df_results_sorted = df.sort_values(by='data_combination', ascending=False)\n",
    "    \n",
    "    return df_results_sorted\n",
    "\n",
    "\n",
    "# def objective_func(X_train, X_test, X_val, \n",
    "#                y_train, y_test, y_val, hyperparams, i_dict):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f998054f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_search(X_train, X_test, X_val, \\\n",
    "                  y_train, y_test, y_val, \\\n",
    "                  param_grid, isSimpleFC, i_dict, MAX_EVALS = 15):\n",
    "    \n",
    "    sub_total_results = pd.DataFrame(columns = ['data_combination', 'typeSet', 'isSimpleFC', 'Accuracy', 'Recall', \\\n",
    "               'Weighted-F1', 'F1-micro', 'F1-macro', 'train_time', 'hyperparams', 'num_epoch'],)\n",
    "    \n",
    "    for i in range(MAX_EVALS):\n",
    "        hyperparams = {k: random.sample(v, 1)[0] for k, v in param_grid.items()}\n",
    "\n",
    "        try:\n",
    "            new_results = objective_func(X_train, X_test, X_val,  y_train, y_test, y_val,\n",
    "                                hyperparams, i_dict, isSimpleFC)\n",
    "            sub_total_results = pd.concat([sub_total_results, new_results], ignore_index=True)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error with hyperparams {hyperparams}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Sort with best score on top\n",
    "    return sub_total_results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7295744e",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "param_grid1 = {\n",
    "    'num_epochs': [50, 80, 120],\n",
    "    'batch_size': [1, 4, 32, 64],\n",
    "    'loss_difference_threshold': [0.01, 0.001],\n",
    "    'hidden_dims': [[256, 128], [128, 64], [64, 32]],\n",
    "    'dropout_rate': [0.3, 0.5, 0.7],\n",
    "    'learning_rate': [0.001, 0.0001, 0.00001],\n",
    "    'optimizers': [optim.Adam, optim.SGD],\n",
    "    'criteria': [nn.CrossEntropyLoss, nn.NLLLoss]\n",
    "}\n",
    "param_grid2 = {\n",
    "    'num_epochs': [50, 80, 120],\n",
    "    'batch_size': [1, 4, 32, 64],\n",
    "    'loss_difference_threshold': [0.01, 0.001],\n",
    "    'hidden_dims': [128, 256, 512],\n",
    "    'dropout_rate': [0.3, 0.5, 0.7],\n",
    "    'learning_rate': [0.001, 0.0001, 0.00001],\n",
    "    'optimizers': [optim.Adam, optim.SGD],\n",
    "    'criteria': [nn.CrossEntropyLoss, nn.NLLLoss]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fcf2b3",
   "metadata": {},
   "source": [
    "<h5> First find the best hyperparameter combination for the DeepClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163a1cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparamTuning(X_trainSet, X_testSet, X_valSet, y_train, y_test, y_val, isSimpleFC, param_grid, indices):\n",
    "    total_results = pd.DataFrame(columns = ['data_combination', 'typeSet', 'isSimpleFC', 'Accuracy', 'Recall', \\\n",
    "               'Weighted-F1', 'F1-micro', 'F1-macro', 'train_time', 'hyperparams', 'num_epoch'],)\n",
    "    for i in range(len(indices)):\n",
    "        print(\"============ PART \", i, \"============\")\n",
    "        X_train = X_trainSet[i]\n",
    "        X_test = X_testSet[i]\n",
    "        X_val = X_valSet[i]\n",
    "\n",
    "        sub_total_results = random_search(X_train, X_test, X_val, y_train, y_test, y_val,\n",
    "                     param_grid, isSimpleFC, indices[i])\n",
    "        total_results = pd.concat([sub_total_results, total_results], ignore_index=True)\n",
    "\n",
    "    return total_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1fd4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"data/dump/\" + dataset_path + \"/CNNBiLSTM_data_for_classifier/results/deep_classifier_tuned_Df.pkl\"\n",
    "checkFile = os.path.isfile(file_path)\n",
    "\n",
    "if checkFile: \n",
    "    with open(file_path, \"rb\") as file:\n",
    "        total_results1_sorted = pickle.load(file)\n",
    "else:\n",
    "    total_results1 = hyperparamTuning(selectedTrainDeepList, selectedTestDeepList, selectedValDeepList, \\\n",
    "                                 y_train, y_test, y_val, False, param_grid1, indices1)\n",
    "    \n",
    "    total_results1_sorted = total_results1.sort_values(by='Weighted-F1', ascending=False)\n",
    "    with open(file_path, 'wb') as file:\n",
    "        pickle.dump(total_results1_sorted, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c5d2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)  # Show all rows\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.width', None)  # Don't limit the width of the display\n",
    "pd.set_option('display.max_colwidth', None)  # Don't truncate column content\n",
    "\n",
    "total_results1_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d089c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"data/dump/\" + dataset_path + \"/CNNBiLSTM_data_for_classifier/results/simple_classifier_tuned_Df.pkl\"\n",
    "checkFile = os.path.isfile(file_path)\n",
    "\n",
    "if checkFile: \n",
    "    with open(file_path, \"rb\") as file:\n",
    "        total_results2_sorted = pickle.load(file)\n",
    "else: \n",
    "    total_results2 = hyperparamTuning(selectedTrainList, selectedTestList, selectedValList, \\\n",
    "                                     y_train, y_test, y_val, True, param_grid2, indices2)\n",
    "    \n",
    "    total_results2_sorted = total_results2.sort_values(by='Weighted-F1', ascending=False)\n",
    "    with open(file_path, 'wb') as file:\n",
    "        pickle.dump(total_results2_sorted, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7797910f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)  # Show all rows\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.width', None)  # Don't limit the width of the display\n",
    "pd.set_option('display.max_colwidth', None)  # Don't truncate column content\n",
    "    \n",
    "total_results2_sorted"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
