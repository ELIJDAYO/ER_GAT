{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29c3cd42",
   "metadata": {},
   "source": [
    "Put libraries here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "553916bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, os, pickle\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5dc1152",
   "metadata": {},
   "source": [
    "Code related to GAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ecf3858",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DialogueGraphDataLoader(DataLoader):\n",
    "    def __init__(self, node_features_list, edge_index_list, batch_size=1, shuffle=False):\n",
    "        graph_dataset = DialogueGraphDataset(node_features_list, edge_index_list)\n",
    "        super().__init__(graph_dataset, batch_size, shuffle, collate_fn=dialogue_graph_collate_fn)\n",
    "\n",
    "class DialogueGraphDataset(Dataset):\n",
    "    def __init__(self, node_features_list, edge_index_list):\n",
    "        self.node_features_list = node_features_list\n",
    "        self.edge_index_list = edge_index_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.edge_index_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.node_features_list[idx], self.edge_index_list[idx]\n",
    "\n",
    "def dialogue_graph_collate_fn(batch):\n",
    "    node_features_list, edge_index_list = zip(*batch)\n",
    "    \n",
    "    node_features_list_combined = []\n",
    "    num_nodes_seen = 0\n",
    "\n",
    "    for node_features, edge_index in zip(node_features_list, edge_index_list):\n",
    "        # Assuming node_features is a tuple (text_embeddings, speakers_list)\n",
    "        text_embeddings, speakers_list = node_features\n",
    "        combined_features = (text_embeddings, speakers_list)\n",
    "\n",
    "        node_features_list_combined.append(combined_features)\n",
    "\n",
    "        # Translate the range of edge_index\n",
    "        edge_index_list.append(edge_index + num_nodes_seen)\n",
    "        num_nodes_seen += len(text_embeddings)\n",
    "\n",
    "    # Merge the dialogue graphs into a single graph with multiple connected components\n",
    "    node_features_combined = [torch.cat(features, 1) for features in zip(*node_features_list_combined)]\n",
    "    edge_index = torch.cat(edge_index_list, 1)\n",
    "\n",
    "    return node_features_combined, edge_index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539e3ed3",
   "metadata": {},
   "source": [
    "Some methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c53e5417",
   "metadata": {
    "code_folding": [
     0,
     20,
     42
    ]
   },
   "outputs": [],
   "source": [
    "def create_node_pairs_dict(start_idx, end_idx):\n",
    "    # Initialize an empty list to store pairs\n",
    "    list_node_i = []\n",
    "    list_node_j = []\n",
    "#     node_pairs_dict = {}\n",
    "    end_idx = end_idx - start_idx\n",
    "    start_idx = 0\n",
    "    for i in range(start_idx, end_idx+1):\n",
    "        val = 3\n",
    "        while(val >= 0):\n",
    "            target_idx = i-val\n",
    "#                 print(target_idx)\n",
    "            if target_idx >= 0:\n",
    "                list_node_i.append(i)\n",
    "                list_node_j.append(target_idx)\n",
    "#                 node_pairs_dict[i] = target_idx\n",
    "            val = val-1\n",
    "    \n",
    "    return [list_node_i, list_node_j]\n",
    "\n",
    "def create_adjacency_list(node_pairs):\n",
    "    adjacency_list_dict = {}\n",
    "\n",
    "    # Iterate through pairs of nodes\n",
    "    for i in range(0, len(node_pairs[0])):\n",
    "        source_node, target_node = node_pairs[0][i], node_pairs[1][i]\n",
    "\n",
    "#         # Add source node to target node's neighbors\n",
    "#         if target_node not in adjacency_list_dict:\n",
    "#             adjacency_list_dict[target_node] = [source_node]\n",
    "#         else:\n",
    "#             adjacency_list_dict[target_node].append(source_node)\n",
    "\n",
    "        # Add target node to source node's neighbors\n",
    "        if source_node not in adjacency_list_dict:\n",
    "            adjacency_list_dict[source_node] = [target_node]\n",
    "        else:\n",
    "            adjacency_list_dict[source_node].append(target_node)\n",
    "\n",
    "    return adjacency_list_dict\n",
    "# print(ranges[:1])\n",
    "\n",
    "def get_all_adjacency_list(ranges):\n",
    "    all_adjacency_list = []\n",
    "    for range_pair in ranges:\n",
    "        start_idx, end_idx = range_pair\n",
    "        output = create_node_pairs_dict(start_idx, end_idx)\n",
    "#         print(output)\n",
    "\n",
    "        output = create_adjacency_list(output)\n",
    "        all_adjacency_list.append(output)\n",
    "    return all_adjacency_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "20cb34a8",
   "metadata": {
    "code_folding": [
     2,
     4
    ]
   },
   "outputs": [],
   "source": [
    "checkFile = os.path.isfile(\"data/dump/speaker_encoder.pkl\")\n",
    "encoded_speaker_list = []\n",
    "if checkFile is False:\n",
    "    print(\"Run first the prototype_context_encoder to generate this file\")\n",
    "else:\n",
    "    file = open('data/dump/speaker_encoder.pkl', \"rb\")\n",
    "    encoded_speaker_list, ranges = pickle.load(file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fb6bc790",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkFile = os.path.isfile(\"data/dump/all_adjacency_list.pkl\")\n",
    "adjacency_list = []\n",
    "if checkFile is False:\n",
    "    adjacency_list = get_all_adjacency_list(ranges)\n",
    "else:\n",
    "    file = open('data/dump/all_adjacency_list.pkl', \"rb\")\n",
    "    adjacency_list = pickle.load(file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "64d5fc23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{0: [0],\n",
       "  1: [0, 1],\n",
       "  2: [0, 1, 2],\n",
       "  3: [0, 1, 2, 3],\n",
       "  4: [1, 2, 3, 4],\n",
       "  5: [2, 3, 4, 5],\n",
       "  6: [3, 4, 5, 6],\n",
       "  7: [4, 5, 6, 7],\n",
       "  8: [5, 6, 7, 8],\n",
       "  9: [6, 7, 8, 9],\n",
       "  10: [7, 8, 9, 10],\n",
       "  11: [8, 9, 10, 11],\n",
       "  12: [9, 10, 11, 12],\n",
       "  13: [10, 11, 12, 13]},\n",
       " {0: [0],\n",
       "  1: [0, 1],\n",
       "  2: [0, 1, 2],\n",
       "  3: [0, 1, 2, 3],\n",
       "  4: [1, 2, 3, 4],\n",
       "  5: [2, 3, 4, 5],\n",
       "  6: [3, 4, 5, 6]}]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adjacency_list[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8072d0b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2160"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(adjacency_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7f02158e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'embed/updated_representation_list.pkl'\n",
    "\n",
    "# Load the list from the file using pickle\n",
    "with open(file_path, 'rb') as file:\n",
    "    updated_representations = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "293f6d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([14, 300])\n",
      "tensor([[-2.8721e-01,  5.8134e-01, -1.3142e-01,  ...,  1.8101e-02,\n",
      "         -4.6824e-04,  1.9901e-02],\n",
      "        [-1.6920e-01,  1.8220e-01, -1.2245e-01,  ...,  1.3620e-02,\n",
      "         -2.0732e-03,  8.3473e-03],\n",
      "        [-8.1502e-02,  7.7161e-02, -6.6144e-02,  ...,  1.3882e-02,\n",
      "          3.4588e-03, -1.4834e-03],\n",
      "        ...,\n",
      "        [-4.1162e-03,  2.6335e-02,  2.8706e-02,  ..., -1.6475e-01,\n",
      "         -1.3978e-01,  2.8344e-02],\n",
      "        [-1.7579e-02,  1.8380e-02,  3.3130e-02,  ..., -2.5659e-01,\n",
      "         -2.2489e-01,  1.5857e-02],\n",
      "        [-2.9680e-02,  8.5039e-03,  3.3814e-02,  ..., -3.8804e-01,\n",
      "         -2.8153e-01,  1.1250e-03]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(updated_representations[0].shape)\n",
    "print(updated_representations[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
