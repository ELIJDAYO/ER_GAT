{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e46ede1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,re, time, pickle, collections, importlib, datetime, torch, nltk, pandas as pd, numpy as np\n",
    "from chardet import detect\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from collections import defaultdict, Counter\n",
    "from wordebd import WORDEBD\n",
    "from vocab import Vocab, Vectors\n",
    "from munch import Munch\n",
    "from cnnlstmseq import CNNLSTMseq\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import transformers\n",
    "\n",
    "# Autoreload extensions (if you're using Jupyter Notebook or IPython)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f23de1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "key=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a273b63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoding_type(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        rawdata = f.read()\n",
    "    return detect(rawdata)['encoding']\n",
    "\n",
    "def detect_misspelling(source):\n",
    "    pass\n",
    "\n",
    "def replace_spelling(source):\n",
    "    return re.sub(\"Åf\", \"'\", source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08e24b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(data):\n",
    "    '''\n",
    "    Preprocess text data\n",
    "    @param data: list of text examples\n",
    "    @return preprocessed_data: list of preprocessed text examples\n",
    "    '''\n",
    "    preprocessed_data = []\n",
    "    for example in data:\n",
    "        # Convert to lowercase\n",
    "        example = example.lower()\n",
    "        # Remove punctuation\n",
    "        example = re.sub(r'[^\\w\\s]', '\\'', example)\n",
    "        preprocessed_data.append(example)\n",
    "    return preprocessed_data\n",
    "\n",
    "def load_pretrained_glove():\n",
    "    print(\"Loading GloVe...\")\n",
    "    glv_vector = {}\n",
    "    f = open('/embed/glove/glove.840B.300d.txt', encoding='utf-8')\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word, coefs = values[0], np.asarray(values[1:], dtype='float')\n",
    "        try:\n",
    "            glv_vector[word] = coefs\n",
    "        except ValueError:\n",
    "            continue\n",
    "    f.close()\n",
    "    start_time = time.time()\n",
    "    print(f\"Took {time.time() - start_time} seconds to load pretrained GloVe model.\")\n",
    "    return glv_vector\n",
    "\n",
    "def encode_labels(encoder, l):\n",
    "    return encoder[l]\n",
    "\n",
    "def _read_words(data, convmode=None):\n",
    "    '''    \n",
    "    Count the occurrences of all words\n",
    "    @param convmode: str, None for non conversational scope, 'naive' for classic or naive approach, 'conv' for conversation depth into account (one additional dim and nested values)\n",
    "    @param data: list of examples\n",
    "    @return words: list of words (with duplicates)\n",
    "    '''    \n",
    "    words = []\n",
    "    if convmode is None:\n",
    "        for example in data:\n",
    "            words += example.split()\n",
    "    return words\n",
    "\n",
    "def find_value_ranges(lst):\n",
    "    value_ranges = []\n",
    "    start_index = 0\n",
    "\n",
    "    for i in range(1, len(lst)):\n",
    "        if lst[i] != lst[i - 1]:\n",
    "            value_ranges.append((start_index, i - 1))\n",
    "            start_index = i\n",
    "\n",
    "    # Add the last range\n",
    "    value_ranges.append((start_index, len(lst) - 1))\n",
    "\n",
    "    return value_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d2cf5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12840, 12)\n",
      "(3400, 12)\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV file\n",
    "X_train = pd.read_csv('data/train_sent_emo_dya.csv', encoding='MacRoman')\n",
    "X_test = pd.read_csv('data/test_sent_emo_dya.csv', encoding='MacRoman')\n",
    "\n",
    "# Display the first three rows\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5825e9de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           Utterance          Speaker  \\\n",
      "0  also I was the point person on my companyÅfs t...         Chandler   \n",
      "1                  You mustÅfve had your hands full.  The Interviewer   \n",
      "2                            That I did. That I did.         Chandler   \n",
      "\n",
      "   Emotion Sentiment  Dialogue_ID  Utterance_ID  \n",
      "0  neutral   neutral            0             0  \n",
      "1  neutral   neutral            0             1  \n",
      "2  neutral   neutral            0             2  \n",
      "   Emotion  Dialogue_ID\n",
      "0  neutral            0\n",
      "1  neutral            0\n",
      "2  neutral            0\n",
      "                                           Utterance Speaker   Emotion  \\\n",
      "0  Why do all you‚Äôre coffee mugs have numbers o...    Mark  surprise   \n",
      "1  Oh. That‚Äôs so Monica can keep track. That wa...  Rachel     anger   \n",
      "2                                       Y'know what?  Rachel   neutral   \n",
      "\n",
      "  Sentiment  Dialogue_ID  Utterance_ID  Old_Dialogue_ID  Old_Utterance_ID  \\\n",
      "0  positive            0             0                0                 0   \n",
      "1  negative            0             1                0                 1   \n",
      "2   neutral            0             2                0                 2   \n",
      "\n",
      "   Season  Episode     StartTime       EndTime  \n",
      "0       3       19  00:14:38,127  00:14:40,378  \n",
      "1       3       19  00:14:40,629  00:14:47,385  \n",
      "2       3       19  00:14:56,353  00:14:57,520  \n",
      "    Emotion  Dialogue_ID\n",
      "0  surprise            0\n",
      "1     anger            0\n",
      "2   neutral            0\n"
     ]
    }
   ],
   "source": [
    "# Define features to drop\n",
    "drop_features = list(X_train.columns[6:]) \n",
    "\n",
    "# Create DataFrame for target labels\n",
    "y_train = pd.DataFrame()\n",
    "y_test = pd.DataFrame()\n",
    "\n",
    "y_train[\"Emotion\"] = X_train[\"Emotion\"].copy()\n",
    "y_test[\"Emotion\"] = X_test[\"Emotion\"].copy()\n",
    "\n",
    "y_train[\"Dialogue_ID\"] = X_train[\"Dialogue_ID\"].copy()\n",
    "y_test[\"Dialogue_ID\"] = X_test[\"Dialogue_ID\"].copy()\n",
    "\n",
    "# Drop features from X_train DataFrame\n",
    "X_train = X_train.drop(drop_features, axis=1)\n",
    "\n",
    "print(X_train[:3])\n",
    "print(y_train[:3])\n",
    "\n",
    "print(X_test[:3])\n",
    "print(y_test[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b73b303f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Utterance          Speaker  \\\n",
      "0   also i was the point person on my company's tr...         Chandler   \n",
      "1                    you must've had your hands full'  The Interviewer   \n",
      "2                             that i did' that i did'         Chandler   \n",
      "3       so let's talk a little bit about your duties'  The Interviewer   \n",
      "4                              my duties'  all right'         Chandler   \n",
      "5   now you'll be heading a whole division' so you...  The Interviewer   \n",
      "6                                              i see'         Chandler   \n",
      "7   but there'll be perhaps 30 people under you so...  The Interviewer   \n",
      "8                                       good to know'         Chandler   \n",
      "9                               we can go into detail  The Interviewer   \n",
      "10                             no don't i beg of you'         Chandler   \n",
      "11  all right then' we'll have a definite answer f...  The Interviewer   \n",
      "12                                           really''         Chandler   \n",
      "13                         absolutely'  you can relax  The Interviewer   \n",
      "\n",
      "     Emotion Sentiment  Dialogue_ID  Utterance_ID  \n",
      "0    neutral   neutral            0             0  \n",
      "1    neutral   neutral            0             1  \n",
      "2    neutral   neutral            0             2  \n",
      "3    neutral   neutral            0             3  \n",
      "4   surprise  positive            0             4  \n",
      "5    neutral   neutral            0             5  \n",
      "6    neutral   neutral            0             6  \n",
      "7    neutral   neutral            0             7  \n",
      "8    neutral   neutral            0             8  \n",
      "9    neutral   neutral            0             9  \n",
      "10      fear  negative            0            10  \n",
      "11   neutral   neutral            0            11  \n",
      "12  surprise  positive            0            12  \n",
      "13   neutral   neutral            0            13  \n"
     ]
    }
   ],
   "source": [
    "X_train[\"Utterance\"] = X_train[\"Utterance\"].apply(lambda x: replace_spelling(x))\n",
    "X_test[\"Utterance\"] = X_test[\"Utterance\"].apply(lambda x: replace_spelling(x))\n",
    "\n",
    "X_train[\"Utterance\"] = preprocess_text(X_train[\"Utterance\"].tolist())\n",
    "X_test[\"Utterance\"] = preprocess_text(X_test[\"Utterance\"].tolist())\n",
    "\n",
    "# Print the first 14 rows of X_train DataFrame\n",
    "print(X_train[:14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86036b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkFile1 = os.path.isfile(\"data/dump/label_encoder.pkl\")\n",
    "checkFile2 = os.path.isfile(\"data/dump/label_decoder.pkl\")\n",
    "\n",
    "if key:\n",
    "    labels = sorted(set(y_train.Emotion))\n",
    "    labelEncoder = {label: i for i, label in enumerate(labels)}\n",
    "    labelDecoder = {i: label for i, label in enumerate(labels)}\n",
    "\n",
    "    pickle.dump(labelEncoder, open('data/dump/label_encoder.pkl', 'wb'))\n",
    "    pickle.dump(labelDecoder, open('data/dump/label_decoder.pkl', 'wb'))\n",
    "else:\n",
    "    file1 = open('data/dump/label_encoder.pkl', 'rb')\n",
    "    file2 = open('data/dump/label_decoder.pkl', 'rb')\n",
    "    labelEncoder = pickle.load(file1)\n",
    "    labelDecoder = pickle.load(file2)\n",
    "    file1.close()\n",
    "    file2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2d0af03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anger': 0,\n",
       " 'disgust': 1,\n",
       " 'fear': 2,\n",
       " 'joy': 3,\n",
       " 'neutral': 4,\n",
       " 'sadness': 5,\n",
       " 'surprise': 6}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6211e8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply label encoding to the \"Emotion\" column in y_train\n",
    "y_train[\"Emotion\"] = y_train[\"Emotion\"].apply(lambda x: encode_labels(labelEncoder, x))\n",
    "y_test[\"Emotion\"] = y_test[\"Emotion\"].apply(lambda x: encode_labels(labelEncoder, x))\n",
    "\n",
    "# Copy the encoded \"Emotion\" column from y_train to X_train\n",
    "X_train[\"Emotion\"] = y_train[\"Emotion\"].copy()\n",
    "X_test[\"Emotion\"] = y_test[\"Emotion\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0db6676b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the file already exists\n",
    "checkFile1 = os.path.isfile(\"data/dump/labels_train.pkl\")\n",
    "checkFile2 = os.path.isfile(\"data/dump/labels_test.pkl\")\n",
    "\n",
    "if key:\n",
    "    pickle.dump(X_train[\"Emotion\"], open('data/dump/labels_train.pkl', 'wb'))\n",
    "    pickle.dump(X_test[\"Emotion\"], open('data/dump/labels_test.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1a4583",
   "metadata": {},
   "source": [
    "Creating an embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19929c11",
   "metadata": {},
   "source": [
    "Testing on smaller data. Uncomment to see the size of updated representations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da518513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of contextual embeddings: torch.Size([8, 768])\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained BERT model and tokenizer\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = transformers.BertTokenizer.from_pretrained(model_name)\n",
    "model = transformers.BertModel.from_pretrained(model_name)\n",
    "\n",
    "# Define your dialog data\n",
    "dialogs = [\n",
    "    \"How are you today?\",\n",
    "    \"I'm doing well, thank you!\",\n",
    "    \"That's good to hear.\",\n",
    "    \"Yes, it is.\",\n",
    "    \"Do you have any plans for the weekend?\",\n",
    "    \"Not really, just relaxing at home.\",\n",
    "    \"Sounds nice.\",\n",
    "    \"Indeed.\"\n",
    "]\n",
    "\n",
    "# Tokenize and encode the dialogs\n",
    "encoded_dialogs = [tokenizer.encode(dialog, add_special_tokens=True) for dialog in dialogs]\n",
    "\n",
    "# Pad sequences to the same length\n",
    "max_length = max(len(dialog) for dialog in encoded_dialogs)\n",
    "padded_dialogs = [dialog + [tokenizer.pad_token_id] * (max_length - len(dialog)) for dialog in encoded_dialogs]\n",
    "\n",
    "# Create attention masks\n",
    "attention_masks = [[1] * len(dialog) + [0] * (max_length - len(dialog)) for dialog in encoded_dialogs]\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "input_ids = torch.tensor(padded_dialogs)\n",
    "attention_masks = torch.tensor(attention_masks)\n",
    "\n",
    "# Obtain the BERT embeddings\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids, attention_mask=attention_masks)\n",
    "\n",
    "# Extract the contextual embeddings (CLS token)\n",
    "contextual_embeddings = outputs[0][:, 0, :]  # Extract embeddings for the [CLS] token\n",
    "\n",
    "# Print the shape of the contextual embeddings\n",
    "print(\"Shape of contextual embeddings:\", contextual_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618d7e17",
   "metadata": {},
   "source": [
    "This is just a duplicate of code above. Using this on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3718155a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2160\n",
      "577\n"
     ]
    }
   ],
   "source": [
    "rangesTrain = find_value_ranges(X_train[\"Dialogue_ID\"])\n",
    "print(len(rangesTrain))\n",
    "\n",
    "rangesTest = find_value_ranges(X_test[\"Dialogue_ID\"])\n",
    "print(len(rangesTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c509245",
   "metadata": {},
   "source": [
    "Testing on small sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63595e55",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# # Load pre-trained BERT model and tokenizer\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# # List of text dialogs\n",
    "# dialogs = [\n",
    "#     [\"How are you today?\", \"I'm doing well, thank you!\"],\n",
    "#     [\"That's good to hear.\", \"Yes, it is.\", \"Do you have any plans for the weekend?\", \"Not really, just relaxing at home.\"],\n",
    "#     [\"Sounds nice.\", \"Indeed.\"]\n",
    "# ]\n",
    "\n",
    "# # List to store contextual embeddings for each utterance\n",
    "# contextual_embeddings = []\n",
    "\n",
    "# # Iterate through each dialog\n",
    "# for dialog in dialogs:\n",
    "#     # Tokenize and convert dialog to input IDs\n",
    "#     inputs = tokenizer(dialog, return_tensors='pt', padding=True, truncation=True)\n",
    "    \n",
    "#     # Get BERT model outputs\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(**inputs)\n",
    "\n",
    "#     # Extract contextual embeddings (CLS token represents the entire sequence)\n",
    "#     embeddings = outputs.last_hidden_state[:, 0, :].tolist()\n",
    "\n",
    "#     # Store embeddings for each utterance in the dialog\n",
    "#     contextual_embeddings.append(embeddings)\n",
    "\n",
    "# # Print the list of contextual embeddings\n",
    "# print(\"List of Contextual Embeddings:\")\n",
    "# # for embedding in contextual_embeddings:\n",
    "# #     print(embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66db3fa",
   "metadata": {},
   "source": [
    "#### Contexualized train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7abe85c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the file doesn't exist, compute updated representations and save them\n",
    "if key:\n",
    "    dialogs = []\n",
    "    for range_pair, iteration in zip(rangesTrain, range(len(rangesTrain))):\n",
    "        start_idx, end_idx = range_pair            \n",
    "        dialog = list(X_train['Utterance'][start_idx:end_idx + 1])\n",
    "        dialogs.append(dialog)\n",
    "\n",
    "    # List to store contextual embeddings for each utterance\n",
    "    contextualEmbeddingsTrain = []\n",
    "\n",
    "    # Iterate through each dialog\n",
    "    for dialog in dialogs:\n",
    "        # Tokenize and convert dialog to input IDs\n",
    "        inputs = tokenizer(dialog, return_tensors='pt', padding=True, truncation=True)\n",
    "\n",
    "        # Get BERT model outputs\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        # Extract contextual embeddings (CLS token represents the entire sequence)\n",
    "        embeddings = outputs.last_hidden_state[:, 0, :].tolist()\n",
    "\n",
    "        # Store embeddings for each utterance in the dialog\n",
    "        contextualEmbeddingsTrain.append(torch.tensor(embeddings))\n",
    "\n",
    "#         if iteration % 800 == 0 | iteration == len(ranges):\n",
    "    file_path = f'embed/u_prime_BERT_train.pkl'\n",
    "    with open(file_path, 'wb') as file:\n",
    "            pickle.dump(contextualEmbeddingsTrain, file)\n",
    "\n",
    "else:\n",
    "    file_path = f'embed/u_prime_BERT_train.pkl'\n",
    "    with open(file_path, 'rb') as file:\n",
    "        contextualEmbeddingsTrain = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d54912",
   "metadata": {},
   "source": [
    "<h4> Contexualize test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b03a417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the file doesn't exist, compute updated representations and save them\n",
    "if key:\n",
    "    dialogs = []\n",
    "    for range_pair, iteration in zip(rangesTest, range(len(rangesTest))):\n",
    "        start_idx, end_idx = range_pair            \n",
    "        dialog = list(X_train['Utterance'][start_idx:end_idx + 1])\n",
    "        dialogs.append(dialog)\n",
    "\n",
    "    # List to store contextual embeddings for each utterance\n",
    "    contextualEmbeddingsTest = []\n",
    "\n",
    "    # Iterate through each dialog\n",
    "    for dialog in dialogs:\n",
    "        # Tokenize and convert dialog to input IDs\n",
    "        inputs = tokenizer(dialog, return_tensors='pt', padding=True, truncation=True)\n",
    "\n",
    "        # Get BERT model outputs\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        # Extract contextual embeddings (CLS token represents the entire sequence)\n",
    "        embeddings = outputs.last_hidden_state[:, 0, :].tolist()\n",
    "\n",
    "        # Store embeddings for each utterance in the dialog\n",
    "        contextualEmbeddingsTest.append(torch.tensor(embeddings))\n",
    "\n",
    "#         if iteration % 800 == 0 | iteration == len(ranges):\n",
    "    file_path = f'embed/u_prime_BERT_test.pkl'\n",
    "    with open(file_path, 'wb') as file:\n",
    "            pickle.dump(contextualEmbeddingsTest, file)\n",
    "\n",
    "else:\n",
    "    file_path = f'embed/u_prime_BERT_test.pkl'\n",
    "    with open(file_path, 'rb') as file:\n",
    "        contextualEmbeddingsTest = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a606e9e",
   "metadata": {},
   "source": [
    "<h4> Getting speaker encoder for train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "65ff6791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the file exists\n",
    "checkFile = os.path.isfile(\"data/dump/speaker_encoder_train.pkl\")\n",
    "encodedSpeakersTrain = []\n",
    "\n",
    "if key:\n",
    "    for range_pair in rangesTrain:\n",
    "        start_idx, end_idx = range_pair\n",
    "        speaker_per_dialog = X_train['Speaker'][start_idx:end_idx + 1].copy()\n",
    "        speaker_feature = sorted(set(speaker_per_dialog))\n",
    "        speaker_encoder = {feature: i for i, feature in enumerate(speaker_feature)}\n",
    "        speaker_decoder = {i: feature for i, feature in enumerate(speaker_feature)}\n",
    "\n",
    "        encoded_speaker = speaker_per_dialog.replace(speaker_encoder)\n",
    "        encodedSpeakersTrain.append(encoded_speaker)\n",
    "\n",
    "    # Save encoded speaker list and ranges to a file using pickle\n",
    "    file_path = 'data/dump/speaker_encoder_train.pkl'\n",
    "    with open(file_path, 'wb') as file:\n",
    "        pickle.dump([encodedSpeakersTrain, rangesTrain], file)\n",
    "else:\n",
    "    # Load encoded speaker list and ranges from the existing pickle file\n",
    "    file = open('data/dump/speaker_encoder_train.pkl', \"rb\")\n",
    "    encodedSpeakersTrain, rangesTrain = pickle.load(file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e219fa5",
   "metadata": {},
   "source": [
    "<h4> Getting speaker encoder for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9beaa84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the file exists\n",
    "checkFile = os.path.isfile(\"data/dump/speaker_encoder_test.pkl\")\n",
    "encodedSpeakersTest = []\n",
    "\n",
    "if key:\n",
    "    for range_pair in rangesTest:\n",
    "        start_idx, end_idx = range_pair\n",
    "        speaker_per_dialog = X_train['Speaker'][start_idx:end_idx + 1].copy()\n",
    "        speaker_feature = sorted(set(speaker_per_dialog))\n",
    "        speaker_encoder = {feature: i for i, feature in enumerate(speaker_feature)}\n",
    "        speaker_decoder = {i: feature for i, feature in enumerate(speaker_feature)}\n",
    "\n",
    "        encoded_speaker = speaker_per_dialog.replace(speaker_encoder)\n",
    "        encodedSpeakersTest.append(encoded_speaker)\n",
    "\n",
    "    # Save encoded speaker list and ranges to a file using pickle\n",
    "    file_path = 'data/dump/speaker_encoder_test.pkl'\n",
    "    with open(file_path, 'wb') as file:\n",
    "        pickle.dump([encodedSpeakersTest, rangesTest], file)\n",
    "else:\n",
    "    # Load encoded speaker list and ranges from the existing pickle file\n",
    "    file = open('data/dump/speaker_encoder_test.pkl', \"rb\")\n",
    "    encodedSpeakersTest, rangesTest = pickle.load(file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530a19cb",
   "metadata": {},
   "source": [
    "Unsupervised visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b5f1de43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6144])\n"
     ]
    }
   ],
   "source": [
    "# Assuming contextual_embeddings is your list of contextual embeddings\n",
    "\n",
    "# Flatten the list of contextual embeddings into a single list\n",
    "flattened_embeddings = [emb for dialogue in contextual_embeddings for emb in dialogue]\n",
    "\n",
    "# Convert the flattened list into a single tensor\n",
    "tensor_data = torch.tensor(flattened_embeddings)\n",
    "\n",
    "# Check the shape of the tensor\n",
    "print(tensor_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "12995d9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'anger',\n",
       " 1: 'disgust',\n",
       " 2: 'fear',\n",
       " 3: 'joy',\n",
       " 4: 'neutral',\n",
       " 5: 'sadness',\n",
       " 6: 'surprise'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelDecoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbb8c52",
   "metadata": {},
   "source": [
    "Distribution of labels in train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3d031c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anger: 1500 train occurrences\n",
      "disgust: 364 train occurrences\n",
      "fear: 338 train occurrences\n",
      "joy: 2312 train occurrences\n",
      "neutral: 5960 train occurrences\n",
      "sadness: 876 train occurrences\n",
      "surprise: 1490 train occurrences\n"
     ]
    }
   ],
   "source": [
    "# Calculate the counts for each unique label\n",
    "uniqueLabelsTrain, labelCountsTrain = np.unique(list(X_train[\"Emotion\"]), return_counts=True)\n",
    "\n",
    "# Print the counts for each unique label\n",
    "for label, count in zip(uniqueLabelsTrain, labelCountsTrain):\n",
    "    print(f\"{labelDecoder[label]}: {count} train occurrences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f53cc6",
   "metadata": {},
   "source": [
    "Distribution of labels in test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f23dd72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anger: 516 train occurrences\n",
      "disgust: 99 train occurrences\n",
      "fear: 60 train occurrences\n",
      "joy: 495 train occurrences\n",
      "neutral: 1615 train occurrences\n",
      "sadness: 263 train occurrences\n",
      "surprise: 352 train occurrences\n"
     ]
    }
   ],
   "source": [
    "# Calculate the counts for each unique label\n",
    "uniqueLabelsTest, labelCountsTest = np.unique(list(X_test[\"Emotion\"]), return_counts=True)\n",
    "\n",
    "# Print the counts for each unique label\n",
    "for label, count in zip(uniqueLabelsTest, labelCountsTest):\n",
    "    print(f\"{labelDecoder[label]}: {count} train occurrences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c07b8f",
   "metadata": {},
   "source": [
    "Visualize utterance embeddnig (u') with T-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3d430fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = torch.tensor(X_train[\"Emotion\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f1043832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed63efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# runTSNE = 1\n",
    "# if runTSNE:\n",
    "#     from sklearn.manifold import TSNE\n",
    "#     import matplotlib.pyplot as plt\n",
    "\n",
    "#     # List of perplexity values to loop over\n",
    "#     perplexity_values = [50]\n",
    "\n",
    "#     # Loop over each perplexity value\n",
    "#     for perplexity in perplexity_values:\n",
    "#         # Initialize t-SNE with the current perplexity value\n",
    "#         tsne = TSNE(n_components=2, perplexity=perplexity, random_state=42)\n",
    "\n",
    "#         # Fit and transform the data using t-SNE\n",
    "#         h_prime_tsne = tsne.fit_transform(tensor_data.detach().numpy())\n",
    "\n",
    "#         # Plot the node embeddings with different colors for each label\n",
    "#         plt.figure(figsize=(10, 8))\n",
    "#         for label, emotion in zip(range(len(label_encoder)), label_encoder):\n",
    "#             indices = (labels == label).nonzero().squeeze()\n",
    "#             plt.scatter(h_prime_tsne[indices, 0], h_prime_tsne[indices, 1], label=f'{emotion}')\n",
    "#         plt.title(f'Utterance Embeddings (Train) Visualization (t-SNE) - Perplexity {perplexity}', color=\"white\")\n",
    "#         plt.xlabel('Dimension 1', color=\"white\")\n",
    "#         plt.ylabel('Dimension 2', color=\"white\")\n",
    "#         plt.legend()\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e2170c",
   "metadata": {},
   "source": [
    " Visualize utterance embedding (u') with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e6dc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca = PCA(n_components=2)\n",
    "# pca_result = pca.fit_transform(tensor_data.detach().numpy())\n",
    "\n",
    "# # Plot the PCA result with color-coded labels\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# for label in np.unique(labels):\n",
    "#     indices = labels == label\n",
    "#     plt.scatter(pca_result[indices, 0], pca_result[indices, 1], label=f'{label_decoder[label]}', alpha=0.5)\n",
    "#     plt.title('PCA Visualization of Utterance Embeddings (Train) with Color-Coded Labels')\n",
    "#     plt.xlabel('Principal Component 1')\n",
    "#     plt.ylabel('Principal Component 2')\n",
    "#     plt.legend()\n",
    "#     plt.grid(True)\n",
    "#     plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
