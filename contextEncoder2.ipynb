{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e46ede1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os,re, time, pickle, collections, importlib, datetime, torch, nltk, pandas as pd, numpy as np, time\n",
    "from chardet import detect\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from collections import defaultdict, Counter\n",
    "from wordebd import WORDEBD\n",
    "from vocab import Vocab, Vectors\n",
    "from munch import Munch\n",
    "from cnnlstmseq import CNNLSTMseq\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import transformers\n",
    "\n",
    "# Autoreload extensions (if you're using Jupyter Notebook or IPython)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f23de1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "key=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a273b63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoding_type(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        rawdata = f.read()\n",
    "    return detect(rawdata)['encoding']\n",
    "\n",
    "def detect_misspelling(source):\n",
    "    pass\n",
    "\n",
    "def replace_spelling(source):\n",
    "    return re.sub(\"\", \"\", source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08e24b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(data):\n",
    "    '''\n",
    "    Preprocess text data\n",
    "    @param data: list of text examples\n",
    "    @return preprocessed_data: list of preprocessed text examples\n",
    "    '''\n",
    "    preprocessed_data = []\n",
    "    for example in data:\n",
    "        # Convert to lowercase\n",
    "        example = example.lower()\n",
    "        # Remove punctuation\n",
    "        example = re.sub(r'[^\\w\\s]', '\\'', example)\n",
    "        preprocessed_data.append(example)\n",
    "    return preprocessed_data\n",
    "\n",
    "def load_pretrained_glove():\n",
    "    print(\"Loading GloVe...\")\n",
    "    glv_vector = {}\n",
    "    f = open('/embed/glove/glove.840B.300d.txt', encoding='utf-8')\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word, coefs = values[0], np.asarray(values[1:], dtype='float')\n",
    "        try:\n",
    "            glv_vector[word] = coefs\n",
    "        except ValueError:\n",
    "            continue\n",
    "    f.close()\n",
    "    start_time = time.time()\n",
    "    print(f\"Took {time.time() - start_time} seconds to load pretrained GloVe model.\")\n",
    "    return glv_vector\n",
    "\n",
    "def encode_labels(encoder, l):\n",
    "    return encoder[l]\n",
    "\n",
    "def _read_words(data, convmode=None):\n",
    "    '''    \n",
    "    Count the occurrences of all words\n",
    "    @param convmode: str, None for non conversational scope, 'naive' for classic or naive approach, 'conv' for conversation depth into account (one additional dim and nested values)\n",
    "    @param data: list of examples\n",
    "    @return words: list of words (with duplicates)\n",
    "    '''    \n",
    "    words = []\n",
    "    if convmode is None:\n",
    "        for example in data:\n",
    "            words += example.split()\n",
    "    return words\n",
    "\n",
    "def find_value_ranges(lst):\n",
    "    value_ranges = []\n",
    "    start_index = 0\n",
    "\n",
    "    for i in range(1, len(lst)):\n",
    "        if lst[i] != lst[i - 1]:\n",
    "            value_ranges.append((start_index, i - 1))\n",
    "            start_index = i\n",
    "\n",
    "    # Add the last range\n",
    "    value_ranges.append((start_index, len(lst) - 1))\n",
    "\n",
    "    return value_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d2cf5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12840, 12)\n",
      "(3400, 12)\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV file\n",
    "X_train = pd.read_csv('data/train_sent_emo_dya.csv', encoding='shift_jis')\n",
    "X_test = pd.read_csv('data/test_sent_emo_dya.csv', encoding='utf-8')\n",
    "\n",
    "# Display the first three rows\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5825e9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features to drop\n",
    "drop_features = list(X_train.columns[6:]) \n",
    "\n",
    "# Create DataFrame for target labels\n",
    "y_train = pd.DataFrame()\n",
    "y_test = pd.DataFrame()\n",
    "\n",
    "y_train[\"Emotion\"] = X_train[\"Emotion\"].copy()\n",
    "y_test[\"Emotion\"] = X_test[\"Emotion\"].copy()\n",
    "\n",
    "y_train[\"Dialogue_ID\"] = X_train[\"Dialogue_ID\"].copy()\n",
    "y_test[\"Dialogue_ID\"] = X_test[\"Dialogue_ID\"].copy()\n",
    "\n",
    "# Drop features from X_train DataFrame\n",
    "X_train = X_train.drop(drop_features, axis=1)\n",
    "X_test = X_test.drop(drop_features, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d104ee",
   "metadata": {},
   "source": [
    "Before spelling correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad1731f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>also I was the point person on my company’s tr...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You must’ve had your hands full.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>That I did. That I did.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>So let’s talk a little bit about your duties.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My duties?  All right.</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Now you’ll be heading a whole division, so you...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I see.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>But there’ll be perhaps 30 people under you so...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Good to know.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>We can go into detail</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>No don’t I beg of you!</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>All right then, we’ll have a definite answer f...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Really?!</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Absolutely.  You can relax</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>But then who? The waitress I went out with las...</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>You know? Forget it!</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>No-no-no-no, no! Who, who were you talking about?</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>No, I-I-I-I don't, I actually don't know</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Ok!</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>All right, well...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Yeah, sure!</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Hey, Mon.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Hey-hey-hey. You wanna hear something that sucks.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Do I ever.</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Chris says they’re closing down the bar.</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>No way!</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Yeah, apparently they’re turning it into some ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Just coffee! Where are we gonna hang out now?</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Got me.</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Can I get a beer.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Hey, did you pick a roommate?</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>You betcha!</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Is it the Italian guy?</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Um-mm, yeah right!</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Oh my God, oh my God! Poor Monica!</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>What, what, what?!</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>What?!</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>He was with her when he wrote this poem.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Look,  'My vessel so empty with nothing inside.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Now that I've touched you, you seem emptier st...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>He thinks Monica is empty, she is the empty vase!</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Oh, totally. Oh, God, oh, she seemed so happy ...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>What?!</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>He was with her when he wrote this poem.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Look,  'My vessel so empty with nothing inside.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Now that I've touched you, you seem emptier st...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>He thinks Monica is empty, she is the empty vase!</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Oh, totally. Oh, God, oh, she seemed so happy ...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Done.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Hey!</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Utterance   Emotion\n",
       "0   also I was the point person on my company’s tr...   neutral\n",
       "1                    You must’ve had your hands full.   neutral\n",
       "2                             That I did. That I did.   neutral\n",
       "3       So let’s talk a little bit about your duties.   neutral\n",
       "4                              My duties?  All right.  surprise\n",
       "5   Now you’ll be heading a whole division, so you...   neutral\n",
       "6                                              I see.   neutral\n",
       "7   But there’ll be perhaps 30 people under you so...   neutral\n",
       "8                                       Good to know.   neutral\n",
       "9                               We can go into detail   neutral\n",
       "10                             No don’t I beg of you!      fear\n",
       "11  All right then, we’ll have a definite answer f...   neutral\n",
       "12                                           Really?!  surprise\n",
       "13                         Absolutely.  You can relax   neutral\n",
       "14  But then who? The waitress I went out with las...  surprise\n",
       "15                               You know? Forget it!   sadness\n",
       "16  No-no-no-no, no! Who, who were you talking about?  surprise\n",
       "17           No, I-I-I-I don't, I actually don't know      fear\n",
       "18                                                Ok!   neutral\n",
       "19                                 All right, well...   neutral\n",
       "20                                        Yeah, sure!   neutral\n",
       "21                                          Hey, Mon.   neutral\n",
       "22  Hey-hey-hey. You wanna hear something that sucks.   neutral\n",
       "23                                         Do I ever.       joy\n",
       "24           Chris says they’re closing down the bar.   sadness\n",
       "25                                            No way!  surprise\n",
       "26  Yeah, apparently they’re turning it into some ...   neutral\n",
       "27      Just coffee! Where are we gonna hang out now?   disgust\n",
       "28                                            Got me.   sadness\n",
       "29                                  Can I get a beer.   neutral\n",
       "30                      Hey, did you pick a roommate?   neutral\n",
       "31                                        You betcha!       joy\n",
       "32                             Is it the Italian guy?   neutral\n",
       "33                                 Um-mm, yeah right!       joy\n",
       "34                 Oh my God, oh my God! Poor Monica!  surprise\n",
       "35                                 What, what, what?!  surprise\n",
       "36                                             What?!  surprise\n",
       "37           He was with her when he wrote this poem.   neutral\n",
       "38    Look,  'My vessel so empty with nothing inside.   neutral\n",
       "39  Now that I've touched you, you seem emptier st...   neutral\n",
       "40  He thinks Monica is empty, she is the empty vase!  surprise\n",
       "41  Oh, totally. Oh, God, oh, she seemed so happy ...   sadness\n",
       "42                                             What?!  surprise\n",
       "43           He was with her when he wrote this poem.   neutral\n",
       "44    Look,  'My vessel so empty with nothing inside.   neutral\n",
       "45  Now that I've touched you, you seem emptier st...   neutral\n",
       "46  He thinks Monica is empty, she is the empty vase!  surprise\n",
       "47  Oh, totally. Oh, God, oh, she seemed so happy ...   sadness\n",
       "48                                              Done.   neutral\n",
       "49                                               Hey!  surprise"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[[\"Utterance\", \"Emotion\"]][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "880afd4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Why do all you’re coffee mugs have numbers on ...</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Oh. That’s so Monica can keep track. That way ...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Y'know what?</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Okay.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ross, didn't you say that there was an elevato...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Uhh, yes I did but there isn't. Okay, here we go.</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Okay, go left. Left! Left!</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Okay, y'know what? There is no more left, left!</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Oh okay, lift it straight up over your head!</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Straight up over your head!</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>You can do it!</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>You can do it!</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Okay.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>You got it?</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Oh, okay, I get it.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>No wait, look. Look! I'm sorry, it's just I've...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Howard's the</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Yes but too me he's just, man.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Okay, fine, whatever. Welcome to the building.</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Ugh, can you believe that guy!</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Ugh, can you believe that guy!</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Yeah. I really like his glasses.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Ohh!</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>What?</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>It kicked! I think the baby kicked!</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Oh my God!</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Oh no wait, oh no, the elastic on my underwear...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Oh no wait, oh no, the elastic on my underwear...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Oh my God! I overslept! I was supposed to be o...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Look, I know I feel asleep before I could show...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>They’re just ten blocks away, if I run, I can ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Oh my God! I overslept! I was supposed to be o...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Oh wait, Joey, you can’t go like that! You stink!</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Look, I know I feel asleep before I could show...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>They’re just ten blocks away, if I run, I can ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>You’re coming on to the entire room!  I’m Chan...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>You mind if I</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>No, please.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>So uh, what are you in for?</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>I talk in my sleep.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>What a coincidence, I listen in my sleep.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>You’re coming on to the entire room!  I’m Chan...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>What a coincidence, I listen in my sleep.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>So why don’t you give me your number?</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Previously on Friends.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>I don’t know exactly. It’s-it’s sorta like wre...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>I don’t know exactly. It’s-it’s sorta like wre...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Utterance   Emotion\n",
       "0   Why do all you’re coffee mugs have numbers on ...  surprise\n",
       "1   Oh. That’s so Monica can keep track. That way ...     anger\n",
       "2                                        Y'know what?   neutral\n",
       "3                                               Okay.   neutral\n",
       "4   Ross, didn't you say that there was an elevato...   neutral\n",
       "5   Uhh, yes I did but there isn't. Okay, here we go.   sadness\n",
       "6                          Okay, go left. Left! Left!  surprise\n",
       "7     Okay, y'know what? There is no more left, left!     anger\n",
       "8        Oh okay, lift it straight up over your head!     anger\n",
       "9                         Straight up over your head!     anger\n",
       "10                                     You can do it!       joy\n",
       "11                                     You can do it!       joy\n",
       "12                                              Okay.   neutral\n",
       "13                                        You got it?   neutral\n",
       "14                                Oh, okay, I get it.   neutral\n",
       "15  No wait, look. Look! I'm sorry, it's just I've...      fear\n",
       "16                                       Howard's the   neutral\n",
       "17                     Yes but too me he's just, man.   neutral\n",
       "18     Okay, fine, whatever. Welcome to the building.     anger\n",
       "19                     Ugh, can you believe that guy!   disgust\n",
       "20                     Ugh, can you believe that guy!   disgust\n",
       "21                   Yeah. I really like his glasses.   neutral\n",
       "22                                               Ohh!  surprise\n",
       "23                                              What?   neutral\n",
       "24                It kicked! I think the baby kicked!  surprise\n",
       "25                                         Oh my God!  surprise\n",
       "26  Oh no wait, oh no, the elastic on my underwear...   neutral\n",
       "27  Oh no wait, oh no, the elastic on my underwear...   neutral\n",
       "28  Oh my God! I overslept! I was supposed to be o...      fear\n",
       "29  Look, I know I feel asleep before I could show...     anger\n",
       "30  They’re just ten blocks away, if I run, I can ...   neutral\n",
       "31  Oh my God! I overslept! I was supposed to be o...      fear\n",
       "32  Oh wait, Joey, you can’t go like that! You stink!   disgust\n",
       "33  Look, I know I feel asleep before I could show...     anger\n",
       "34  They’re just ten blocks away, if I run, I can ...   neutral\n",
       "35  You’re coming on to the entire room!  I’m Chan...     anger\n",
       "36                                                Hi.   neutral\n",
       "37                                                Hi.   neutral\n",
       "38                                      You mind if I   neutral\n",
       "39                                        No, please.   neutral\n",
       "40                        So uh, what are you in for?   neutral\n",
       "41                                I talk in my sleep.   neutral\n",
       "42          What a coincidence, I listen in my sleep.   neutral\n",
       "43  You’re coming on to the entire room!  I’m Chan...     anger\n",
       "44                                                Hi.   neutral\n",
       "45          What a coincidence, I listen in my sleep.   neutral\n",
       "46              So why don’t you give me your number?   neutral\n",
       "47                             Previously on Friends.   neutral\n",
       "48  I don’t know exactly. It’s-it’s sorta like wre...   neutral\n",
       "49  I don’t know exactly. It’s-it’s sorta like wre...   neutral"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[[\"Utterance\", \"Emotion\"]][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b73b303f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train[\"Utterance\"] = X_train[\"Utterance\"].apply(lambda x: replace_spelling(x))\n",
    "# X_test[\"Utterance\"] = X_test[\"Utterance\"].apply(lambda x: replace_spelling(x))\n",
    "\n",
    "# X_train[\"Utterance\"] = preprocess_text(X_train[\"Utterance\"].tolist())\n",
    "# X_test[\"Utterance\"] = preprocess_text(X_test[\"Utterance\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86036b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkFile1 = os.path.isfile(\"data/dump/label_encoder.pkl\")\n",
    "checkFile2 = os.path.isfile(\"data/dump/label_decoder.pkl\")\n",
    "\n",
    "if key:\n",
    "    labels = sorted(set(y_train.Emotion))\n",
    "    labelEncoder = {label: i for i, label in enumerate(labels)}\n",
    "    labelDecoder = {i: label for i, label in enumerate(labels)}\n",
    "\n",
    "    pickle.dump(labelEncoder, open('data/dump/label_encoder.pkl', 'wb'))\n",
    "    pickle.dump(labelDecoder, open('data/dump/label_decoder.pkl', 'wb'))\n",
    "else:\n",
    "    file1 = open('data/dump/label_encoder.pkl', 'rb')\n",
    "    file2 = open('data/dump/label_decoder.pkl', 'rb')\n",
    "    labelEncoder = pickle.load(file1)\n",
    "    labelDecoder = pickle.load(file2)\n",
    "    file1.close()\n",
    "    file2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2d0af03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anger': 0,\n",
       " 'disgust': 1,\n",
       " 'fear': 2,\n",
       " 'joy': 3,\n",
       " 'neutral': 4,\n",
       " 'sadness': 5,\n",
       " 'surprise': 6}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6211e8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply label encoding to the \"Emotion\" column in y_train\n",
    "y_train[\"Emotion\"] = y_train[\"Emotion\"].apply(lambda x: encode_labels(labelEncoder, x))\n",
    "y_test[\"Emotion\"] = y_test[\"Emotion\"].apply(lambda x: encode_labels(labelEncoder, x))\n",
    "\n",
    "# Copy the encoded \"Emotion\" column from y_train to X_train\n",
    "X_train[\"Emotion\"] = y_train[\"Emotion\"].copy()\n",
    "X_test[\"Emotion\"] = y_test[\"Emotion\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0db6676b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the file already exists\n",
    "checkFile1 = os.path.isfile(\"data/dump/labels_train.pkl\")\n",
    "checkFile2 = os.path.isfile(\"data/dump/labels_test.pkl\")\n",
    "\n",
    "if key:\n",
    "    pickle.dump(X_train[\"Emotion\"], open('data/dump/labels_train.pkl', 'wb'))\n",
    "    pickle.dump(X_test[\"Emotion\"], open('data/dump/labels_test.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1a4583",
   "metadata": {},
   "source": [
    "Creating an embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19929c11",
   "metadata": {},
   "source": [
    "Testing on smaller data. Uncomment to see the size of updated representations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da518513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of contextual embeddings: torch.Size([8, 768])\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained BERT model and tokenizer\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = transformers.BertTokenizer.from_pretrained(model_name)\n",
    "model = transformers.BertModel.from_pretrained(model_name)\n",
    "\n",
    "# Define your dialog data\n",
    "dialogs = [\n",
    "    \"How are you today?\",\n",
    "    \"I'm doing well, thank you!\",\n",
    "    \"That's good to hear.\",\n",
    "    \"Yes, it is.\",\n",
    "    \"Do you have any plans for the weekend?\",\n",
    "    \"Not really, just relaxing at home.\",\n",
    "    \"Sounds nice.\",\n",
    "    \"Indeed.\"\n",
    "]\n",
    "\n",
    "# Tokenize and encode the dialogs\n",
    "encoded_dialogs = [tokenizer.encode(dialog, add_special_tokens=True) for dialog in dialogs]\n",
    "\n",
    "# Pad sequences to the same length\n",
    "max_length = max(len(dialog) for dialog in encoded_dialogs)\n",
    "padded_dialogs = [dialog + [tokenizer.pad_token_id] * (max_length - len(dialog)) for dialog in encoded_dialogs]\n",
    "\n",
    "# Create attention masks\n",
    "attention_masks = [[1] * len(dialog) + [0] * (max_length - len(dialog)) for dialog in encoded_dialogs]\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "input_ids = torch.tensor(padded_dialogs)\n",
    "attention_masks = torch.tensor(attention_masks)\n",
    "\n",
    "# Obtain the BERT embeddings\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids, attention_mask=attention_masks)\n",
    "\n",
    "# Extract the contextual embeddings (CLS token)\n",
    "contextual_embeddings = outputs[0][:, 0, :]  # Extract embeddings for the [CLS] token\n",
    "\n",
    "# Print the shape of the contextual embeddings\n",
    "print(\"Shape of contextual embeddings:\", contextual_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618d7e17",
   "metadata": {},
   "source": [
    "This is just a duplicate of code above. Using this on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3718155a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2160\n",
      "577\n"
     ]
    }
   ],
   "source": [
    "rangesTrain = find_value_ranges(X_train[\"Dialogue_ID\"])\n",
    "print(len(rangesTrain))\n",
    "\n",
    "rangesTest = find_value_ranges(X_test[\"Dialogue_ID\"])\n",
    "print(len(rangesTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77955986",
   "metadata": {},
   "source": [
    "Testing on small sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63595e55",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# # Load pre-trained BERT model and tokenizer\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# # List of text dialogs\n",
    "# dialogs = [\n",
    "#     [\"How are you today?\", \"I'm doing well, thank you!\"],\n",
    "#     [\"That's good to hear.\", \"Yes, it is.\", \"Do you have any plans for the weekend?\", \"Not really, just relaxing at home.\"],\n",
    "#     [\"Sounds nice.\", \"Indeed.\"]\n",
    "# ]\n",
    "\n",
    "# # List to store contextual embeddings for each utterance\n",
    "# contextual_embeddings = []\n",
    "\n",
    "# # Iterate through each dialog\n",
    "# for dialog in dialogs:\n",
    "#     # Tokenize and convert dialog to input IDs\n",
    "#     inputs = tokenizer(dialog, return_tensors='pt', padding=True, truncation=True)\n",
    "    \n",
    "#     # Get BERT model outputs\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(**inputs)\n",
    "\n",
    "#     # Extract contextual embeddings (CLS token represents the entire sequence)\n",
    "#     embeddings = outputs.last_hidden_state[:, 0, :].tolist()\n",
    "\n",
    "#     # Store embeddings for each utterance in the dialog\n",
    "#     contextual_embeddings.append(embeddings)\n",
    "\n",
    "# # Print the list of contextual embeddings\n",
    "# print(\"List of Contextual Embeddings:\")\n",
    "# # for embedding in contextual_embeddings:\n",
    "# #     print(embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87280a72",
   "metadata": {},
   "source": [
    "#### Contexualized train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7abe85c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Ranges: 2160it [00:00, 32285.38it/s]\n",
      "Processing Dialogs: 100%|██████████████████████████████████████████████████████████| 2160/2160 [08:38<00:00,  4.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contexualized train data - Elapsed time: 521.2036039829254 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "if key:\n",
    "    dialogs = []\n",
    "    for range_pair, iteration in tqdm(zip(rangesTrain, range(len(rangesTrain))), desc=\"Processing Ranges\"):\n",
    "        start_idx, end_idx = range_pair            \n",
    "        dialog = list(X_train['Utterance'][start_idx:end_idx + 1])\n",
    "        dialogs.append(dialog)\n",
    "\n",
    "    # List to store contextual embeddings for each utterance\n",
    "    contextualEmbeddingsTrain = []\n",
    "\n",
    "    # Iterate through each dialog\n",
    "    for dialog in tqdm(dialogs, desc=\"Processing Dialogs\"):\n",
    "        # Tokenize and convert dialog to input IDs\n",
    "        inputs = tokenizer(dialog, return_tensors='pt', padding=True, truncation=True)\n",
    "\n",
    "        # Get BERT model outputs\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        # Extract contextual embeddings (CLS token represents the entire sequence)\n",
    "        embeddings = outputs.last_hidden_state[:, 0, :].tolist()\n",
    "\n",
    "        # Store embeddings for each utterance in the dialog\n",
    "        contextualEmbeddingsTrain.append(torch.tensor(embeddings))\n",
    "\n",
    "    file_path = f'embed/u_prime_BERT_train.pkl'\n",
    "    with open(file_path, 'wb') as file:\n",
    "            pickle.dump(contextualEmbeddingsTrain, file)\n",
    "\n",
    "else:\n",
    "    file_path = f'embed/u_prime_BERT_train.pkl'\n",
    "    with open(file_path, 'rb') as file:\n",
    "        contextualEmbeddingsTrain = pickle.load(file)\n",
    "        \n",
    "# Record end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Contexualized train data - Elapsed time: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c1c3a4",
   "metadata": {},
   "source": [
    "<h4> Contexualize test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8604a65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 577/577 [00:00<00:00, 16969.56it/s]\n",
      "Processing Dialogs: 100%|████████████████████████████████████████████████████████████| 577/577 [02:17<00:00,  4.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contexualized test data - Elapsed time: 139.1604368686676 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "if key:\n",
    "    dialogs = []\n",
    "    for range_pair in tqdm(rangesTest):\n",
    "        start_idx, end_idx = range_pair            \n",
    "        dialog = list(X_test['Utterance'][start_idx:end_idx + 1])\n",
    "        dialogs.append(dialog)\n",
    "\n",
    "    contextualEmbeddingsTest = []\n",
    "\n",
    "    for dialog in tqdm(dialogs, desc=\"Processing Dialogs\"):\n",
    "        inputs = tokenizer(dialog, return_tensors='pt', padding=True, truncation=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        embeddings = outputs.last_hidden_state[:, 0, :].tolist()\n",
    "        contextualEmbeddingsTest.append(torch.tensor(embeddings))\n",
    "\n",
    "    file_path = f'embed/u_prime_BERT_test.pkl'\n",
    "    with open(file_path, 'wb') as file:\n",
    "        pickle.dump(contextualEmbeddingsTest, file)\n",
    "\n",
    "else:\n",
    "    file_path = f'embed/u_prime_BERT_test.pkl'\n",
    "    with open(file_path, 'rb') as file:\n",
    "        contextualEmbeddingsTest = pickle.load(file)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Contexualized test data - Elapsed time: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89b17e6",
   "metadata": {},
   "source": [
    "<h4> Getting speaker encoder for train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "65ff6791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the file exists\n",
    "checkFile = os.path.isfile(\"data/dump/speaker_encoder_train.pkl\")\n",
    "encodedSpeakersTrain = []\n",
    "\n",
    "if key:\n",
    "    for range_pair in rangesTrain:\n",
    "        start_idx, end_idx = range_pair\n",
    "        speaker_per_dialog = X_train['Speaker'][start_idx:end_idx + 1].copy()\n",
    "        speaker_feature = sorted(set(speaker_per_dialog))\n",
    "        speaker_encoder = {feature: i for i, feature in enumerate(speaker_feature)}\n",
    "        speaker_decoder = {i: feature for i, feature in enumerate(speaker_feature)}\n",
    "\n",
    "        encoded_speaker = speaker_per_dialog.replace(speaker_encoder)\n",
    "        encodedSpeakersTrain.append(encoded_speaker)\n",
    "\n",
    "    # Save encoded speaker list and ranges to a file using pickle\n",
    "    file_path = 'data/dump/speaker_encoder_train.pkl'\n",
    "    with open(file_path, 'wb') as file:\n",
    "        pickle.dump([encodedSpeakersTrain, rangesTrain], file)\n",
    "else:\n",
    "    # Load encoded speaker list and ranges from the existing pickle file\n",
    "    file = open('data/dump/speaker_encoder_train.pkl', \"rb\")\n",
    "    encodedSpeakersTrain, rangesTrain = pickle.load(file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30584c74",
   "metadata": {},
   "source": [
    "<h4> Getting speaker encoder for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd271d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the file exists\n",
    "checkFile = os.path.isfile(\"data/dump/speaker_encoder_test.pkl\")\n",
    "encodedSpeakersTest = []\n",
    "\n",
    "if key:\n",
    "    for range_pair in rangesTest:\n",
    "        start_idx, end_idx = range_pair\n",
    "        speaker_per_dialog = X_test['Speaker'][start_idx:end_idx + 1].copy()\n",
    "        speaker_feature = sorted(set(speaker_per_dialog))\n",
    "        speaker_encoder = {feature: i for i, feature in enumerate(speaker_feature)}\n",
    "        speaker_decoder = {i: feature for i, feature in enumerate(speaker_feature)}\n",
    "\n",
    "        encoded_speaker = speaker_per_dialog.replace(speaker_encoder)\n",
    "        encodedSpeakersTest.append(encoded_speaker)\n",
    "\n",
    "    # Save encoded speaker list and ranges to a file using pickle\n",
    "    file_path = 'data/dump/speaker_encoder_test.pkl'\n",
    "    with open(file_path, 'wb') as file:\n",
    "        pickle.dump([encodedSpeakersTest, rangesTest], file)\n",
    "else:\n",
    "    # Load encoded speaker list and ranges from the existing pickle file\n",
    "    file = open('data/dump/speaker_encoder_test.pkl', \"rb\")\n",
    "    encodedSpeakersTest, rangesTest = pickle.load(file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530a19cb",
   "metadata": {},
   "source": [
    "Unsupervised visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b5f1de43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6144])\n"
     ]
    }
   ],
   "source": [
    "# Assuming contextual_embeddings is your list of contextual embeddings\n",
    "\n",
    "# Flatten the list of contextual embeddings into a single list\n",
    "flattened_embeddings = [emb for dialogue in contextual_embeddings for emb in dialogue]\n",
    "\n",
    "# Convert the flattened list into a single tensor\n",
    "tensor_data = torch.tensor(flattened_embeddings)\n",
    "\n",
    "# Check the shape of the tensor\n",
    "print(tensor_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "12995d9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'anger',\n",
       " 1: 'disgust',\n",
       " 2: 'fear',\n",
       " 3: 'joy',\n",
       " 4: 'neutral',\n",
       " 5: 'sadness',\n",
       " 6: 'surprise'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelDecoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d362bd",
   "metadata": {},
   "source": [
    "Distribution of labels in train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d031c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anger: 1500 train occurrences\n",
      "disgust: 364 train occurrences\n",
      "fear: 338 train occurrences\n",
      "joy: 2312 train occurrences\n",
      "neutral: 5960 train occurrences\n",
      "sadness: 876 train occurrences\n",
      "surprise: 1490 train occurrences\n"
     ]
    }
   ],
   "source": [
    "# Calculate the counts for each unique label\n",
    "uniqueLabelsTrain, labelCountsTrain = np.unique(list(X_train[\"Emotion\"]), return_counts=True)\n",
    "\n",
    "# Print the counts for each unique label\n",
    "for label, count in zip(uniqueLabelsTrain, labelCountsTrain):\n",
    "    print(f\"{labelDecoder[label]}: {count} train occurrences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f7a401",
   "metadata": {},
   "source": [
    "Distribution of labels in test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9627c3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anger: 516 test occurrences\n",
      "disgust: 99 test occurrences\n",
      "fear: 60 test occurrences\n",
      "joy: 495 test occurrences\n",
      "neutral: 1615 test occurrences\n",
      "sadness: 263 test occurrences\n",
      "surprise: 352 test occurrences\n"
     ]
    }
   ],
   "source": [
    "# Calculate the counts for each unique label\n",
    "uniqueLabelsTest, labelCountsTest = np.unique(list(X_test[\"Emotion\"]), return_counts=True)\n",
    "\n",
    "# Print the counts for each unique label\n",
    "for label, count in zip(uniqueLabelsTest, labelCountsTest):\n",
    "    print(f\"{labelDecoder[label]}: {count} test occurrences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c07b8f",
   "metadata": {},
   "source": [
    "Visualize utterance embeddnig (u') with T-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3d430fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = torch.tensor(X_train[\"Emotion\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f1043832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aed63efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# runTSNE = 1\n",
    "# if runTSNE:\n",
    "#     from sklearn.manifold import TSNE\n",
    "#     import matplotlib.pyplot as plt\n",
    "\n",
    "#     # List of perplexity values to loop over\n",
    "#     perplexity_values = [50]\n",
    "\n",
    "#     # Loop over each perplexity value\n",
    "#     for perplexity in perplexity_values:\n",
    "#         # Initialize t-SNE with the current perplexity value\n",
    "#         tsne = TSNE(n_components=2, perplexity=perplexity, random_state=42)\n",
    "\n",
    "#         # Fit and transform the data using t-SNE\n",
    "#         h_prime_tsne = tsne.fit_transform(tensor_data.detach().numpy())\n",
    "\n",
    "#         # Plot the node embeddings with different colors for each label\n",
    "#         plt.figure(figsize=(10, 8))\n",
    "#         for label, emotion in zip(range(len(label_encoder)), label_encoder):\n",
    "#             indices = (labels == label).nonzero().squeeze()\n",
    "#             plt.scatter(h_prime_tsne[indices, 0], h_prime_tsne[indices, 1], label=f'{emotion}')\n",
    "#         plt.title(f'Utterance Embeddings (Train) Visualization (t-SNE) - Perplexity {perplexity}', color=\"white\")\n",
    "#         plt.xlabel('Dimension 1', color=\"white\")\n",
    "#         plt.ylabel('Dimension 2', color=\"white\")\n",
    "#         plt.legend()\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e2170c",
   "metadata": {},
   "source": [
    " Visualize utterance embedding (u') with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "91e6dc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca = PCA(n_components=2)\n",
    "# pca_result = pca.fit_transform(tensor_data.detach().numpy())\n",
    "\n",
    "# # Plot the PCA result with color-coded labels\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# for label in np.unique(labels):\n",
    "#     indices = labels == label\n",
    "#     plt.scatter(pca_result[indices, 0], pca_result[indices, 1], label=f'{label_decoder[label]}', alpha=0.5)\n",
    "#     plt.title('PCA Visualization of Utterance Embeddings (Train) with Color-Coded Labels')\n",
    "#     plt.xlabel('Principal Component 1')\n",
    "#     plt.ylabel('Principal Component 2')\n",
    "#     plt.legend()\n",
    "#     plt.grid(True)\n",
    "#     plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
