{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing of libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import collections\n",
    "from vocab import Vocab, Vectors\n",
    "from wordebd import WORDEBD\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12840, 12)\n",
      "(3400, 12)\n",
      "(1462, 12)\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"dataset_drop_noise\"\n",
    "\n",
    "# Read the CSV file\n",
    "TrainData = pd.read_csv('data/dataset_original/train_sent_emo_dya.csv', encoding='shift_jis')\n",
    "TestData = pd.read_csv('data/dataset_original/test_sent_emo_dya.csv', encoding='utf-8')\n",
    "DevData = pd.read_csv('data/dataset_original/dev_sent_emo_dya.csv', encoding='utf-8')\n",
    "\n",
    "# Display the first three rows\n",
    "print(TrainData.shape)\n",
    "print(TestData.shape)\n",
    "print(DevData.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping of Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop Old_Dialogue_ID, Old_Utterance_ID, Season, Episode, StartTime, and EndTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define features to drop\n",
    "drop_features = list(TrainData.columns[6:]) \n",
    "drop_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop features from X_train DataFrame\n",
    "if not drop_features:\n",
    "    TrainData = TrainData.drop(drop_features, axis=1)\n",
    "    TestData = TestData.drop(drop_features, axis=1)\n",
    "    DevData = DevData.drop(drop_features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkFile1 = os.path.isfile(\"data/dump/\" + dataset_path + \"/label_encoder.pkl\")\n",
    "checkFile2 = os.path.isfile(\"data/dump/\" + dataset_path + \"/label_decoder.pkl\")\n",
    "\n",
    "key = True\n",
    "\n",
    "if not (checkFile1 and checkFile2):\n",
    "    labels = sorted(set(TrainData.Emotion))\n",
    "    labelEncoder = {label: i for i, label in enumerate(labels)}\n",
    "    labelDecoder = {i: label for i, label in enumerate(labels)}\n",
    "\n",
    "    pickle.dump(labelEncoder, open('data/dump/' + dataset_path + '/label_encoder.pkl', 'wb'))\n",
    "    pickle.dump(labelDecoder, open('data/dump/' + dataset_path + '/label_decoder.pkl', 'wb'))\n",
    "else:\n",
    "    file1 = open('data/dump/' + dataset_path + '/label_encoder.pkl', 'rb')\n",
    "    file2 = open('data/dump/' + dataset_path + '/label_decoder.pkl', 'rb')\n",
    "    labelEncoder = pickle.load(file1)\n",
    "    labelDecoder = pickle.load(file2)\n",
    "    file1.close()\n",
    "    file2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anger': 0,\n",
       " 'disgust': 1,\n",
       " 'fear': 2,\n",
       " 'joy': 3,\n",
       " 'neutral': 4,\n",
       " 'sadness': 5,\n",
       " 'surprise': 6}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_labels(encoder, l):\n",
    "    return encoder[l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply label encoding to the \"Emotion\" column in y_train\n",
    "TrainData[\"Emotion\"] = TrainData[\"Emotion\"].apply(lambda x: encode_labels(labelEncoder, x))\n",
    "TestData[\"Emotion\"] = TestData[\"Emotion\"].apply(lambda x: encode_labels(labelEncoder, x))\n",
    "DevData[\"Emotion\"] = DevData[\"Emotion\"].apply(lambda x: encode_labels(labelEncoder, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_value_ranges(lst):\n",
    "    value_ranges = []\n",
    "    start_index = 0\n",
    "\n",
    "    for i in range(1, len(lst)):\n",
    "        if lst[i] != lst[i - 1]:\n",
    "            value_ranges.append((start_index, i - 1))\n",
    "            start_index = i\n",
    "\n",
    "    # Add the last range\n",
    "    value_ranges.append((start_index, len(lst) - 1))\n",
    "\n",
    "    return value_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2160\n",
      "577\n",
      "270\n"
     ]
    }
   ],
   "source": [
    "rangesTrain = find_value_ranges(TrainData[\"Dialogue_ID\"])\n",
    "print(len(rangesTrain))\n",
    "\n",
    "rangesTest = find_value_ranges(TestData[\"Dialogue_ID\"])\n",
    "print(len(rangesTest))\n",
    "\n",
    "rangesDev = find_value_ranges(DevData[\"Dialogue_ID\"])\n",
    "print(len(rangesDev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speaker Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding speaker on train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the file exists\n",
    "checkFile = os.path.isfile(\"data/dump/\" + dataset_path + \"/speaker_encoder_train.pkl\")\n",
    "encodedSpeakersTrain = []\n",
    "\n",
    "if not checkFile:\n",
    "    for range_pair in rangesTrain:\n",
    "        start_idx, end_idx = range_pair\n",
    "        speaker_per_dialog = TrainData['Speaker'][start_idx:end_idx + 1].copy()\n",
    "        speaker_feature = sorted(set(speaker_per_dialog))\n",
    "        speaker_encoder = {feature: i for i, feature in enumerate(speaker_feature)}\n",
    "        speaker_decoder = {i: feature for i, feature in enumerate(speaker_feature)}\n",
    "\n",
    "        encoded_speaker = speaker_per_dialog.replace(speaker_encoder)\n",
    "        encodedSpeakersTrain.append(encoded_speaker)\n",
    "\n",
    "    # Save encoded speaker list and ranges to a file using pickle\n",
    "    file_path = 'data/dump/' + dataset_path + '/speaker_encoder_train.pkl'\n",
    "    with open(file_path, 'wb') as file:\n",
    "        pickle.dump([encodedSpeakersTrain, rangesTrain], file)\n",
    "else:\n",
    "    # Load encoded speaker list and ranges from the existing pickle file\n",
    "    file = open('data/dump/' + dataset_path + '/speaker_encoder_train.pkl', \"rb\")\n",
    "    encodedSpeakersTrain, rangesTrain = pickle.load(file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding speaker on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the file exists\n",
    "checkFile = os.path.isfile(\"data/dump/\" + dataset_path + \"/speaker_encoder_test.pkl\")\n",
    "encodedSpeakersTest = []\n",
    "\n",
    "if not checkFile:\n",
    "    for range_pair in rangesTest:\n",
    "        start_idx, end_idx = range_pair\n",
    "        speaker_per_dialog = TestData['Speaker'][start_idx:end_idx + 1].copy()\n",
    "        speaker_feature = sorted(set(speaker_per_dialog))\n",
    "        speaker_encoder = {feature: i for i, feature in enumerate(speaker_feature)}\n",
    "        speaker_decoder = {i: feature for i, feature in enumerate(speaker_feature)}\n",
    "\n",
    "        encoded_speaker = speaker_per_dialog.replace(speaker_encoder)\n",
    "        encodedSpeakersTest.append(encoded_speaker)\n",
    "\n",
    "    # Save encoded speaker list and ranges to a file using pickle\n",
    "    file_path = 'data/dump/' + dataset_path + '/speaker_encoder_test.pkl'\n",
    "    with open(file_path, 'wb') as file:\n",
    "        pickle.dump([encodedSpeakersTest, rangesTest], file)\n",
    "else:\n",
    "    # Load encoded speaker list and ranges from the existing pickle file\n",
    "    file = open('data/dump/' + dataset_path + '/speaker_encoder_test.pkl', \"rb\")\n",
    "    encodedSpeakersTest, rangesTest = pickle.load(file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the file exists\n",
    "checkFile = os.path.isfile(\"data/dump/\" + dataset_path + \"/speaker_encoder_dev.pkl\")\n",
    "encodedSpeakersDev = []\n",
    "\n",
    "if not checkFile:\n",
    "    for range_pair in rangesDev:\n",
    "        start_idx, end_idx = range_pair\n",
    "        speaker_per_dialog = DevData['Speaker'][start_idx:end_idx + 1].copy()\n",
    "        speaker_feature = sorted(set(speaker_per_dialog))\n",
    "        speaker_encoder = {feature: i for i, feature in enumerate(speaker_feature)}\n",
    "        speaker_decoder = {i: feature for i, feature in enumerate(speaker_feature)}\n",
    "\n",
    "        encoded_speaker = speaker_per_dialog.replace(speaker_encoder)\n",
    "        encodedSpeakersDev.append(encoded_speaker)\n",
    "\n",
    "    # Save encoded speaker list and ranges to a file using pickle\n",
    "    file_path = 'data/dump/' + dataset_path + '/speaker_encoder_dev.pkl'\n",
    "    with open(file_path, 'wb') as file:\n",
    "        pickle.dump([encodedSpeakersDev, rangesDev], file)\n",
    "else:\n",
    "    # Load encoded speaker list and ranges from the existing pickle file\n",
    "    with open('data/dump/' + dataset_path + '/speaker_encoder_dev.pkl', \"rb\") as file:\n",
    "        encodedSpeakersDev, rangesDev = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the encoded speakers in the Train and Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the list of encoded speakers if it is nested\n",
    "encodedSpeakersTrain_flat = [item for sublist in encodedSpeakersTrain for item in sublist]\n",
    "encodedSpeakersTest_flat  = [item for sublist in encodedSpeakersTest for item in sublist]\n",
    "encodedSpeakersDev_flat  = [item for sublist in encodedSpeakersDev for item in sublist]\n",
    "\n",
    "# Replace the 'Speaker' column in TrainData with the encoded speaker data\n",
    "TrainData['Speaker'] = encodedSpeakersTrain_flat\n",
    "TestData['Speaker'] = encodedSpeakersTest_flat\n",
    "DevData['Speaker'] = encodedSpeakersDev_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainData['Speaker'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TestData['Speaker'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DevData['Speaker'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\edayo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\edayo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\edayo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download NLTK data (if not already downloaded)\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Make a copy of X_train_utterances\n",
    "train_utterances = TrainData['Utterance']\n",
    "test_utterances = TestData['Utterance']\n",
    "dev_utterances = DevData['Utterance']\n",
    "\n",
    "# Initialize the lemmatizer and stop words\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Tokenize\n",
    "    words = word_tokenize(text)\n",
    "\n",
    "    # Remove punctuation and non-alphabetic characters, and stop words\n",
    "    words = [word for word in words if word.isalpha() and word not in stop_words]\n",
    "\n",
    "    # Lemmatize\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "    # Join words back into a single string\n",
    "    cleaned_text = ' '.join(words)\n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "# Apply the clean_text function to each utterance\n",
    "train_utterances = train_utterances.apply(clean_text)\n",
    "test_utterances = test_utterances.apply(clean_text)\n",
    "dev_utterances = dev_utterances.apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    also point person company transition system\n",
       "1                                 must hand full\n",
       "2                                               \n",
       "3                       let talk little bit duty\n",
       "4                                     duty right\n",
       "Name: Utterance, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_utterances.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                            coffee mug number bottom\n",
       "1    oh monica keep track way one missing like number\n",
       "2                                                    \n",
       "3                                                okay\n",
       "4                                   ross say elevator\n",
       "Name: Utterance, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_utterances.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                  oh god lost totally lost\n",
       "1                                          \n",
       "2    could go bank close account cut source\n",
       "3                                    genius\n",
       "4                                    genius\n",
       "Name: Utterance, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_utterances.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for empty strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty in Train Utterances: 664\n",
      "Empty in Test Utterances: 170\n",
      "Empty in Dev Utterances: 89\n"
     ]
    }
   ],
   "source": [
    "# Count the empty string values in X_train_utterances\n",
    "empty_string_count_train = (train_utterances == '').sum()\n",
    "empty_string_count_test = (test_utterances == '').sum()\n",
    "empty_string_count_dev = (dev_utterances == '').sum()\n",
    "\n",
    "print(f\"Empty in Train Utterances: {empty_string_count_train}\")\n",
    "print(f\"Empty in Test Utterances: {empty_string_count_test}\")\n",
    "print(f\"Empty in Dev Utterances: {empty_string_count_dev}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update 'Utterance' column and remove all empty strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (12176, 6)\n",
      "Test data shape: (3230, 6)\n",
      "Dev data shape: (1373, 6)\n"
     ]
    }
   ],
   "source": [
    "# Update X_train with the cleaned utterances\n",
    "TrainData['Utterance'] = train_utterances\n",
    "TestData['Utterance'] = test_utterances\n",
    "DevData['Utterance'] = dev_utterances\n",
    "\n",
    "# Drop rows where Utterance is an empty string. Empty string value is ''.\n",
    "TrainData = TrainData[TrainData['Utterance'] != '']\n",
    "TestData = TestData[TestData['Utterance'] != '']\n",
    "DevData = DevData[DevData['Utterance'] != '']\n",
    "\n",
    "# Reset the index\n",
    "TrainData.reset_index(drop=True, inplace=True)\n",
    "TestData.reset_index(drop=True, inplace=True)\n",
    "DevData.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(f\"Train data shape: {TrainData.shape}\")\n",
    "print(f\"Test data shape: {TestData.shape}\")\n",
    "print(f\"Dev data shape: {DevData.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Take note of new shape of Train and Test Data after dropping the values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove rows with *n* or below number of words and create a new **Dropped Words Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing rows that is 2 words or below:\n",
      "Train shape : (7354, 6)\n",
      "Test shape: (1973, 6)\n",
      "Test shape: (858, 6)\n"
     ]
    }
   ],
   "source": [
    "n = 2 # This number removes rows with n or less words. (Retains rows with more than n words)\n",
    "\n",
    "# Retain rows with more than n words\n",
    "Dropwords_TrainData = TrainData[TrainData['Utterance'].apply(lambda x: len(x.split()) > n)]\n",
    "Dropwords_TestData = TestData[TestData['Utterance'].apply(lambda x: len(x.split()) > n)]\n",
    "Dropwords_DevData = DevData[DevData['Utterance'].apply(lambda x: len(x.split()) > n)]\n",
    "\n",
    "Dropwords_TrainData.reset_index(drop=True, inplace=True)\n",
    "Dropwords_TestData.reset_index(drop=True, inplace=True)\n",
    "Dropwords_DevData.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(f\"After removing rows that is {n} words or below:\")\n",
    "print(f\"Train shape : {Dropwords_TrainData.shape}\")\n",
    "print(f\"Test shape: {Dropwords_TestData.shape}\")\n",
    "print(f\"Test shape: {Dropwords_DevData.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get random sample from train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9283</th>\n",
       "      <td>one beat</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2197</th>\n",
       "      <td>got really weird message ross said turn</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11391</th>\n",
       "      <td>come door ask</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8405</th>\n",
       "      <td>oh know helped pick ring</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10992</th>\n",
       "      <td>coming cool cool cool</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9529</th>\n",
       "      <td>well know suds save</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>okay nodded</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>actually ca happen</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6915</th>\n",
       "      <td>well yeah one</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7059</th>\n",
       "      <td>monica snort laugh</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Utterance  Emotion\n",
       "9283                                  one beat        0\n",
       "2197   got really weird message ross said turn        4\n",
       "11391                            come door ask        2\n",
       "8405                  oh know helped pick ring        4\n",
       "10992                    coming cool cool cool        0\n",
       "9529                       well know suds save        4\n",
       "270                                okay nodded        4\n",
       "339                         actually ca happen        4\n",
       "6915                             well yeah one        4\n",
       "7059                        monica snort laugh        0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randomly select 10 rows\n",
    "random_sample = TrainData.sample(n=10)[[\"Utterance\", \"Emotion\"]]\n",
    "\n",
    "random_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2123</th>\n",
       "      <td>second date</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>kicked think baby kicked</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2360</th>\n",
       "      <td>erin still</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2963</th>\n",
       "      <td>monica come let go baby coming</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2320</th>\n",
       "      <td>well best convince crazy girl dying get going ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2210</th>\n",
       "      <td>chandler guy right</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1145</th>\n",
       "      <td>borrow phone want call apartment check grandma...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1845</th>\n",
       "      <td>channie</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2445</th>\n",
       "      <td>every moment precious</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1933</th>\n",
       "      <td>right okay great uh chandler get behind desk</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Utterance  Emotion\n",
       "2123                                        second date        3\n",
       "20                             kicked think baby kicked        6\n",
       "2360                                         erin still        3\n",
       "2963                     monica come let go baby coming        4\n",
       "2320  well best convince crazy girl dying get going ...        4\n",
       "2210                                 chandler guy right        4\n",
       "1145  borrow phone want call apartment check grandma...        4\n",
       "1845                                            channie        5\n",
       "2445                              every moment precious        5\n",
       "1933       right okay great uh chandler get behind desk        4"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randomly select 10 rows\n",
    "random_sample = TestData.sample(n=10)[[\"Utterance\", \"Emotion\"]]\n",
    "\n",
    "random_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>magic story use wan na sex</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>got get save</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>thanks guy</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>need talk</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1264</th>\n",
       "      <td>screwed</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>anxious way help thing along</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>guess</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>oh well listen anyway directing new al pacino ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1351</th>\n",
       "      <td>tell anything</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>oh god slept</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Utterance  Emotion\n",
       "1085                         magic story use wan na sex        0\n",
       "426                                        got get save        2\n",
       "855                                          thanks guy        4\n",
       "1241                                          need talk        3\n",
       "1264                                            screwed        3\n",
       "461                        anxious way help thing along        4\n",
       "132                                               guess        4\n",
       "1299  oh well listen anyway directing new al pacino ...        3\n",
       "1351                                      tell anything        4\n",
       "698                                        oh god slept        6"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randomly select 10 rows\n",
    "random_sample = DevData.sample(n=10)[[\"Utterance\", \"Emotion\"]]\n",
    "\n",
    "random_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6079</th>\n",
       "      <td>look see happening</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1911</th>\n",
       "      <td>joey please think best forget</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4942</th>\n",
       "      <td>chandler love come tonight</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>matter never gon na get meet anyway</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5583</th>\n",
       "      <td>rachel green marry</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>better go museum underwear</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4310</th>\n",
       "      <td>another one never party</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5799</th>\n",
       "      <td>um um rachel talk sec</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6424</th>\n",
       "      <td>right uh listen say crank notch</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2802</th>\n",
       "      <td>know one poughkeepsie even though two hour tra...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Utterance  Emotion\n",
       "6079                                 look see happening        0\n",
       "1911                      joey please think best forget        2\n",
       "4942                         chandler love come tonight        3\n",
       "768                 matter never gon na get meet anyway        5\n",
       "5583                                 rachel green marry        3\n",
       "743                          better go museum underwear        3\n",
       "4310                            another one never party        6\n",
       "5799                              um um rachel talk sec        4\n",
       "6424                    right uh listen say crank notch        3\n",
       "2802  know one poughkeepsie even though two hour tra...        4"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randomly select 10 rows\n",
    "random_sample = Dropwords_TrainData.sample(n=10)[[\"Utterance\", \"Emotion\"]]\n",
    "\n",
    "random_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1970</th>\n",
       "      <td>yeah fade accent people think know adjusting l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>guy please watch right</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670</th>\n",
       "      <td>nope nope ah rather talk</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1808</th>\n",
       "      <td>ca lokk nice might doctor</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>yeah help get past security guard</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>rach look oh hi strong ross skywalker come rescue</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>guy going come one game</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>okay uh temporarily call clint</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>oh god know father</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1264</th>\n",
       "      <td>okay finish apple juice</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Utterance  Emotion\n",
       "1970  yeah fade accent people think know adjusting l...        0\n",
       "613                              guy please watch right        1\n",
       "1670                           nope nope ah rather talk        4\n",
       "1808                          ca lokk nice might doctor        4\n",
       "645                   yeah help get past security guard        4\n",
       "575   rach look oh hi strong ross skywalker come rescue        3\n",
       "1039                            guy going come one game        6\n",
       "452                      okay uh temporarily call clint        4\n",
       "1230                                 oh god know father        6\n",
       "1264                            okay finish apple juice        4"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randomly select 10 rows\n",
    "random_sample = Dropwords_TestData.sample(n=10)[[\"Utterance\", \"Emotion\"]]\n",
    "\n",
    "random_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>oh let tell story</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>actually thought going</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>well thinking think best way would</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>nothing monica stupid fight</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>fact time right</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>well actually eat mine still bathroom</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>okay wait wait</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>hey father house</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>wow look like got lot good stuff</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>sadly could enticed</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Utterance  Emotion\n",
       "255                      oh let tell story        5\n",
       "487                 actually thought going        4\n",
       "362     well thinking think best way would        4\n",
       "68             nothing monica stupid fight        5\n",
       "589                        fact time right        4\n",
       "493  well actually eat mine still bathroom        3\n",
       "338                         okay wait wait        4\n",
       "786                       hey father house        6\n",
       "49        wow look like got lot good stuff        3\n",
       "834                    sadly could enticed        3"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randomly select 10 rows\n",
    "random_sample = Dropwords_DevData.sample(n=10)[[\"Utterance\", \"Emotion\"]]\n",
    "\n",
    "random_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Division of X and y data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame for target labels\n",
    "y_train = pd.DataFrame()\n",
    "y_test = pd.DataFrame()\n",
    "y_dev = pd.DataFrame()\n",
    "\n",
    "X_train = TrainData\n",
    "X_test = TestData\n",
    "X_dev = DevData\n",
    "    \n",
    "y_train[\"Emotion\"] = TrainData[\"Emotion\"].copy()\n",
    "y_test[\"Emotion\"] = TestData[\"Emotion\"].copy()\n",
    "y_dev[\"Emotion\"] = DevData[\"Emotion\"].copy()\n",
    "\n",
    "y_train[\"Dialogue_ID\"] = TrainData[\"Dialogue_ID\"].copy()\n",
    "y_test[\"Dialogue_ID\"] = TestData[\"Dialogue_ID\"].copy()\n",
    "y_dev[\"Dialogue_ID\"] = DevData[\"Dialogue_ID\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (12176, 6)\n",
      "Shape of y_train: (12176, 2)\n",
      "--\n",
      "Shape of X_test: (3230, 6)\n",
      "Shape of y_test: (3230, 2)\n",
      "--\n",
      "Shape of X_dev: (1373, 6)\n",
      "Shape of y_dev: (1373, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f'Shape of X_train: {X_train.shape}')\n",
    "print(f'Shape of y_train: {y_train.shape}')\n",
    "print('--')\n",
    "print(f'Shape of X_test: {X_test.shape}')\n",
    "print(f'Shape of y_test: {y_test.shape}')\n",
    "print('--')\n",
    "print(f'Shape of X_dev: {X_dev.shape}')\n",
    "print(f'Shape of y_dev: {y_dev.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame for target labels\n",
    "y_dropped_train = pd.DataFrame()\n",
    "y_dropped_test = pd.DataFrame()\n",
    "y_dropped_dev = pd.DataFrame()\n",
    "\n",
    "X_dropped_train = Dropwords_TrainData\n",
    "X_dropped_test = Dropwords_TestData\n",
    "X_dropped_dev = Dropwords_DevData\n",
    "\n",
    "y_dropped_train[\"Emotion\"] = Dropwords_TrainData[\"Emotion\"].copy()\n",
    "y_dropped_test[\"Emotion\"] = Dropwords_TestData[\"Emotion\"].copy()\n",
    "y_dropped_dev[\"Emotion\"] = Dropwords_DevData[\"Emotion\"].copy()\n",
    "\n",
    "y_dropped_train[\"Dialogue_ID\"] = Dropwords_TrainData[\"Dialogue_ID\"].copy()\n",
    "y_dropped_test[\"Dialogue_ID\"] = Dropwords_TestData[\"Dialogue_ID\"].copy()\n",
    "y_dropped_dev[\"Dialogue_ID\"] = Dropwords_DevData[\"Dialogue_ID\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_dropped_train: (7354, 6)\n",
      "Shape of y_dropped_train: (7354, 2)\n",
      "--\n",
      "Shape of X_dropped_test: (1973, 6)\n",
      "Shape of y_dropped_test: (1973, 2)\n",
      "--\n",
      "Shape of X_dropped_dev: (858, 6)\n",
      "Shape of y_dropped_dev: (858, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f'Shape of X_dropped_train: {X_dropped_train.shape}')\n",
    "print(f'Shape of y_dropped_train: {y_dropped_train.shape}')\n",
    "print('--')\n",
    "print(f'Shape of X_dropped_test: {X_dropped_test.shape}')\n",
    "print(f'Shape of y_dropped_test: {y_dropped_test.shape}')\n",
    "print('--')\n",
    "print(f'Shape of X_dropped_dev: {X_dropped_dev.shape}')\n",
    "print(f'Shape of y_dropped_dev: {y_dropped_dev.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output data to new csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Label Encoding Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the file already exists\n",
    "checkFile1 = os.path.isfile(\"data/dump/\" + dataset_path + \"/labels_train.pkl\")\n",
    "checkFile2 = os.path.isfile(\"data/dump/\" + dataset_path + \"/labels_test.pkl\")\n",
    "\n",
    "if key:\n",
    "    pickle.dump(X_train[\"Emotion\"], open('data/dump/' + dataset_path + '/labels_train.pkl', 'wb'))\n",
    "    pickle.dump(X_test[\"Emotion\"], open('data/dump/' + dataset_path + '/labels_test.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training and Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exportDataToCSV(df, name):\n",
    "    path = \"data/\" + dataset_path + \"/\" + name + \".csv\"\n",
    "    df.to_csv(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "exportDataToCSV(X_train, \"train_sent_emo_dya\")\n",
    "exportDataToCSV(y_train, \"y_train\")\n",
    "\n",
    "exportDataToCSV(X_test, \"test_sent_emo_dya\")\n",
    "exportDataToCSV(y_test, \"y_test\")\n",
    "\n",
    "exportDataToCSV(X_dev, \"dev_sent_emo_dya\")\n",
    "exportDataToCSV(y_dev, \"y_dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "exportDataToCSV(X_dropped_train, \"dropwords_X_train\")\n",
    "exportDataToCSV(y_dropped_train, \"dropwords_y_train\")\n",
    "\n",
    "exportDataToCSV(X_dropped_test, \"dropwords_X_test\")\n",
    "exportDataToCSV(y_dropped_test, \"dropwords_y_test\")\n",
    "\n",
    "exportDataToCSV(X_dropped_dev, \"dropwords_X_dev\")\n",
    "exportDataToCSV(y_dropped_dev, \"dropwords_y_dev\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
