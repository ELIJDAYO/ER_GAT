{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing of libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import collections\n",
    "from vocab import Vocab, Vectors\n",
    "from wordebd import WORDEBD\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use(\"fivethirtyeight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12840, 12)\n",
      "(3400, 12)\n",
      "(1462, 12)\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"dataset_drop_noise\"\n",
    "\n",
    "# Read the CSV file\n",
    "TrainData = pd.read_csv('data/dataset_original/NOT_FOR_TRAINING/train_sent_emo_dya.csv', encoding='shift_jis')\n",
    "TestData = pd.read_csv('data/dataset_original/NOT_FOR_TRAINING/test_sent_emo_dya.csv', encoding='utf-8')\n",
    "DevData = pd.read_csv('data/dataset_original/NOT_FOR_TRAINING/dev_sent_emo_dya.csv', encoding='utf-8')\n",
    "\n",
    "# Display the first three rows\n",
    "print(TrainData.shape)\n",
    "print(TestData.shape)\n",
    "print(DevData.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping of Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop Old_Dialogue_ID, Old_Utterance_ID, Season, Episode, StartTime, and EndTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Old_Dialogue_ID',\n",
       " 'Old_Utterance_ID',\n",
       " 'Season',\n",
       " 'Episode',\n",
       " 'StartTime',\n",
       " 'EndTime']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define features to drop\n",
    "drop_features = list(TrainData.columns[6:]) \n",
    "drop_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop features from X_train DataFrame\n",
    "TrainData = TrainData.drop(drop_features, axis=1)\n",
    "TestData = TestData.drop(drop_features, axis=1)\n",
    "DevData = DevData.drop(drop_features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = True\n",
    "\n",
    "checkFile1 = os.path.isfile(\"data/dump/\" + dataset_path + \"/label_encoder.pkl\")\n",
    "checkFile2 = os.path.isfile(\"data/dump/\" + dataset_path + \"/label_decoder.pkl\")\n",
    "\n",
    "if not (checkFile1 and checkFile2):\n",
    "    labels = sorted(set(TrainData.Emotion))\n",
    "    labelEncoder = {label: i for i, label in enumerate(labels)}\n",
    "    labelDecoder = {i: label for i, label in enumerate(labels)}\n",
    "\n",
    "    pickle.dump(labelEncoder, open('data/dump/' + dataset_path + '/label_encoder.pkl', 'wb'))\n",
    "    pickle.dump(labelDecoder, open('data/dump/' + dataset_path + '/label_decoder.pkl', 'wb'))\n",
    "else:\n",
    "    file1 = open('data/dump/' + dataset_path + '/label_encoder.pkl', 'rb')\n",
    "    file2 = open('data/dump/' + dataset_path + '/label_decoder.pkl', 'rb')\n",
    "    labelEncoder = pickle.load(file1)\n",
    "    labelDecoder = pickle.load(file2)\n",
    "    file1.close()\n",
    "    file2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anger': 0,\n",
       " 'disgust': 1,\n",
       " 'fear': 2,\n",
       " 'joy': 3,\n",
       " 'neutral': 4,\n",
       " 'sadness': 5,\n",
       " 'surprise': 6}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_labels(encoder, l):\n",
    "    return encoder[l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply label encoding to the \"Emotion\" column in y_train\n",
    "TrainData[\"Emotion\"] = TrainData[\"Emotion\"].apply(lambda x: encode_labels(labelEncoder, x))\n",
    "TestData[\"Emotion\"] = TestData[\"Emotion\"].apply(lambda x: encode_labels(labelEncoder, x))\n",
    "DevData[\"Emotion\"] = DevData[\"Emotion\"].apply(lambda x: encode_labels(labelEncoder, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_value_ranges(lst):\n",
    "    value_ranges = []\n",
    "    start_index = 0\n",
    "\n",
    "    for i in range(1, len(lst)):\n",
    "        if lst[i] != lst[i - 1]:\n",
    "            value_ranges.append((start_index, i - 1))\n",
    "            start_index = i\n",
    "\n",
    "    # Add the last range\n",
    "    value_ranges.append((start_index, len(lst) - 1))\n",
    "\n",
    "    return value_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2160\n",
      "577\n",
      "270\n"
     ]
    }
   ],
   "source": [
    "rangesTrain = find_value_ranges(TrainData[\"Dialogue_ID\"])\n",
    "print(len(rangesTrain))\n",
    "\n",
    "rangesTest = find_value_ranges(TestData[\"Dialogue_ID\"])\n",
    "print(len(rangesTest))\n",
    "\n",
    "rangesDev = find_value_ranges(DevData[\"Dialogue_ID\"])\n",
    "print(len(rangesDev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copying orginal dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section will copy the current dataframe to be ready for export and stored at dataset_original since dataset_original will NOT have any pre-processing of utterances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainData_Original =  TrainData.copy()\n",
    "TestData_Original = TestData.copy()\n",
    "DevData_Original = DevData.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\edayo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\edayo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\edayo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download NLTK data (if not already downloaded)\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Make a copy of X_train_utterances\n",
    "train_utterances = TrainData['Utterance']\n",
    "test_utterances = TestData['Utterance']\n",
    "dev_utterances = DevData['Utterance']\n",
    "\n",
    "# Initialize the lemmatizer and stop words\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "custom_stop_words = set([\n",
    "    'a', 'an', 'the', 'and', 'but', 'or', 'nor', 'for', 'yet', 'so',\n",
    "    'at', 'by', 'for', 'in', 'of', 'on', 'to', 'with', 'about', 'above',\n",
    "    'across', 'after', 'against', 'along', 'among', 'around', 'as', 'before',\n",
    "    'behind', 'below', 'beneath', 'beside', 'between', 'beyond', 'during',\n",
    "    'except', 'from', 'inside', 'into', 'near', 'outside', 'over', 'through',\n",
    "    'under', 'until', 'up', 'upon', 'within', 'without', 'I', 'me', 'my',\n",
    "    'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours',\n",
    "    'yourself', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers',\n",
    "    'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs',\n",
    "    'themselves', 'am', 'is', 'are', 'was', 'were', 'be', 'being', 'been',\n",
    "    'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'get',\n",
    "    'go', 'make', 'take', 'want', 'know', 'see', 'come', 'think', 'look',\n",
    "    'use', 'find', 'give', 'tell', 'work', 'call', 'try', 'ask', 'need',\n",
    "    'feel', 'become', 'leave', 'put', 'mean', 'keep', 'let', 'begin',\n",
    "    'seem', 'help', 'talk', 'turn', 'start', 'show', 'hear', 'play', 'run',\n",
    "    'move', 'like', 'live', 'believe', 'hold', 'bring', 'happen', 'write',\n",
    "    'provide', 'sit', 'stand', 'lose', 'pay', 'meet', 'include', 'continue',\n",
    "    'set', 'learn', 'change', 'lead', 'understand', 'watch', 'follow',\n",
    "    'stop', 'create', 'speak', 'read', 'allow', 'add', 'spend', 'grow',\n",
    "    'open', 'walk', 'win', 'offer', 'remember', 'love', 'consider',\n",
    "    'appear', 'buy', 'serve', 'die', 'send', 'expect', 'build', 'stay',\n",
    "    'fall', 'cut', 'reach', 'kill', 'remain', 'suggest', 'raise', 'pass',\n",
    "    'sell', 'require', 'report', 'decide', 'pull', 'become', 'very',\n",
    "    'really', 'too', 'quite', 'much', 'so', 'just', 'even', 'now', 'then',\n",
    "    'here', 'there', 'when', 'where', 'why', 'how', 'well', 'also', 'such',\n",
    "    'still', 'only', 'always', 'never', 'ever', 'often', 'usually',\n",
    "    'sometimes', 'once', 'this', 'that', 'these', 'those', 'each', 'every',\n",
    "    'all', 'some', 'any', 'both', 'few', 'many', 'much', 'more', 'most',\n",
    "    'other', 'another', 'such', 'same', 'own', 'what', 'which', 'either',\n",
    "    'neither', 'not', 'no', \"n't\", 'nor', 'oh', 'ah', 'uh', 'um'\n",
    "])\n",
    "\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Tokenize\n",
    "    words = word_tokenize(text)\n",
    "\n",
    "    # Remove punctuation and non-alphabetic characters, and stop words\n",
    "    words = [word for word in words if word.isalpha() and word not in custom_stop_words]\n",
    "\n",
    "    # Lemmatize\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "    # Join words back into a single string\n",
    "    cleaned_text = ' '.join(words)\n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "# Apply the clean_text function to each utterance\n",
    "train_utterances = train_utterances.apply(clean_text)\n",
    "test_utterances = test_utterances.apply(clean_text)\n",
    "dev_utterances = dev_utterances.apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    i point person company s transition system\n",
       "1                             must ve hand full\n",
       "2                                           i i\n",
       "3                             s little bit duty\n",
       "4                                    duty right\n",
       "Name: Utterance, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_utterances.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                          re coffee mug number bottom\n",
       "1    s monica can track way if one missing can s nu...\n",
       "2                                                     \n",
       "3                                                 okay\n",
       "4                                    ross say elevator\n",
       "Name: Utterance, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_utterances.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              god s lost s totally lost\n",
       "1                                       \n",
       "2    could bank close account off source\n",
       "3                              re genius\n",
       "4                              re genius\n",
       "Name: Utterance, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_utterances.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for empty strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty in Train Utterances: 940\n",
      "Empty in Test Utterances: 239\n",
      "Empty in Dev Utterances: 122\n"
     ]
    }
   ],
   "source": [
    "# Count the empty string values in X_train_utterances\n",
    "empty_string_count_train = (train_utterances == '').sum()\n",
    "empty_string_count_test = (test_utterances == '').sum()\n",
    "empty_string_count_dev = (dev_utterances == '').sum()\n",
    "\n",
    "print(f\"Empty in Train Utterances: {empty_string_count_train}\")\n",
    "print(f\"Empty in Test Utterances: {empty_string_count_test}\")\n",
    "print(f\"Empty in Dev Utterances: {empty_string_count_dev}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update 'Utterance' column and remove all empty strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (11900, 6)\n",
      "Test data shape: (3161, 6)\n",
      "Dev data shape: (1340, 6)\n"
     ]
    }
   ],
   "source": [
    "# Update X_train with the cleaned utterances\n",
    "TrainData['Utterance'] = train_utterances\n",
    "TestData['Utterance'] = test_utterances\n",
    "DevData['Utterance'] = dev_utterances\n",
    "\n",
    "# Drop rows where Utterance is an empty string. Empty string value is ''.\n",
    "TrainData = TrainData[TrainData['Utterance'] != '']\n",
    "TestData = TestData[TestData['Utterance'] != '']\n",
    "DevData = DevData[DevData['Utterance'] != '']\n",
    "\n",
    "# Reset the index\n",
    "TrainData.reset_index(drop=True, inplace=True)\n",
    "TestData.reset_index(drop=True, inplace=True)\n",
    "DevData.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(f\"Train data shape: {TrainData.shape}\")\n",
    "print(f\"Test data shape: {TestData.shape}\")\n",
    "print(f\"Dev data shape: {DevData.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Take note of new shape of Train and Test Data after dropping the values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove rows with *n* or below number of words and create a new **Dropped Words Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing rows that is 2 words or below:\n",
      "Train shape : (7359, 6)\n",
      "Test shape: (1981, 6)\n",
      "Test shape: (858, 6)\n"
     ]
    }
   ],
   "source": [
    "n = 2 # This number removes rows with n or less words. (Retains rows with more than n words)\n",
    "\n",
    "# Retain rows with more than n words\n",
    "TrainData = TrainData[TrainData['Utterance'].apply(lambda x: len(x.split()) > n)]\n",
    "TestData = TestData[TestData['Utterance'].apply(lambda x: len(x.split()) > n)]\n",
    "DevData = DevData[DevData['Utterance'].apply(lambda x: len(x.split()) > n)]\n",
    "\n",
    "TrainData.reset_index(drop=True, inplace=True)\n",
    "TestData.reset_index(drop=True, inplace=True)\n",
    "DevData.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(f\"After removing rows that is {n} words or below:\")\n",
    "print(f\"Train shape : {TrainData.shape}\")\n",
    "print(f\"Test shape: {TestData.shape}\")\n",
    "print(f\"Test shape: {DevData.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get random sample from train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>i gon na chance apologise</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2093</th>\n",
       "      <td>relax s issac s philly should</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>i don t adrienne s attracted victor</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>hey ross i told i don t</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2654</th>\n",
       "      <td>ross re right i don t i thought real grass</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4638</th>\n",
       "      <td>i thought said could shoot spot</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3881</th>\n",
       "      <td>wow if people knew</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2822</th>\n",
       "      <td>hey guy i m writing holiday song everyone</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5323</th>\n",
       "      <td>s right wesley i stopped say re real doctor wo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6803</th>\n",
       "      <td>i made promise hey</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Utterance  Emotion\n",
       "396                           i gon na chance apologise        1\n",
       "2093                      relax s issac s philly should        4\n",
       "288                 i don t adrienne s attracted victor        1\n",
       "1593                            hey ross i told i don t        0\n",
       "2654         ross re right i don t i thought real grass        5\n",
       "4638                    i thought said could shoot spot        4\n",
       "3881                                 wow if people knew        6\n",
       "2822          hey guy i m writing holiday song everyone        3\n",
       "5323  s right wesley i stopped say re real doctor wo...        0\n",
       "6803                                 i made promise hey        6"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randomly select 10 rows\n",
    "random_sample = TrainData.sample(n=10)[[\"Utterance\", \"Emotion\"]]\n",
    "\n",
    "random_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>shh told off kiss everything</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1784</th>\n",
       "      <td>i i sorry</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>yes cool because i model</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1754</th>\n",
       "      <td>i shared puddin man</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1180</th>\n",
       "      <td>would characterize theme book rachel green</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1390</th>\n",
       "      <td>yeah right right walkin right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1167</th>\n",
       "      <td>i i saw</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>could i possibly done</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>okay ll today ll deal</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564</th>\n",
       "      <td>check out okay i can guest coming okay</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Utterance  Emotion\n",
       "763                 shh told off kiss everything        4\n",
       "1784                                   i i sorry        4\n",
       "997                     yes cool because i model        4\n",
       "1754                         i shared puddin man        0\n",
       "1180  would characterize theme book rachel green        4\n",
       "1390               yeah right right walkin right        0\n",
       "1167                                     i i saw        4\n",
       "1017                       could i possibly done        0\n",
       "867                        okay ll today ll deal        4\n",
       "1564      check out okay i can guest coming okay        4"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randomly select 10 rows\n",
    "random_sample = TestData.sample(n=10)[[\"Utterance\", \"Emotion\"]]\n",
    "\n",
    "random_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>man listen gon na squeeze perps shoe little bi...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>i mention carl guy i hired identical twin medi...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>woman museum called said cancellation could we...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>child coming world building negative fighting ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>s chandler s way pretending didn t mime</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>i bet great story</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>saw way ran out</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>damn robot re supposed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>yeah hi ken adam nice</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>course sweetie brand new</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Utterance  Emotion\n",
       "82   man listen gon na squeeze perps shoe little bi...        3\n",
       "392  i mention carl guy i hired identical twin medi...        4\n",
       "166  woman museum called said cancellation could we...        2\n",
       "380  child coming world building negative fighting ...        0\n",
       "808            s chandler s way pretending didn t mime        4\n",
       "844                                  i bet great story        3\n",
       "660                                    saw way ran out        5\n",
       "632                             damn robot re supposed        0\n",
       "752                              yeah hi ken adam nice        4\n",
       "247                           course sweetie brand new        4"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randomly select 10 rows\n",
    "random_sample = DevData.sample(n=10)[[\"Utterance\", \"Emotion\"]]\n",
    "\n",
    "random_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib.cm' has no attribute 'get_cmap'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m top_words\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Corrected WordCloud generation for all datasets\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m WC_Train \u001b[38;5;241m=\u001b[39m \u001b[43mWordCloud\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_font_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m800\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1600\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwhite\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m     11\u001b[0m \u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerate(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(TrainData\u001b[38;5;241m.\u001b[39mUtterance))\n\u001b[0;32m     13\u001b[0m WC_Test \u001b[38;5;241m=\u001b[39m WordCloud(\n\u001b[0;32m     14\u001b[0m     max_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2000\u001b[39m, min_font_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, height\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m800\u001b[39m, width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1600\u001b[39m, background_color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhite\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     15\u001b[0m )\u001b[38;5;241m.\u001b[39mgenerate(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(TestData\u001b[38;5;241m.\u001b[39mUtterance))\n\u001b[0;32m     17\u001b[0m WC_Dev \u001b[38;5;241m=\u001b[39m WordCloud(\n\u001b[0;32m     18\u001b[0m     max_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2000\u001b[39m, min_font_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, height\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m800\u001b[39m, width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1600\u001b[39m, background_color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhite\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     19\u001b[0m )\u001b[38;5;241m.\u001b[39mgenerate(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(DevData\u001b[38;5;241m.\u001b[39mUtterance))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\wordcloud\\wordcloud.py:337\u001b[0m, in \u001b[0;36mWordCloud.__init__\u001b[1;34m(self, font_path, width, height, margin, ranks_only, prefer_horizontal, mask, scale, color_func, max_words, min_font_size, stopwords, random_state, background_color, max_font_size, font_step, mode, relative_scaling, regexp, collocations, colormap, normalize_plurals, contour_width, contour_color, repeat, include_numbers, min_word_length, collocation_threshold)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontour_width \u001b[38;5;241m=\u001b[39m contour_width\n\u001b[0;32m    336\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale \u001b[38;5;241m=\u001b[39m scale\n\u001b[1;32m--> 337\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolor_func \u001b[38;5;241m=\u001b[39m color_func \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mcolormap_color_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolormap\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_words \u001b[38;5;241m=\u001b[39m max_words\n\u001b[0;32m    339\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstopwords \u001b[38;5;241m=\u001b[39m stopwords \u001b[38;5;28;01mif\u001b[39;00m stopwords \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m STOPWORDS\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\wordcloud\\wordcloud.py:106\u001b[0m, in \u001b[0;36mcolormap_color_func.__init__\u001b[1;34m(self, colormap)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, colormap):\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m--> 106\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolormap \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_cmap\u001b[49m(colormap)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'matplotlib.cm' has no attribute 'get_cmap'"
     ]
    }
   ],
   "source": [
    "# # WORD CLOUDS\n",
    "# # Function to get the top 10 words from a word cloud\n",
    "# def get_top_words(wordcloud):\n",
    "#     word_freq = wordcloud.words_\n",
    "#     top_words = [word for word, freq in sorted(word_freq.items(), key=lambda x: x[1], reverse=True)[:10]]\n",
    "#     return top_words\n",
    "\n",
    "# # Corrected WordCloud generation for all datasets\n",
    "# WC_Train = WordCloud(\n",
    "#     max_words=2000, min_font_size=10, height=800, width=1600, background_color=\"white\"\n",
    "# ).generate(\" \".join(TrainData.Utterance))\n",
    "\n",
    "# WC_Test = WordCloud(\n",
    "#     max_words=2000, min_font_size=10, height=800, width=1600, background_color=\"white\"\n",
    "# ).generate(\" \".join(TestData.Utterance))\n",
    "\n",
    "# WC_Dev = WordCloud(\n",
    "#     max_words=2000, min_font_size=10, height=800, width=1600, background_color=\"white\"\n",
    "# ).generate(\" \".join(DevData.Utterance))\n",
    "\n",
    "# # Get top 10 words for each dataset\n",
    "# top_words_train = get_top_words(WC_Train)\n",
    "# top_words_test = get_top_words(WC_Test)\n",
    "# top_words_dev = get_top_words(WC_Dev)\n",
    "\n",
    "# # Print the top words\n",
    "# print(\"Top words in TrainData:\", top_words_train)\n",
    "# print(\"Top words in TestData:\", top_words_test)\n",
    "# print(\"Top words in DevData:\", top_words_dev)\n",
    "\n",
    "# # PLOT\n",
    "# fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(20, 30))  # Adjust the layout and size as needed\n",
    "# axes = axes.flatten()  # Flatten the 2D array to 1D for easier indexing\n",
    "\n",
    "# wordclouds = [WC_Train, WC_Test, WC_Dev]\n",
    "# titles = ['TrainData', 'TestData', 'DevData']\n",
    "\n",
    "# # Plot each WordCloud\n",
    "# for idx, wc in enumerate(wordclouds):\n",
    "#     axes[idx].imshow(wc, interpolation='bilinear')\n",
    "#     axes[idx].set_title(titles[idx], fontsize=16)\n",
    "#     axes[idx].axis('off')\n",
    "\n",
    "# # Remove any empty subplots (if applicable)\n",
    "# for idx in range(len(wordclouds), len(axes)):\n",
    "#     fig.delaxes(axes[idx])\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Division of X and y data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame for target labels\n",
    "y_train = pd.DataFrame()\n",
    "y_test = pd.DataFrame()\n",
    "y_dev = pd.DataFrame()\n",
    "\n",
    "X_train = TrainData\n",
    "X_test = TestData\n",
    "X_dev = DevData\n",
    "    \n",
    "y_train[\"Emotion\"] = TrainData[\"Emotion\"].copy()\n",
    "y_test[\"Emotion\"] = TestData[\"Emotion\"].copy()\n",
    "y_dev[\"Emotion\"] = DevData[\"Emotion\"].copy()\n",
    "\n",
    "y_train[\"Dialogue_ID\"] = TrainData[\"Dialogue_ID\"].copy()\n",
    "y_test[\"Dialogue_ID\"] = TestData[\"Dialogue_ID\"].copy()\n",
    "y_dev[\"Dialogue_ID\"] = DevData[\"Dialogue_ID\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (7359, 6)\n",
      "Shape of y_train: (7359, 2)\n",
      "--\n",
      "Shape of X_test: (1981, 6)\n",
      "Shape of y_test: (1981, 2)\n",
      "--\n",
      "Shape of X_dev: (858, 6)\n",
      "Shape of y_dev: (858, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f'Shape of X_train: {X_train.shape}')\n",
    "print(f'Shape of y_train: {y_train.shape}')\n",
    "print('--')\n",
    "print(f'Shape of X_test: {X_test.shape}')\n",
    "print(f'Shape of y_test: {y_test.shape}')\n",
    "print('--')\n",
    "print(f'Shape of X_dev: {X_dev.shape}')\n",
    "print(f'Shape of y_dev: {y_dev.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output data to new csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Label Encoding Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check if the file already exists\n",
    "# checkFile1 = os.path.isfile(\"data/dump/\" + dataset_path + \"/labels_train.pkl\")\n",
    "# checkFile2 = os.path.isfile(\"data/dump/\" + dataset_path + \"/labels_test.pkl\")\n",
    "\n",
    "# if key:\n",
    "#     pickle.dump(X_train[\"Emotion\"], open('data/dump/' + dataset_path + '/labels_train.pkl', 'wb'))\n",
    "#     pickle.dump(X_test[\"Emotion\"], open('data/dump/' + dataset_path + '/labels_test.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Drop Noise Training and Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exportDataToCSV(df, name):\n",
    "    path = \"data/\" + dataset_path + \"/\" + name + \".csv\"\n",
    "    df.to_csv(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Dialogue_ID</th>\n",
       "      <th>Utterance_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i point person company s transition system</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>4</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>must ve hand full</td>\n",
       "      <td>The Interviewer</td>\n",
       "      <td>4</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s little bit duty</td>\n",
       "      <td>The Interviewer</td>\n",
       "      <td>4</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ll heading whole division ll lot duty</td>\n",
       "      <td>The Interviewer</td>\n",
       "      <td>4</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ll perhaps people can dump certain amount</td>\n",
       "      <td>The Interviewer</td>\n",
       "      <td>4</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7354</th>\n",
       "      <td>guy messing right</td>\n",
       "      <td>Joey</td>\n",
       "      <td>6</td>\n",
       "      <td>positive</td>\n",
       "      <td>2158</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7355</th>\n",
       "      <td>i got ta side chandler one</td>\n",
       "      <td>Joey</td>\n",
       "      <td>4</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2159</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7356</th>\n",
       "      <td>i first moved city i went out couple time girl...</td>\n",
       "      <td>Joey</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>2159</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7357</th>\n",
       "      <td>guy messing right</td>\n",
       "      <td>Joey</td>\n",
       "      <td>6</td>\n",
       "      <td>positive</td>\n",
       "      <td>2159</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7358</th>\n",
       "      <td>good one second i whoa</td>\n",
       "      <td>Joey</td>\n",
       "      <td>3</td>\n",
       "      <td>positive</td>\n",
       "      <td>2159</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7359 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Utterance          Speaker  \\\n",
       "0            i point person company s transition system         Chandler   \n",
       "1                                     must ve hand full  The Interviewer   \n",
       "2                                     s little bit duty  The Interviewer   \n",
       "3                 ll heading whole division ll lot duty  The Interviewer   \n",
       "4             ll perhaps people can dump certain amount  The Interviewer   \n",
       "...                                                 ...              ...   \n",
       "7354                                  guy messing right             Joey   \n",
       "7355                         i got ta side chandler one             Joey   \n",
       "7356  i first moved city i went out couple time girl...             Joey   \n",
       "7357                                  guy messing right             Joey   \n",
       "7358                             good one second i whoa             Joey   \n",
       "\n",
       "      Emotion Sentiment  Dialogue_ID  Utterance_ID  \n",
       "0           4   neutral            0             0  \n",
       "1           4   neutral            0             1  \n",
       "2           4   neutral            0             3  \n",
       "3           4   neutral            0             5  \n",
       "4           4   neutral            0             7  \n",
       "...       ...       ...          ...           ...  \n",
       "7354        6  positive         2158             5  \n",
       "7355        4   neutral         2159             1  \n",
       "7356        1  negative         2159             2  \n",
       "7357        6  positive         2159             4  \n",
       "7358        3  positive         2159             6  \n",
       "\n",
       "[7359 rows x 6 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "exportDataToCSV(X_train, \"X_train\")\n",
    "exportDataToCSV(y_train, \"y_train\")\n",
    "\n",
    "exportDataToCSV(X_test, \"X_test\")\n",
    "exportDataToCSV(y_test, \"y_test\")\n",
    "\n",
    "exportDataToCSV(X_dev, \"X_dev\")\n",
    "exportDataToCSV(y_dev, \"y_dev\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Original Training and Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_path = \"dataset_original\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exportDataToCSV(TrainData_Original, \"X_train\")\n",
    "# exportDataToCSV(TrainData_Original['Emotion'], \"y_train\")\n",
    "\n",
    "# exportDataToCSV(TestData_Original, \"X_test\")\n",
    "# exportDataToCSV(TestData_Original['Emotion'], \"y_test\")\n",
    "\n",
    "# exportDataToCSV(DevData_Original, \"X_dev\")\n",
    "# exportDataToCSV(DevData_Original['Emotion'], \"y_dev\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
