{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing of libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import collections\n",
    "from vocab import Vocab, Vectors\n",
    "from wordebd import WORDEBD\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12840, 12)\n",
      "(3400, 12)\n",
      "(1462, 12)\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"dataset_drop_noise\"\n",
    "\n",
    "# Read the CSV file\n",
    "TrainData = pd.read_csv('data/dataset_original/train_sent_emo_dya.csv', encoding='shift_jis')\n",
    "TestData = pd.read_csv('data/dataset_original/test_sent_emo_dya.csv', encoding='utf-8')\n",
    "DevData = pd.read_csv('data/dataset_original/dev_sent_emo_dya.csv', encoding='utf-8')\n",
    "\n",
    "# Display the first three rows\n",
    "print(TrainData.shape)\n",
    "print(TestData.shape)\n",
    "print(DevData.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping of Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop Old_Dialogue_ID, Old_Utterance_ID, Season, Episode, StartTime, and EndTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Old_Dialogue_ID',\n",
       " 'Old_Utterance_ID',\n",
       " 'Season',\n",
       " 'Episode',\n",
       " 'StartTime',\n",
       " 'EndTime']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define features to drop\n",
    "drop_features = list(TrainData.columns[6:]) \n",
    "drop_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop features from X_train DataFrame\n",
    "if not drop_features:\n",
    "    TrainData = TrainData.drop(drop_features, axis=1)\n",
    "    TestData = TestData.drop(drop_features, axis=1)\n",
    "    DevData = DevData.drop(drop_features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkFile1 = os.path.isfile(\"data/dump/\" + dataset_path + \"/label_encoder.pkl\")\n",
    "checkFile2 = os.path.isfile(\"data/dump/\" + dataset_path + \"/label_decoder.pkl\")\n",
    "\n",
    "key = True\n",
    "\n",
    "if not (checkFile1 and checkFile2):\n",
    "    labels = sorted(set(TrainData.Emotion))\n",
    "    labelEncoder = {label: i for i, label in enumerate(labels)}\n",
    "    labelDecoder = {i: label for i, label in enumerate(labels)}\n",
    "\n",
    "    pickle.dump(labelEncoder, open('data/dump/' + dataset_path + '/label_encoder.pkl', 'wb'))\n",
    "    pickle.dump(labelDecoder, open('data/dump/' + dataset_path + '/label_decoder.pkl', 'wb'))\n",
    "else:\n",
    "    file1 = open('data/dump/' + dataset_path + '/label_encoder.pkl', 'rb')\n",
    "    file2 = open('data/dump/' + dataset_path + '/label_decoder.pkl', 'rb')\n",
    "    labelEncoder = pickle.load(file1)\n",
    "    labelDecoder = pickle.load(file2)\n",
    "    file1.close()\n",
    "    file2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anger': 0,\n",
       " 'disgust': 1,\n",
       " 'fear': 2,\n",
       " 'joy': 3,\n",
       " 'neutral': 4,\n",
       " 'sadness': 5,\n",
       " 'surprise': 6}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_labels(encoder, l):\n",
    "    return encoder[l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply label encoding to the \"Emotion\" column in y_train\n",
    "TrainData[\"Emotion\"] = TrainData[\"Emotion\"].apply(lambda x: encode_labels(labelEncoder, x))\n",
    "TestData[\"Emotion\"] = TestData[\"Emotion\"].apply(lambda x: encode_labels(labelEncoder, x))\n",
    "DevData[\"Emotion\"] = DevData[\"Emotion\"].apply(lambda x: encode_labels(labelEncoder, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_value_ranges(lst):\n",
    "    value_ranges = []\n",
    "    start_index = 0\n",
    "\n",
    "    for i in range(1, len(lst)):\n",
    "        if lst[i] != lst[i - 1]:\n",
    "            value_ranges.append((start_index, i - 1))\n",
    "            start_index = i\n",
    "\n",
    "    # Add the last range\n",
    "    value_ranges.append((start_index, len(lst) - 1))\n",
    "\n",
    "    return value_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2160\n",
      "577\n",
      "270\n"
     ]
    }
   ],
   "source": [
    "rangesTrain = find_value_ranges(TrainData[\"Dialogue_ID\"])\n",
    "print(len(rangesTrain))\n",
    "\n",
    "rangesTest = find_value_ranges(TestData[\"Dialogue_ID\"])\n",
    "print(len(rangesTest))\n",
    "\n",
    "rangesDev = find_value_ranges(DevData[\"Dialogue_ID\"])\n",
    "print(len(rangesDev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speaker Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding speaker on train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check if the file exists\n",
    "# checkFile = os.path.isfile(\"data/dump/\" + dataset_path + \"/speaker_encoder_train.pkl\")\n",
    "# encodedSpeakersTrain = []\n",
    "\n",
    "# if not checkFile:\n",
    "#     for range_pair in rangesTrain:\n",
    "#         start_idx, end_idx = range_pair\n",
    "#         speaker_per_dialog = TrainData['Speaker'][start_idx:end_idx + 1].copy()\n",
    "#         speaker_feature = sorted(set(speaker_per_dialog))\n",
    "#         speaker_encoder = {feature: i for i, feature in enumerate(speaker_feature)}\n",
    "#         speaker_decoder = {i: feature for i, feature in enumerate(speaker_feature)}\n",
    "\n",
    "#         encoded_speaker = speaker_per_dialog.replace(speaker_encoder)\n",
    "#         encodedSpeakersTrain.append(encoded_speaker)\n",
    "\n",
    "#     # Save encoded speaker list and ranges to a file using pickle\n",
    "#     file_path = 'data/dump/' + dataset_path + '/speaker_encoder_train.pkl'\n",
    "#     with open(file_path, 'wb') as file:\n",
    "#         pickle.dump([encodedSpeakersTrain, rangesTrain], file)\n",
    "# else:\n",
    "#     # Load encoded speaker list and ranges from the existing pickle file\n",
    "#     file = open('data/dump/' + dataset_path + '/speaker_encoder_train.pkl', \"rb\")\n",
    "#     encodedSpeakersTrain, rangesTrain = pickle.load(file)\n",
    "#     file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding speaker on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check if the file exists\n",
    "# checkFile = os.path.isfile(\"data/dump/\" + dataset_path + \"/speaker_encoder_test.pkl\")\n",
    "# encodedSpeakersTest = []\n",
    "\n",
    "# if not checkFile:\n",
    "#     for range_pair in rangesTest:\n",
    "#         start_idx, end_idx = range_pair\n",
    "#         speaker_per_dialog = TestData['Speaker'][start_idx:end_idx + 1].copy()\n",
    "#         speaker_feature = sorted(set(speaker_per_dialog))\n",
    "#         speaker_encoder = {feature: i for i, feature in enumerate(speaker_feature)}\n",
    "#         speaker_decoder = {i: feature for i, feature in enumerate(speaker_feature)}\n",
    "\n",
    "#         encoded_speaker = speaker_per_dialog.replace(speaker_encoder)\n",
    "#         encodedSpeakersTest.append(encoded_speaker)\n",
    "\n",
    "#     # Save encoded speaker list and ranges to a file using pickle\n",
    "#     file_path = 'data/dump/' + dataset_path + '/speaker_encoder_test.pkl'\n",
    "#     with open(file_path, 'wb') as file:\n",
    "#         pickle.dump([encodedSpeakersTest, rangesTest], file)\n",
    "# else:\n",
    "#     # Load encoded speaker list and ranges from the existing pickle file\n",
    "#     file = open('data/dump/' + dataset_path + '/speaker_encoder_test.pkl', \"rb\")\n",
    "#     encodedSpeakersTest, rangesTest = pickle.load(file)\n",
    "#     file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check if the file exists\n",
    "# checkFile = os.path.isfile(\"data/dump/\" + dataset_path + \"/speaker_encoder_dev.pkl\")\n",
    "# encodedSpeakersDev = []\n",
    "\n",
    "# if not checkFile:\n",
    "#     for range_pair in rangesDev:\n",
    "#         start_idx, end_idx = range_pair\n",
    "#         speaker_per_dialog = DevData['Speaker'][start_idx:end_idx + 1].copy()\n",
    "#         speaker_feature = sorted(set(speaker_per_dialog))\n",
    "#         speaker_encoder = {feature: i for i, feature in enumerate(speaker_feature)}\n",
    "#         speaker_decoder = {i: feature for i, feature in enumerate(speaker_feature)}\n",
    "\n",
    "#         encoded_speaker = speaker_per_dialog.replace(speaker_encoder)\n",
    "#         encodedSpeakersDev.append(encoded_speaker)\n",
    "\n",
    "#     # Save encoded speaker list and ranges to a file using pickle\n",
    "#     file_path = 'data/dump/' + dataset_path + '/speaker_encoder_dev.pkl'\n",
    "#     with open(file_path, 'wb') as file:\n",
    "#         pickle.dump([encodedSpeakersDev, rangesDev], file)\n",
    "# else:\n",
    "#     # Load encoded speaker list and ranges from the existing pickle file\n",
    "#     with open('data/dump/' + dataset_path + '/speaker_encoder_dev.pkl', \"rb\") as file:\n",
    "#         encodedSpeakersDev, rangesDev = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the encoded speakers in the Train and Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the list of encoded speakers if it is nested\n",
    "# encodedSpeakersTrain_flat = [item for sublist in encodedSpeakersTrain for item in sublist]\n",
    "# encodedSpeakersTest_flat  = [item for sublist in encodedSpeakersTest for item in sublist]\n",
    "# encodedSpeakersDev_flat  = [item for sublist in encodedSpeakersDev for item in sublist]\n",
    "\n",
    "# Replace the 'Speaker' column in TrainData with the encoded speaker data\n",
    "# TrainData['Speaker'] = encodedSpeakersTrain_flat\n",
    "# TestData['Speaker'] = encodedSpeakersTest_flat\n",
    "# DevData['Speaker'] = encodedSpeakersDev_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Chandler', 'The Interviewer', 'Joey', 'Rachel', 'Monica',\n",
       "       'Phoebe', 'Ross', 'Sergei', 'Customer', 'Jade', 'Mona', 'Charlie',\n",
       "       'Paleontologist', 'Professore Clerk', 'Caitlin', 'Nurse',\n",
       "       'Mr. Treeger', 'Carol', 'The Casting Director', 'Emily',\n",
       "       'Elizabeth', 'Paul', 'The Dry Cleaner', 'Joey and Chandler',\n",
       "       'Kate', 'The Director', 'Mr. Tribbiani', 'Guru Saj', 'Wayne',\n",
       "       'Richard', 'Dina', 'Bobby', 'Danny', 'Krista', 'Jill', 'Stevens',\n",
       "       'Doug', 'Bob', 'Mr. Franklin', 'Director', 'Janice', 'Tony',\n",
       "       'Peter', 'Ticket Counter Attendant', 'Dr. Long', 'Charlton Heston',\n",
       "       'Joshua', 'Nancy', 'Kim', 'Joanna', 'Cassie', 'Dr. Rhodes',\n",
       "       'Dr. Johnson', 'Kristen', 'Jester', 'Sarah', 'Pete',\n",
       "       'The Singing Man', 'Commercial', 'Mark', 'A Female Student', 'All',\n",
       "       'Cliff', 'Tag', 'Eric', 'Dr. Green', 'Mr. Heckles', 'Mr. Geller',\n",
       "       'Sophie', 'Singer', 'David', 'Hitchhiker', '1st Customer',\n",
       "       '2nd Customer', '3rd Customer', 'The Presenter', 'Policeman',\n",
       "       'Duncan', 'Jane', 'Message', 'Gary', 'Bonnie', 'Woman', 'Leslie',\n",
       "       'Isabella', \"Joey's Hand Twin\", 'Kiki', 'Joanne', 'Fireman No. 3',\n",
       "       'Susan', 'Mischa', 'The Assistant Director', 'Mrs. Geller',\n",
       "       'Emeril', 'Man', 'Jake', 'Tom', 'Lecturer', 'The Woman',\n",
       "       'Monica and Ross', 'The Vendor', 'Julio', 'Janine', 'Julie',\n",
       "       'Dr. Baldhara', 'Young Ethan', 'Dr. Leedbetter', 'Phoebe Sr.',\n",
       "       'Katie', 'Gunther', 'Earl', 'Barry', 'Robbie', 'Lydia', 'Bernice',\n",
       "       'Mindy', 'Robert', 'Issac', 'Chloe', 'Supervisor', 'Kathy',\n",
       "       'Voice', 'Stu', 'Tour Guide', 'Dr. Ledbetter', 'Mrs. Burgin',\n",
       "       'Mr. Burgin', 'Annabelle', 'Flight Attendant', 'Roger',\n",
       "       'Front Desk Clerk', 'Mr. Zelner', 'Student', 'Jason', 'Guy', 'Jim',\n",
       "       'Liam', 'Phoebe Sr', 'Stage Director', 'PBS Volunteer',\n",
       "       'Gary Collins', 'Carl', 'Phoebe and Rachel', 'The Cigarette Guy',\n",
       "       'Lorraine', 'an', 'Richard’s Date', 'Frank', 'Rachel and Phoebe',\n",
       "       \"Mona's Date\", 'Ross and Joey', 'Mike', 'Dr. Miller', 'Both',\n",
       "       'Receptionist', 'Mrs. Green', 'Marc', 'Dana', 'The Fireman',\n",
       "       'Drunken Gambler', 'Raymond', 'Kristin', 'Monica and Phoebe',\n",
       "       'A Student', 'Hoshi', 'Ben', 'Teacher', 'Stephanie', 'Evil Bitch',\n",
       "       'Sick Bastard', 'Kyle', 'Nurse #1', 'Nurse #2',\n",
       "       'Dr. Stryker Ramoray', 'Helena', 'Angela', 'Steve',\n",
       "       'Airline Employee', 'Janitor', 'Mr. Posner', 'Mrs. Lynch', 'Paolo',\n",
       "       'Megan', 'Joey and Ross', 'Hombre Man', 'Dr. Zane', 'Alice',\n",
       "       'Russell', 'Chip', 'The Lurker', 'The Security Guard',\n",
       "       'The Librarian', 'The Head Librarian', 'Guy #1', 'Shelley', 'Girl',\n",
       "       'Leader', 'Dr. Wesley', 'Dr. Drake Remoray', 'Hope', 'Stranger',\n",
       "       'Hold Voice', 'Rick', 'Vince', 'Phoebe/Waitress', 'Joey/Drake',\n",
       "       'Rachel/actress', 'Mr. Waltham', 'Mrs. Waltham', 'Ms. McKenna',\n",
       "       'Fake Monica', 'Doctor', 'Boy in the Cape', 'Mrs. Chatracus',\n",
       "       'Paula', 'Burt', 'Ursula', 'Older Scientist', 'Another Tour Guide',\n",
       "       'Another Scientist', 'The Potential Roommate', 'Aunt Lillian',\n",
       "       'Ronni', 'Cecilia', 'Hotel Clerk', 'Casey', 'The Instructor',\n",
       "       'Jay Leno', 'The Smoking Woman', 'Trudie Styler',\n",
       "       'The Acting Teacher', 'Dr. Franzblau', 'Mrs. Tedlock', 'The Guys',\n",
       "       'The Museum Official', 'The Croupier', 'Jeannine', 'The Conductor',\n",
       "       'Woman On Train', 'The Food Critic', 'The Cooking Teacher',\n",
       "       'Waiter', 'Allesandro', 'Terry', 'Friend No. 2', 'Friend No. 1',\n",
       "       'Her-Friends', 'Estelle', 'Mrs. Tribbiani', 'Larry',\n",
       "       'Fireman No. 1', 'Fireman No. 2', 'Dr. Oberman', 'Gerston',\n",
       "       'Santos', 'Petrie', \"Maitre d'\", 'Melissa', 'Stanley', 'The Grip'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainData['Speaker'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Mark', 'Rachel', 'Ross', 'Steve', 'Phoebe', 'Monica', 'Joey',\n",
       "       'Chandler', 'Marjorie', 'Jade', 'Fireman #1', 'Roger', 'Gary',\n",
       "       'A Waiter', 'The Waiter', 'Janice', 'Duncan', 'Danny', 'Man',\n",
       "       'Phoebe Sr', 'All', 'Carol', 'Dr. Franzblau', 'Student',\n",
       "       'Mr. Geller', 'Mrs. Geller', 'Mrs. Bing', 'Mr. Bing', 'Leslie',\n",
       "       'Phoebe and Leslie', 'Female Student', 'Judge', 'Chip', 'Kathy',\n",
       "       'Gunther', 'Flight Attendant', 'Larry', 'Molly',\n",
       "       'Ross and Chandler', 'Woman', 'The Director',\n",
       "       'The Casting Director', 'Nurse', 'Emily', 'Frank Sr.', 'Host',\n",
       "       'Mike', 'Wayne', 'Paul', 'Guest #1', 'Cliff', 'Lorraine', 'Guy',\n",
       "       'Sarah', 'Lydia', 'The Instructor', 'Dana',\n",
       "       'Ticket Counter Attendant', 'Brenda', 'Director',\n",
       "       'Rachel and Bonnie', 'Bonnie', 'Mr. Waltham', 'Jill', 'Eric',\n",
       "       'Frannie', 'Frank', 'Mona', 'Doug', 'Joanna', 'Sophie', 'Chloe',\n",
       "       'The Teacher', 'The Stripper', 'Elizabeth', 'Tag', 'Female Clerk',\n",
       "       'Kim', 'Nancy', 'The Fan', 'Erin', 'Bob', 'The Dry Cleaner',\n",
       "       'Mr. Treeger', 'David', 'Hold Voice', 'Tommy', 'Ginger', 'Dina',\n",
       "       'Jessica Lockhart', 'Cecilia', 'Waitress', 'Tour Guide',\n",
       "       'Mr. Kaplan', 'Alan', 'Drew', 'Pete', 'Doctor Connelly', 'Susan'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TestData['Speaker'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Phoebe', 'Monica', 'Ross', 'Chandler', 'Joey', 'All', 'Rachel',\n",
       "       'Estelle', 'Gary', 'Guy', 'Woman', 'Mrs. Green', 'Dr. Harad',\n",
       "       'Frank', 'Alice', 'Bob', 'Whitney', 'Kyle', 'Passerby', 'Susan',\n",
       "       'Cookie', 'Kori', 'Dr. Long', 'Carol', 'TV Announcer',\n",
       "       'The Hot Girl', 'Jen', 'Monica and Rachel', 'The Dry Cleaner',\n",
       "       'Carl', 'Waitress', 'Janine', 'Stage Manager', 'Lauren', 'Kate',\n",
       "       'Mrs. Geller', 'Joanna', 'Tag', 'Max', 'Elizabeth', 'Charlie',\n",
       "       'Doctor', 'Cliff', 'Jeannine', 'Ross and Rachel', 'Ursula'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DevData['Speaker'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\edayo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\edayo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\edayo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download NLTK data (if not already downloaded)\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Make a copy of X_train_utterances\n",
    "train_utterances = TrainData['Utterance']\n",
    "test_utterances = TestData['Utterance']\n",
    "dev_utterances = DevData['Utterance']\n",
    "\n",
    "# Initialize the lemmatizer and stop words\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Tokenize\n",
    "    words = word_tokenize(text)\n",
    "\n",
    "    # Remove punctuation and non-alphabetic characters, and stop words\n",
    "    words = [word for word in words if word.isalpha() and word not in stop_words]\n",
    "\n",
    "    # Lemmatize\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "    # Join words back into a single string\n",
    "    cleaned_text = ' '.join(words)\n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "# Apply the clean_text function to each utterance\n",
    "train_utterances = train_utterances.apply(clean_text)\n",
    "test_utterances = test_utterances.apply(clean_text)\n",
    "dev_utterances = dev_utterances.apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    also point person company transition system\n",
       "1                                 must hand full\n",
       "2                                               \n",
       "3                       let talk little bit duty\n",
       "4                                     duty right\n",
       "Name: Utterance, dtype: object"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_utterances.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                            coffee mug number bottom\n",
       "1    oh monica keep track way one missing like number\n",
       "2                                                    \n",
       "3                                                okay\n",
       "4                                   ross say elevator\n",
       "Name: Utterance, dtype: object"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_utterances.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                  oh god lost totally lost\n",
       "1                                          \n",
       "2    could go bank close account cut source\n",
       "3                                    genius\n",
       "4                                    genius\n",
       "Name: Utterance, dtype: object"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_utterances.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for empty strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty in Train Utterances: 664\n",
      "Empty in Test Utterances: 170\n",
      "Empty in Dev Utterances: 89\n"
     ]
    }
   ],
   "source": [
    "# Count the empty string values in X_train_utterances\n",
    "empty_string_count_train = (train_utterances == '').sum()\n",
    "empty_string_count_test = (test_utterances == '').sum()\n",
    "empty_string_count_dev = (dev_utterances == '').sum()\n",
    "\n",
    "print(f\"Empty in Train Utterances: {empty_string_count_train}\")\n",
    "print(f\"Empty in Test Utterances: {empty_string_count_test}\")\n",
    "print(f\"Empty in Dev Utterances: {empty_string_count_dev}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update 'Utterance' column and remove all empty strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (12176, 12)\n",
      "Test data shape: (3230, 12)\n",
      "Dev data shape: (1373, 12)\n"
     ]
    }
   ],
   "source": [
    "# Update X_train with the cleaned utterances\n",
    "TrainData['Utterance'] = train_utterances\n",
    "TestData['Utterance'] = test_utterances\n",
    "DevData['Utterance'] = dev_utterances\n",
    "\n",
    "# Drop rows where Utterance is an empty string. Empty string value is ''.\n",
    "TrainData = TrainData[TrainData['Utterance'] != '']\n",
    "TestData = TestData[TestData['Utterance'] != '']\n",
    "DevData = DevData[DevData['Utterance'] != '']\n",
    "\n",
    "# Reset the index\n",
    "TrainData.reset_index(drop=True, inplace=True)\n",
    "TestData.reset_index(drop=True, inplace=True)\n",
    "DevData.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(f\"Train data shape: {TrainData.shape}\")\n",
    "print(f\"Test data shape: {TestData.shape}\")\n",
    "print(f\"Dev data shape: {DevData.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Take note of new shape of Train and Test Data after dropping the values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove rows with *n* or below number of words and create a new **Dropped Words Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing rows that is 2 words or below:\n",
      "Train shape : (7354, 12)\n",
      "Test shape: (1973, 12)\n",
      "Test shape: (858, 12)\n"
     ]
    }
   ],
   "source": [
    "n = 2 # This number removes rows with n or less words. (Retains rows with more than n words)\n",
    "\n",
    "# Retain rows with more than n words\n",
    "Dropwords_TrainData = TrainData[TrainData['Utterance'].apply(lambda x: len(x.split()) > n)]\n",
    "Dropwords_TestData = TestData[TestData['Utterance'].apply(lambda x: len(x.split()) > n)]\n",
    "Dropwords_DevData = DevData[DevData['Utterance'].apply(lambda x: len(x.split()) > n)]\n",
    "\n",
    "Dropwords_TrainData.reset_index(drop=True, inplace=True)\n",
    "Dropwords_TestData.reset_index(drop=True, inplace=True)\n",
    "Dropwords_DevData.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(f\"After removing rows that is {n} words or below:\")\n",
    "print(f\"Train shape : {Dropwords_TrainData.shape}\")\n",
    "print(f\"Test shape: {Dropwords_TestData.shape}\")\n",
    "print(f\"Test shape: {Dropwords_DevData.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get random sample from train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>sound great</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7825</th>\n",
       "      <td>guy got anything eat went johnos chicken closed</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4314</th>\n",
       "      <td>take hand</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9026</th>\n",
       "      <td>something wrong</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>every year</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5576</th>\n",
       "      <td>definitely</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5739</th>\n",
       "      <td>really think room</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10360</th>\n",
       "      <td>true</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4190</th>\n",
       "      <td>double</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10498</th>\n",
       "      <td>yeah feel kinda responsible</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Utterance  Emotion\n",
       "766                                        sound great        6\n",
       "7825   guy got anything eat went johnos chicken closed        6\n",
       "4314                                         take hand        4\n",
       "9026                                   something wrong        4\n",
       "2007                                        every year        4\n",
       "5576                                        definitely        3\n",
       "5739                                 really think room        4\n",
       "10360                                             true        4\n",
       "4190                                            double        3\n",
       "10498                      yeah feel kinda responsible        0"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randomly select 10 rows\n",
    "random_sample = TrainData.sample(n=10)[[\"Utterance\", \"Emotion\"]]\n",
    "\n",
    "random_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1890</th>\n",
       "      <td>joke well think hef would disagree sent check ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2675</th>\n",
       "      <td>yeah</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2463</th>\n",
       "      <td>go chandler</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1278</th>\n",
       "      <td>love let tell friend</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1776</th>\n",
       "      <td>know face ross</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1772</th>\n",
       "      <td>know every year say gon na send holiday card n...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2453</th>\n",
       "      <td>yes saying actual word</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749</th>\n",
       "      <td>oh great joey want check picture mona ice skating</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3095</th>\n",
       "      <td>oh god saw oh</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>oh bad really bad thing burned as</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Utterance  Emotion\n",
       "1890  joke well think hef would disagree sent check ...        4\n",
       "2675                                               yeah        4\n",
       "2463                                        go chandler        4\n",
       "1278                               love let tell friend        3\n",
       "1776                                     know face ross        0\n",
       "1772  know every year say gon na send holiday card n...        4\n",
       "2453                             yes saying actual word        4\n",
       "1749  oh great joey want check picture mona ice skating        3\n",
       "3095                                      oh god saw oh        6\n",
       "89                    oh bad really bad thing burned as        5"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randomly select 10 rows\n",
    "random_sample = TestData.sample(n=10)[[\"Utterance\", \"Emotion\"]]\n",
    "\n",
    "random_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>yeah reason get big</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185</th>\n",
       "      <td>come taste bad</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>know knew probably give real name either</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>exactly looking hmm</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>hey mon</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>ok talking</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>musta read sonogram wrong</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>oh know know one joey got monica turkey stuck ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>idiot</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>leave</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Utterance  Emotion\n",
       "630                                 yeah reason get big        4\n",
       "1185                                     come taste bad        4\n",
       "1198           know knew probably give real name either        4\n",
       "43                                  exactly looking hmm        4\n",
       "703                                             hey mon        3\n",
       "474                                          ok talking        4\n",
       "173                           musta read sonogram wrong        6\n",
       "405   oh know know one joey got monica turkey stuck ...        3\n",
       "349                                               idiot        1\n",
       "300                                               leave        5"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randomly select 10 rows\n",
    "random_sample = DevData.sample(n=10)[[\"Utterance\", \"Emotion\"]]\n",
    "\n",
    "random_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>right definitely taste nutmeg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1427</th>\n",
       "      <td>well least hearing first time fifth grade hall...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4503</th>\n",
       "      <td>oh god really hope</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4562</th>\n",
       "      <td>oh please could</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5896</th>\n",
       "      <td>yeah okay scott</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>okay sir let see got right</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2409</th>\n",
       "      <td>musta sweeping found broom hand</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5482</th>\n",
       "      <td>little toast ding ding</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3792</th>\n",
       "      <td>taping people day</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6399</th>\n",
       "      <td>like bug bunny cartoon bug playing position ri...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Utterance  Emotion\n",
       "714                       right definitely taste nutmeg        4\n",
       "1427  well least hearing first time fifth grade hall...        1\n",
       "4503                                 oh god really hope        3\n",
       "4562                                    oh please could        4\n",
       "5896                                    yeah okay scott        4\n",
       "1294                         okay sir let see got right        4\n",
       "2409                    musta sweeping found broom hand        4\n",
       "5482                             little toast ding ding        3\n",
       "3792                                  taping people day        4\n",
       "6399  like bug bunny cartoon bug playing position ri...        3"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randomly select 10 rows\n",
    "random_sample = Dropwords_TrainData.sample(n=10)[[\"Utterance\", \"Emotion\"]]\n",
    "\n",
    "random_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1528</th>\n",
       "      <td>hi remember u</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>people people people</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>one hot chicky</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>know creep went date go find new one</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>think next patient far along</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1921</th>\n",
       "      <td>think hear sound</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1360</th>\n",
       "      <td>well old dog year think snoopy still allowed f...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>right look bottom line ross fixable act fast okay</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1363</th>\n",
       "      <td>oh sure need train somebody new</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1937</th>\n",
       "      <td>well anything copy going</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Utterance  Emotion\n",
       "1528                                      hi remember u        4\n",
       "928                                people people people        4\n",
       "340                                      one hot chicky        3\n",
       "784                know creep went date go find new one        1\n",
       "522                        think next patient far along        4\n",
       "1921                                   think hear sound        3\n",
       "1360  well old dog year think snoopy still allowed f...        5\n",
       "150   right look bottom line ross fixable act fast okay        4\n",
       "1363                    oh sure need train somebody new        3\n",
       "1937                           well anything copy going        4"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randomly select 10 rows\n",
    "random_sample = Dropwords_TestData.sample(n=10)[[\"Utterance\", \"Emotion\"]]\n",
    "\n",
    "random_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>heaven door sure pressing ear listening intently</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>good bone bruise right puncture wound ring</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>hey call get okay</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>oh hi max hey know everybody</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>jen know may sound uh would maybe wan na grab ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>go barn undress hold</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>joey talking terrific actor</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>know oh god genius</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>already baby leave alone</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>tell look adrienne baby gon na want meet</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Utterance  Emotion\n",
       "282   heaven door sure pressing ear listening intently        4\n",
       "710         good bone bruise right puncture wound ring        4\n",
       "339                                  hey call get okay        4\n",
       "628                       oh hi max hey know everybody        4\n",
       "343  jen know may sound uh would maybe wan na grab ...        4\n",
       "66                                go barn undress hold        4\n",
       "812                        joey talking terrific actor        4\n",
       "372                                 know oh god genius        3\n",
       "97                            already baby leave alone        0\n",
       "427           tell look adrienne baby gon na want meet        4"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randomly select 10 rows\n",
    "random_sample = Dropwords_DevData.sample(n=10)[[\"Utterance\", \"Emotion\"]]\n",
    "\n",
    "random_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Division of X and y data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame for target labels\n",
    "y_train = pd.DataFrame()\n",
    "y_test = pd.DataFrame()\n",
    "y_dev = pd.DataFrame()\n",
    "\n",
    "X_train = TrainData\n",
    "X_test = TestData\n",
    "X_dev = DevData\n",
    "    \n",
    "y_train[\"Emotion\"] = TrainData[\"Emotion\"].copy()\n",
    "y_test[\"Emotion\"] = TestData[\"Emotion\"].copy()\n",
    "y_dev[\"Emotion\"] = DevData[\"Emotion\"].copy()\n",
    "\n",
    "y_train[\"Dialogue_ID\"] = TrainData[\"Dialogue_ID\"].copy()\n",
    "y_test[\"Dialogue_ID\"] = TestData[\"Dialogue_ID\"].copy()\n",
    "y_dev[\"Dialogue_ID\"] = DevData[\"Dialogue_ID\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (12176, 12)\n",
      "Shape of y_train: (12176, 2)\n",
      "--\n",
      "Shape of X_test: (3230, 12)\n",
      "Shape of y_test: (3230, 2)\n",
      "--\n",
      "Shape of X_dev: (1373, 12)\n",
      "Shape of y_dev: (1373, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f'Shape of X_train: {X_train.shape}')\n",
    "print(f'Shape of y_train: {y_train.shape}')\n",
    "print('--')\n",
    "print(f'Shape of X_test: {X_test.shape}')\n",
    "print(f'Shape of y_test: {y_test.shape}')\n",
    "print('--')\n",
    "print(f'Shape of X_dev: {X_dev.shape}')\n",
    "print(f'Shape of y_dev: {y_dev.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame for target labels\n",
    "y_dropped_train = pd.DataFrame()\n",
    "y_dropped_test = pd.DataFrame()\n",
    "y_dropped_dev = pd.DataFrame()\n",
    "\n",
    "X_dropped_train = Dropwords_TrainData\n",
    "X_dropped_test = Dropwords_TestData\n",
    "X_dropped_dev = Dropwords_DevData\n",
    "\n",
    "y_dropped_train[\"Emotion\"] = Dropwords_TrainData[\"Emotion\"].copy()\n",
    "y_dropped_test[\"Emotion\"] = Dropwords_TestData[\"Emotion\"].copy()\n",
    "y_dropped_dev[\"Emotion\"] = Dropwords_DevData[\"Emotion\"].copy()\n",
    "\n",
    "y_dropped_train[\"Dialogue_ID\"] = Dropwords_TrainData[\"Dialogue_ID\"].copy()\n",
    "y_dropped_test[\"Dialogue_ID\"] = Dropwords_TestData[\"Dialogue_ID\"].copy()\n",
    "y_dropped_dev[\"Dialogue_ID\"] = Dropwords_DevData[\"Dialogue_ID\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_dropped_train: (7354, 12)\n",
      "Shape of y_dropped_train: (7354, 2)\n",
      "--\n",
      "Shape of X_dropped_test: (1973, 12)\n",
      "Shape of y_dropped_test: (1973, 2)\n",
      "--\n",
      "Shape of X_dropped_dev: (858, 12)\n",
      "Shape of y_dropped_dev: (858, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f'Shape of X_dropped_train: {X_dropped_train.shape}')\n",
    "print(f'Shape of y_dropped_train: {y_dropped_train.shape}')\n",
    "print('--')\n",
    "print(f'Shape of X_dropped_test: {X_dropped_test.shape}')\n",
    "print(f'Shape of y_dropped_test: {y_dropped_test.shape}')\n",
    "print('--')\n",
    "print(f'Shape of X_dropped_dev: {X_dropped_dev.shape}')\n",
    "print(f'Shape of y_dropped_dev: {y_dropped_dev.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output data to new csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Label Encoding Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the file already exists\n",
    "checkFile1 = os.path.isfile(\"data/dump/\" + dataset_path + \"/labels_train.pkl\")\n",
    "checkFile2 = os.path.isfile(\"data/dump/\" + dataset_path + \"/labels_test.pkl\")\n",
    "\n",
    "if key:\n",
    "    pickle.dump(X_train[\"Emotion\"], open('data/dump/' + dataset_path + '/labels_train.pkl', 'wb'))\n",
    "    pickle.dump(X_test[\"Emotion\"], open('data/dump/' + dataset_path + '/labels_test.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training and Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exportDataToCSV(df, name):\n",
    "    path = \"data/\" + dataset_path + \"/\" + name + \".csv\"\n",
    "    df.to_csv(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "exportDataToCSV(X_train, \"train_sent_emo_dya\")\n",
    "exportDataToCSV(y_train, \"y_train\")\n",
    "\n",
    "exportDataToCSV(X_test, \"test_sent_emo_dya\")\n",
    "exportDataToCSV(y_test, \"y_test\")\n",
    "\n",
    "exportDataToCSV(X_dev, \"dev_sent_emo_dya\")\n",
    "exportDataToCSV(y_dev, \"y_dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exportDataToCSV(X_dropped_train, \"dropwords_X_train\")\n",
    "# exportDataToCSV(y_dropped_train, \"dropwords_y_train\")\n",
    "\n",
    "# exportDataToCSV(X_dropped_test, \"dropwords_X_test\")\n",
    "# exportDataToCSV(y_dropped_test, \"dropwords_y_test\")\n",
    "\n",
    "# exportDataToCSV(X_dropped_dev, \"dropwords_X_dev\")\n",
    "# exportDataToCSV(y_dropped_dev, \"dropwords_y_dev\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
