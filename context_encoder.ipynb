{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b63fd00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os, re, time, pickle, collections, importlib, datetime, torch\n",
    "import pandas as pd, numpy as np, pickle\n",
    "from chardet import detect\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from collections import defaultdict, Counter\n",
    "from wordebd import WORDEBD\n",
    "from vocab import Vocab, Vectors\n",
    "from munch import Munch\n",
    "from cnnlstmseq import CNNLSTMseq\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8e3efa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoding_type(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        rawdata = f.read(),\n",
    "    return detect(rawdata['encoding'])\n",
    "\n",
    "def detect_misspelling(source):\n",
    "    pass\n",
    "def replace_spelling(source):\n",
    "    return re.sub(\"Åf\", \"'\", source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b9072d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# referenced from DialogueGCN, mastodon code\n",
    "def preprocess_text(x):\n",
    "    for punct in '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~\\'':\n",
    "        x = x.replace(punct, ' ')\n",
    "    x = ' '.join(x.split())\n",
    "    x = x.lower()\n",
    "\n",
    "    return x\n",
    "\n",
    "def load_pretrained_glove():\n",
    "    print(\"Loading GloVe...\")\n",
    "    glv_vector = {}\n",
    "    f = open('/embed/glove/glove.840B.300d.txt', encoding='utf-8')\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word, coefs = values[0], np.asarray(values[1:], dtype='float')\n",
    "        try:\n",
    "            glv_vector[word] = coefs\n",
    "\n",
    "        except ValueError:\n",
    "            continue\n",
    "    f.close()\n",
    "    start_time = time.time()\n",
    "    print(f\"Took {time.time() - start_time} seconds to load pretrained GloVe model.\")\n",
    "    return glv_vector\n",
    "\n",
    "\n",
    "def encode_labels(encoder, l):\n",
    "    return encoder[l]\n",
    "\n",
    "def load_data_from_npy(file_path):\n",
    "    try:\n",
    "        data = np.load(file_path, allow_pickle=True)\n",
    "        if isinstance(data, np.ndarray):\n",
    "            if data.ndim == 2:\n",
    "                return pd.DataFrame(data)\n",
    "            else:\n",
    "                raise ValueError(\"The loaded array is not two-dimensional.\")\n",
    "        else:\n",
    "            raise TypeError(\"The loaded object is not a NumPy array.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {file_path}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error: An exception occurred - {str(e)}\")\n",
    "        return None\n",
    "    \n",
    "# def sentence_embedding(sentence, embeddings):\n",
    "#     words = sentence.split()\n",
    "#     vectors = [embeddings.get(word, np.zeros(300)) for word in words]\n",
    "#     mean_vector = np.mean(vectors, axis=0)\n",
    "#     return mean_vector\n",
    "\n",
    "def _read_words(data, convmode=None):\n",
    "    '''    \n",
    "        Count the occurrences of all words\n",
    "        @param convmode: str, None for non conversational scope, 'naive' for classic or naive approach, 'conv' for conversation depth into account (one additional dim and nested values)\n",
    "        @param data: list of examples\n",
    "        @return words: list of words (with duplicates)\n",
    "    '''    \n",
    "    words = []\n",
    "    if convmode is None:\n",
    "        for example in data:\n",
    "            words += example.split()     \n",
    "    return words\n",
    "\n",
    "def _data_to_nparray(data, vocab, args):\n",
    "    '''\n",
    "        Convert the data into a dictionary of np arrays for speed.\n",
    "    '''\n",
    "    raw = np.array([e for e in data[\"Utterance\"]], dtype=object)\n",
    "    doc_label = np.array([x for x in data[\"Emotion\"]], dtype=np.int64)\n",
    "\n",
    "    # compute the max text length\n",
    "    text_len = np.array([len(e) for e in data[\"Utterance\"]])\n",
    "    max_text_len = max(text_len)\n",
    "    ids = np.array([e for e in data['Dialogue_ID']])\n",
    "    ids2 = np.array([e for e in data['Utterance_ID']])\n",
    "\n",
    "    # initialize the big numpy array by <pad>\n",
    "    text = vocab.stoi['<pad>'] * np.ones([len(data), max_text_len],\n",
    "                                     dtype=np.int64)\n",
    "\n",
    "    del_idx = []\n",
    "    # convert each token to its corresponding id\n",
    "    for i in range(len(X_train)):\n",
    "        text[i, :len(X_train['Utterance'][i])] = [vocab.stoi[x] if x in vocab.stoi else vocab.stoi['<unk>']\n",
    "                for x in X_train['Utterance'][i]]\n",
    "\n",
    "        # filter out document with only unk and pad\n",
    "        if np.max(text[i]) < 2:\n",
    "            del_idx.append(i)\n",
    "\n",
    "    vocab_size = vocab.vectors.size()[0]\n",
    "\n",
    "\n",
    "    ## Curation for padding (string instead of list of list)\n",
    "    raw = [ [\"<pad>\" if m == [\"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\"] else m for m in c ] for c in raw ]\n",
    "\n",
    "    ids, ids2, text_len, text, doc_label, raw = _del_by_idx( [ids, ids2, text_len, text, doc_label, raw], del_idx, 0)\n",
    "    new_data = {\n",
    "        'ids': ids,\n",
    "        'ids2': ids2,\n",
    "        'text': text,\n",
    "        'text_len': text_len,\n",
    "        'label': doc_label,\n",
    "#         'raw': raw,\n",
    "        'vocab_size': vocab_size,\n",
    "    }\n",
    "\n",
    "    return new_data\n",
    "\n",
    "def _del_by_idx(array_list, idx, axis):\n",
    "\n",
    "    '''        \n",
    "        Delete the specified index for each array in the array_lists\",\n",
    "\n",
    "        @params: array_list: list of np arrays\n",
    "        @params: idx: list of int\n",
    "        @params: axis: int\n",
    "\n",
    "        @return: res: tuple of pruned np arrays\n",
    "    '''\n",
    "    if type(array_list) is not list:\n",
    "        array_list = [array_list]\n",
    "\n",
    "    # modified to perform operations in place\n",
    "    for i, array in enumerate(array_list):\n",
    "        array_list[i] = np.delete(array, idx, axis)\n",
    "\n",
    "    if len(array_list) == 1:\n",
    "        return array_list[0]\n",
    "    else:\n",
    "        return array_list\n",
    "\n",
    "def find_value_ranges(lst):\n",
    "    value_ranges = []\n",
    "    start_index = 0\n",
    "\n",
    "    for i in range(1, len(lst)):\n",
    "        if lst[i] != lst[i - 1]:\n",
    "            value_ranges.append((start_index, i - 1))\n",
    "            start_index = i\n",
    "\n",
    "    # Add the last range\n",
    "    value_ranges.append((start_index, len(lst) - 1))\n",
    "\n",
    "    return value_ranges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94282feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.git',\n",
       " '.gitignore',\n",
       " '.idea',\n",
       " '.ipynb_checkpoints',\n",
       " 'cnnlstmseq.py',\n",
       " 'context_encoder.ipynb',\n",
       " 'data',\n",
       " 'embed',\n",
       " 'emotionClassifier.ipynb',\n",
       " 'emotion_classifier.py',\n",
       " 'GAT.py',\n",
       " 'LICENSE',\n",
       " 'models',\n",
       " 'README.md',\n",
       " 'relationtype_encoder.ipynb',\n",
       " 'runs',\n",
       " 'utils',\n",
       " 'vocab.py',\n",
       " 'wordebd.py',\n",
       " '__pycache__']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7147d96d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Dialogue_ID</th>\n",
       "      <th>Utterance_ID</th>\n",
       "      <th>Old_Dialogue_ID</th>\n",
       "      <th>Old_Utterance_ID</th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode</th>\n",
       "      <th>StartTime</th>\n",
       "      <th>EndTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>also I was the point person on my companyÅfs t...</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>00:16:16,059</td>\n",
       "      <td>00:16:21,731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You mustÅfve had your hands full.</td>\n",
       "      <td>The Interviewer</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>00:16:21,940</td>\n",
       "      <td>00:16:23,442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>That I did. That I did.</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>00:16:23,442</td>\n",
       "      <td>00:16:26,389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Utterance          Speaker  \\\n",
       "0  also I was the point person on my companyÅfs t...         Chandler   \n",
       "1                  You mustÅfve had your hands full.  The Interviewer   \n",
       "2                            That I did. That I did.         Chandler   \n",
       "\n",
       "   Emotion Sentiment  Dialogue_ID  Utterance_ID  Old_Dialogue_ID  \\\n",
       "0  neutral   neutral            0             0                0   \n",
       "1  neutral   neutral            0             1                0   \n",
       "2  neutral   neutral            0             2                0   \n",
       "\n",
       "   Old_Utterance_ID  Season  Episode     StartTime       EndTime  \n",
       "0                 0       8       21  00:16:16,059  00:16:21,731  \n",
       "1                 1       8       21  00:16:21,940  00:16:23,442  \n",
       "2                 2       8       21  00:16:23,442  00:16:26,389  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pd.read_csv('data/train_sent_emo_dya.csv', encoding='MacRoman')\n",
    "X_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4a470f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Dialogue_ID</th>\n",
       "      <th>Utterance_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>also I was the point person on my companyÅfs t...</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You mustÅfve had your hands full.</td>\n",
       "      <td>The Interviewer</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>That I did. That I did.</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Utterance          Speaker  \\\n",
       "0  also I was the point person on my companyÅfs t...         Chandler   \n",
       "1                  You mustÅfve had your hands full.  The Interviewer   \n",
       "2                            That I did. That I did.         Chandler   \n",
       "\n",
       "   Emotion Sentiment  Dialogue_ID  Utterance_ID  \n",
       "0  neutral   neutral            0             0  \n",
       "1  neutral   neutral            0             1  \n",
       "2  neutral   neutral            0             2  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_features = list(X_train.keys()[6:])\n",
    "# drop_features.append(\"Emotion\")\n",
    "drop_features\n",
    "y_train = pd.DataFrame()\n",
    "y_train[\"Emotion\"] = X_train[\"Emotion\"].copy()\n",
    "y_train[\"Dialogue_ID\"] = X_train[\"Dialogue_ID\"].copy()\n",
    "X_train = X_train.drop(drop_features, axis=1)\n",
    "X_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd8ac980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Dialogue_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Emotion  Dialogue_ID\n",
       "0  neutral            0\n",
       "1  neutral            0\n",
       "2  neutral            0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1381d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Dialogue_ID</th>\n",
       "      <th>Utterance_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>also I was the point person on my company's tr...</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You must've had your hands full.</td>\n",
       "      <td>The Interviewer</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>That I did. That I did.</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>So let's talk a little bit about your duties.</td>\n",
       "      <td>The Interviewer</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My duties?  All right.</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>surprise</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Now you'll be heading a whole division, so you...</td>\n",
       "      <td>The Interviewer</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I see.</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>But there'll be perhaps 30 people under you so...</td>\n",
       "      <td>The Interviewer</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Good to know.</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>We can go into detail</td>\n",
       "      <td>The Interviewer</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>No don't I beg of you!</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>fear</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>All right then, we'll have a definite answer f...</td>\n",
       "      <td>The Interviewer</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Really?!</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>surprise</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Absolutely.  You can relax</td>\n",
       "      <td>The Interviewer</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Utterance          Speaker  \\\n",
       "0   also I was the point person on my company's tr...         Chandler   \n",
       "1                    You must've had your hands full.  The Interviewer   \n",
       "2                             That I did. That I did.         Chandler   \n",
       "3       So let's talk a little bit about your duties.  The Interviewer   \n",
       "4                              My duties?  All right.         Chandler   \n",
       "5   Now you'll be heading a whole division, so you...  The Interviewer   \n",
       "6                                              I see.         Chandler   \n",
       "7   But there'll be perhaps 30 people under you so...  The Interviewer   \n",
       "8                                       Good to know.         Chandler   \n",
       "9                               We can go into detail  The Interviewer   \n",
       "10                             No don't I beg of you!         Chandler   \n",
       "11  All right then, we'll have a definite answer f...  The Interviewer   \n",
       "12                                           Really?!         Chandler   \n",
       "13                         Absolutely.  You can relax  The Interviewer   \n",
       "\n",
       "     Emotion Sentiment  Dialogue_ID  Utterance_ID  \n",
       "0    neutral   neutral            0             0  \n",
       "1    neutral   neutral            0             1  \n",
       "2    neutral   neutral            0             2  \n",
       "3    neutral   neutral            0             3  \n",
       "4   surprise  positive            0             4  \n",
       "5    neutral   neutral            0             5  \n",
       "6    neutral   neutral            0             6  \n",
       "7    neutral   neutral            0             7  \n",
       "8    neutral   neutral            0             8  \n",
       "9    neutral   neutral            0             9  \n",
       "10      fear  negative            0            10  \n",
       "11   neutral   neutral            0            11  \n",
       "12  surprise  positive            0            12  \n",
       "13   neutral   neutral            0            13  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[\"Utterance\"] = X_train[\"Utterance\"].apply(lambda x: replace_spelling(x))\n",
    "X_train[:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ab33f245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Dialogue_ID</th>\n",
       "      <th>Utterance_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Hey-hey-hey. You wanna hear something that sucks.</td>\n",
       "      <td>Monica</td>\n",
       "      <td>5</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Do I ever.</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Chris says they're closing down the bar.</td>\n",
       "      <td>Monica</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>No way!</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>6</td>\n",
       "      <td>negative</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Yeah, apparently they're turning it into some ...</td>\n",
       "      <td>Monica</td>\n",
       "      <td>5</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Just coffee! Where are we gonna hang out now?</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>3</td>\n",
       "      <td>negative</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Got me.</td>\n",
       "      <td>Monica</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Can I get a beer.</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>5</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Hey, did you pick a roommate?</td>\n",
       "      <td>Monica</td>\n",
       "      <td>5</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>You betcha!</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Is it the Italian guy?</td>\n",
       "      <td>Monica</td>\n",
       "      <td>5</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Um-mm, yeah right!</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Oh my God, oh my God! Poor Monica!</td>\n",
       "      <td>Phoebe</td>\n",
       "      <td>6</td>\n",
       "      <td>negative</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>What, what, what?!</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>6</td>\n",
       "      <td>negative</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>What?!</td>\n",
       "      <td>Phoebe</td>\n",
       "      <td>6</td>\n",
       "      <td>negative</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>He was with her when he wrote this poem.</td>\n",
       "      <td>Phoebe</td>\n",
       "      <td>5</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Look,  'My vessel so empty with nothing inside.</td>\n",
       "      <td>Phoebe</td>\n",
       "      <td>5</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Now that I've touched you, you seem emptier st...</td>\n",
       "      <td>Phoebe</td>\n",
       "      <td>5</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>He thinks Monica is empty, she is the empty vase!</td>\n",
       "      <td>Phoebe</td>\n",
       "      <td>6</td>\n",
       "      <td>negative</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Oh, totally. Oh, God, oh, she seemed so happy ...</td>\n",
       "      <td>Phoebe</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>What?!</td>\n",
       "      <td>Phoebe</td>\n",
       "      <td>6</td>\n",
       "      <td>negative</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>He was with her when he wrote this poem.</td>\n",
       "      <td>Phoebe</td>\n",
       "      <td>5</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Look,  'My vessel so empty with nothing inside.</td>\n",
       "      <td>Phoebe</td>\n",
       "      <td>5</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Now that I've touched you, you seem emptier st...</td>\n",
       "      <td>Phoebe</td>\n",
       "      <td>5</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>He thinks Monica is empty, she is the empty vase!</td>\n",
       "      <td>Phoebe</td>\n",
       "      <td>6</td>\n",
       "      <td>negative</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Oh, totally. Oh, God, oh, she seemed so happy ...</td>\n",
       "      <td>Phoebe</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Done.</td>\n",
       "      <td>Joey</td>\n",
       "      <td>5</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Hey!</td>\n",
       "      <td>Rachel</td>\n",
       "      <td>6</td>\n",
       "      <td>positive</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Hi!</td>\n",
       "      <td>Ross</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>What are you doing here?</td>\n",
       "      <td>Rachel</td>\n",
       "      <td>6</td>\n",
       "      <td>positive</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Ah y'know, this building is on my paper route ...</td>\n",
       "      <td>Ross</td>\n",
       "      <td>5</td>\n",
       "      <td>neutral</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Oh.</td>\n",
       "      <td>Rachel</td>\n",
       "      <td>5</td>\n",
       "      <td>neutral</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Ross</td>\n",
       "      <td>5</td>\n",
       "      <td>neutral</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Rachel</td>\n",
       "      <td>5</td>\n",
       "      <td>neutral</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>How'd did it go?</td>\n",
       "      <td>Ross</td>\n",
       "      <td>5</td>\n",
       "      <td>neutral</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Oh well, the woman I interviewed with was pret...</td>\n",
       "      <td>Rachel</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>I'm so proud of you.</td>\n",
       "      <td>Ross</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Me too!</td>\n",
       "      <td>Rachel</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Listen, I'm ah, I'm sorry I've been so crazy a...</td>\n",
       "      <td>Ross</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>I know.</td>\n",
       "      <td>Rachel</td>\n",
       "      <td>5</td>\n",
       "      <td>neutral</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Yeah.</td>\n",
       "      <td>Ross</td>\n",
       "      <td>5</td>\n",
       "      <td>neutral</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Yeah.</td>\n",
       "      <td>Rachel</td>\n",
       "      <td>5</td>\n",
       "      <td>neutral</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Ameri-can.</td>\n",
       "      <td>Phoebe</td>\n",
       "      <td>5</td>\n",
       "      <td>neutral</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Ameri-ccan.</td>\n",
       "      <td>Joey</td>\n",
       "      <td>5</td>\n",
       "      <td>neutral</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Ameri-can. Y'know it's a</td>\n",
       "      <td>Phoebe</td>\n",
       "      <td>5</td>\n",
       "      <td>neutral</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Ameri-can. Y'know it's a</td>\n",
       "      <td>Phoebe</td>\n",
       "      <td>5</td>\n",
       "      <td>neutral</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Everybody!!</td>\n",
       "      <td>Sergei</td>\n",
       "      <td>6</td>\n",
       "      <td>positive</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Good job Joe! Well done! Top notch!</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>You liked it? You really liked it?</td>\n",
       "      <td>Joey</td>\n",
       "      <td>6</td>\n",
       "      <td>positive</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Oh-ho-ho, yeah!</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Which part exactly?</td>\n",
       "      <td>Joey</td>\n",
       "      <td>5</td>\n",
       "      <td>neutral</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>The whole thing! Can we go?</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>5</td>\n",
       "      <td>neutral</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Oh no-no-no, give me some specifics.</td>\n",
       "      <td>Joey</td>\n",
       "      <td>4</td>\n",
       "      <td>negative</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>I love the specifics, the specifics were the b...</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Hey, what about the scene with the kangaroo? D...</td>\n",
       "      <td>Joey</td>\n",
       "      <td>5</td>\n",
       "      <td>neutral</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>I was surprised to see a kangaroo in a World W...</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>6</td>\n",
       "      <td>negative</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>You fell asleep!!</td>\n",
       "      <td>Joey</td>\n",
       "      <td>4</td>\n",
       "      <td>negative</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>There was no kangaroo!</td>\n",
       "      <td>Joey</td>\n",
       "      <td>4</td>\n",
       "      <td>negative</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>They didn't take any of my suggestions!</td>\n",
       "      <td>Joey</td>\n",
       "      <td>4</td>\n",
       "      <td>negative</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>That's for coming buddy.</td>\n",
       "      <td>Joey</td>\n",
       "      <td>5</td>\n",
       "      <td>neutral</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Utterance   Speaker  Emotion  \\\n",
       "22  Hey-hey-hey. You wanna hear something that sucks.    Monica        5   \n",
       "23                                         Do I ever.  Chandler        1   \n",
       "24           Chris says they're closing down the bar.    Monica        0   \n",
       "25                                            No way!  Chandler        6   \n",
       "26  Yeah, apparently they're turning it into some ...    Monica        5   \n",
       "27      Just coffee! Where are we gonna hang out now?  Chandler        3   \n",
       "28                                            Got me.    Monica        0   \n",
       "29                                  Can I get a beer.  Chandler        5   \n",
       "30                      Hey, did you pick a roommate?    Monica        5   \n",
       "31                                        You betcha!  Chandler        1   \n",
       "32                             Is it the Italian guy?    Monica        5   \n",
       "33                                 Um-mm, yeah right!  Chandler        1   \n",
       "34                 Oh my God, oh my God! Poor Monica!    Phoebe        6   \n",
       "35                                 What, what, what?!  Chandler        6   \n",
       "36                                             What?!    Phoebe        6   \n",
       "37           He was with her when he wrote this poem.    Phoebe        5   \n",
       "38    Look,  'My vessel so empty with nothing inside.    Phoebe        5   \n",
       "39  Now that I've touched you, you seem emptier st...    Phoebe        5   \n",
       "40  He thinks Monica is empty, she is the empty vase!    Phoebe        6   \n",
       "41  Oh, totally. Oh, God, oh, she seemed so happy ...    Phoebe        0   \n",
       "42                                             What?!    Phoebe        6   \n",
       "43           He was with her when he wrote this poem.    Phoebe        5   \n",
       "44    Look,  'My vessel so empty with nothing inside.    Phoebe        5   \n",
       "45  Now that I've touched you, you seem emptier st...    Phoebe        5   \n",
       "46  He thinks Monica is empty, she is the empty vase!    Phoebe        6   \n",
       "47  Oh, totally. Oh, God, oh, she seemed so happy ...    Phoebe        0   \n",
       "48                                              Done.      Joey        5   \n",
       "49                                               Hey!    Rachel        6   \n",
       "50                                                Hi!      Ross        1   \n",
       "51                           What are you doing here?    Rachel        6   \n",
       "52  Ah y'know, this building is on my paper route ...      Ross        5   \n",
       "53                                                Oh.    Rachel        5   \n",
       "54                                                Hi.      Ross        5   \n",
       "55                                                Hi.    Rachel        5   \n",
       "56                                   How'd did it go?      Ross        5   \n",
       "57  Oh well, the woman I interviewed with was pret...    Rachel        1   \n",
       "58                               I'm so proud of you.      Ross        1   \n",
       "59                                            Me too!    Rachel        1   \n",
       "60  Listen, I'm ah, I'm sorry I've been so crazy a...      Ross        0   \n",
       "61                                            I know.    Rachel        5   \n",
       "62                                              Yeah.      Ross        5   \n",
       "63                                              Yeah.    Rachel        5   \n",
       "64                                         Ameri-can.    Phoebe        5   \n",
       "65                                        Ameri-ccan.      Joey        5   \n",
       "66                           Ameri-can. Y'know it's a    Phoebe        5   \n",
       "67                           Ameri-can. Y'know it's a    Phoebe        5   \n",
       "68                                        Everybody!!    Sergei        6   \n",
       "69                Good job Joe! Well done! Top notch!  Chandler        1   \n",
       "70                 You liked it? You really liked it?      Joey        6   \n",
       "71                                    Oh-ho-ho, yeah!  Chandler        1   \n",
       "72                                Which part exactly?      Joey        5   \n",
       "73                        The whole thing! Can we go?  Chandler        5   \n",
       "74               Oh no-no-no, give me some specifics.      Joey        4   \n",
       "75  I love the specifics, the specifics were the b...  Chandler        1   \n",
       "76  Hey, what about the scene with the kangaroo? D...      Joey        5   \n",
       "77  I was surprised to see a kangaroo in a World W...  Chandler        6   \n",
       "78                                  You fell asleep!!      Joey        4   \n",
       "79                             There was no kangaroo!      Joey        4   \n",
       "80            They didn't take any of my suggestions!      Joey        4   \n",
       "81                           That's for coming buddy.      Joey        5   \n",
       "\n",
       "   Sentiment  Dialogue_ID  Utterance_ID  \n",
       "22   neutral            2             1  \n",
       "23  positive            2             2  \n",
       "24  negative            2             3  \n",
       "25  negative            2             4  \n",
       "26   neutral            2             5  \n",
       "27  negative            2             6  \n",
       "28  negative            2             7  \n",
       "29   neutral            2             8  \n",
       "30   neutral            2             9  \n",
       "31  positive            2            10  \n",
       "32   neutral            2            11  \n",
       "33  positive            2            12  \n",
       "34  negative            3             0  \n",
       "35  negative            3             1  \n",
       "36  negative            3             2  \n",
       "37   neutral            3             3  \n",
       "38   neutral            3             4  \n",
       "39   neutral            3             5  \n",
       "40  negative            3             6  \n",
       "41  negative            3             7  \n",
       "42  negative            4             0  \n",
       "43   neutral            4             1  \n",
       "44   neutral            4             2  \n",
       "45   neutral            4             3  \n",
       "46  negative            4             4  \n",
       "47  negative            4             5  \n",
       "48   neutral            4             6  \n",
       "49  positive            5             0  \n",
       "50  positive            5             1  \n",
       "51  positive            5             2  \n",
       "52   neutral            5             3  \n",
       "53   neutral            5             4  \n",
       "54   neutral            5             5  \n",
       "55   neutral            5             6  \n",
       "56   neutral            5             7  \n",
       "57  positive            5             8  \n",
       "58  positive            5             9  \n",
       "59  positive            5            10  \n",
       "60  negative            5            11  \n",
       "61   neutral            5            12  \n",
       "62   neutral            5            13  \n",
       "63   neutral            5            14  \n",
       "64   neutral            6             0  \n",
       "65   neutral            6             1  \n",
       "66   neutral            6             2  \n",
       "67   neutral            7             0  \n",
       "68  positive            7             1  \n",
       "69  positive            8             0  \n",
       "70  positive            8             1  \n",
       "71  positive            8             2  \n",
       "72   neutral            8             3  \n",
       "73   neutral            8             4  \n",
       "74  negative            8             5  \n",
       "75  positive            8             6  \n",
       "76   neutral            8             7  \n",
       "77  negative            8             8  \n",
       "78  negative            8             9  \n",
       "79  negative            8            10  \n",
       "80  negative            8            11  \n",
       "81   neutral            8            12  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[22:82]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e90851d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkFile1 = os.path.isfile(\"data/dump/label_encoder.pkl\")\n",
    "checkFile2 = os.path.isfile(\"data/dump/label_decoder.pkl\")\n",
    "\n",
    "if checkFile1 or checkFile2 is False:\n",
    "    labels = set(y_train.Emotion)\n",
    "    label_encoder = {label: i for i, label in enumerate(labels)}\n",
    "    label_decoder = {i: label for i, label in enumerate(labels)}\n",
    "\n",
    "    pickle.dump(label_encoder, open('data/dump/label_encoder.pkl', 'wb'))\n",
    "    pickle.dump(label_decoder, open('data/dump/label_decoder.pkl', 'wb'))\n",
    "    \n",
    "else:\n",
    "    file1 = open('data/dump/label_encoder.pkl', 'rb')\n",
    "    file2 = open('data/dump/label_decoder.pkl', 'rb')\n",
    "    label_encoder = pickle.load(file1)\n",
    "    label_decoder = pickle.load(file2)\n",
    "    file1.close()\n",
    "    file2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0503247d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[\"Emotion\"] = y_train[\"Emotion\"].apply(lambda x: encode_labels(label_encoder, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "03d0ac1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Dialogue_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Emotion  Dialogue_ID\n",
       "0         5            0\n",
       "1         5            0\n",
       "2         5            0\n",
       "3         5            0\n",
       "4         6            0\n",
       "5         5            0\n",
       "6         5            0\n",
       "7         5            0\n",
       "8         5            0\n",
       "9         5            0\n",
       "10        2            0\n",
       "11        5            0\n",
       "12        6            0\n",
       "13        5            0\n",
       "14        6            1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2df87a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"Emotion\"] = y_train[\"Emotion\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e1cc4d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save the data in pickle format ##\n",
    "checkFile = os.path.isfile(\"data/dump/train_labels.pkl\")\n",
    "if checkFile is False:\n",
    "    X_train[\"Emotion\"]\n",
    "\n",
    "    pickle.dump(X_train[\"Emotion\"],\n",
    "                open('data/dump/train_labels.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8f38cf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkFile = os.path.isfile(\"data/dump/dialog_ids.pkl\")\n",
    "# if checkFile is False:\n",
    "#     dialogSpeakers, dialogInputSeq, dialogInputMaxSeqLen, dialogLabels = {}, {}, {}, {}\n",
    "#     X_train_dialog_ids = set(X_train.Dialogue_ID)\n",
    "#     all_data = X_train.copy()\n",
    "#     # all_data = X_train.append(X_test, ignore_index=True).append(X_valid, ignore_index=True)\n",
    "\n",
    "#     for item in list(X_train_dialog_ids):\n",
    "#         X_df = all_data[all_data.Dialogue_ID == item]\n",
    "#         y_df = y_train[y_train[\"Dialogue_ID\"] == item] \n",
    "\n",
    "#         dialogSpeakers[item] = list(X_df.Speaker)\n",
    "#         dialogInputSeq[item] = list(X_df.sequence)\n",
    "#         dialogInputMaxSeqLen[item] = max(list(X_df.sentence_length))\n",
    "#         dialogLabels[item] = list(y_df.Emotion)\n",
    "\n",
    "#     pickle.dump([dialogSpeakers, dialogInputSeq, dialogInputMaxSeqLen, dialogLabels, X_train_dialog_ids],\n",
    "#                 open('data/dump/per_dialog_ids.pkl', 'wb'))\n",
    "# else:\n",
    "#     file = open('data/dump/per_dialog_ids.pkl', \"rb\")\n",
    "#     dialogSpeakers, dialogInputSeq, dialogInputMaxSeqLen, dialogLabels, X_train_dialog_ids = pickle.load(file)\n",
    "#     file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f71baeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## tokenize all sentences ##\n",
    "# checkFile = os.path.isfile(\"data/dump/tokenizer.pkl\")\n",
    "\n",
    "# if checkFile is False:\n",
    "#     all_text = list(X_train.Utterance)\n",
    "#     tokenizer = Tokenizer()\n",
    "#     tokenizer.fit_on_texts(all_text)\n",
    "#     pickle.dump(tokenizer, open('data/dump/tokenizer.pkl', 'wb'))\n",
    "# else:\n",
    "#     file = open('data/dump/tokenizer.pkl', 'rb')\n",
    "#     tokenizer = pickle.load(file)\n",
    "#     file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "96268d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## convert the sentences into sequences ## \n",
    "# train_sequence = tokenizer.texts_to_sequences(list(X_train.Utterance)) \n",
    "# X_train['sentence_length'] = [len(item) for item in train_sequence] \n",
    " \n",
    "# max_num_tokens = 250 \n",
    "\n",
    "# train_sequence = pad_sequences(train_sequence, maxlen=max_num_tokens, padding='post') \n",
    " \n",
    "# X_train['sequence'] = list(train_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cad434c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.word_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169ca725",
   "metadata": {},
   "source": [
    "Idk why glove embeddings and toknizers were used in the orig source code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2911056b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## save the data in pickle format ##\n",
    "# checkFile = os.path.isfile(\"data/dump/per_dialog_ids.pkl\")\n",
    "# if checkFile is False:\n",
    "#     dialogSpeakers, dialogInputSeq, dialogInputMaxSeqLen, dialogLabels = {}, {}, {}, {}\n",
    "#     X_train_dialog_ids = set(X_train.Dialogue_ID)\n",
    "#     all_data = X_train.copy()\n",
    "#     # all_data = X_train.append(X_test, ignore_index=True).append(X_valid, ignore_index=True)\n",
    "\n",
    "#     for item in list(X_train_dialog_ids):\n",
    "#         X_df = all_data[all_data.Dialogue_ID == item]\n",
    "#         y_df = y_train[y_train[\"Dialogue_ID\"] == item] \n",
    "\n",
    "#         dialogSpeakers[item] = list(X_df.Speaker)\n",
    "#         dialogInputSeq[item] = list(X_df.sequence)\n",
    "#         dialogInputMaxSeqLen[item] = max(list(X_df.sentence_length))\n",
    "#         dialogLabels[item] = list(y_df.Emotion)\n",
    "\n",
    "#     pickle.dump([dialogSpeakers, dialogInputSeq, dialogInputMaxSeqLen, dialogLabels, X_train_dialog_ids],\n",
    "#                 open('data/dump/per_dialog_ids.pkl', 'wb'))\n",
    "# else:\n",
    "#     file = open('data/dump/per_dialog_ids.pkl', \"rb\")\n",
    "#     dialogSpeakers, dialogInputSeq, dialogInputMaxSeqLen, dialogLabels, X_train_dialog_ids = pickle.load(file)\n",
    "#     file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3849c0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save pretrained embedding matrix ## \n",
    "# file = open('data/dump/glv_embedding_matrix.npy', \"rb\") \n",
    "# if file is None: \n",
    "#     glv_vector = load_pretrained_glove() \n",
    "#     word_vector_length = len(glv_vector['the'])#dim=300 \n",
    "#     word_index = tokenizer.word_index \n",
    "#     inv_word_index = {v: k for k, v in word_index.items()} \n",
    "#     num_unique_words = len(word_index) \n",
    "#     glv_embedding_matrix = np.zeros((num_unique_words + 1, word_vector_length)) \n",
    " \n",
    "#     for j in range(1, num_unique_words + 1): \n",
    "#         glv_embedding_matrix[j] = glv_vector.get(inv_word_index[j], np.random.randn(word_vector_length) / 200) \n",
    " \n",
    "#     np.save('data/dump/glv_embedding_matrix.npy', glv_embedding_matrix) \n",
    "#     print('Done. Completed preprocessing.') \n",
    "# else: \n",
    "#     glv_embedding_matrix = np.load('data/dump/glv_embedding_matrix.npy', allow_pickle=True) \n",
    "#     file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "367963a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab_size, embedding_dim = glv_embedding_matrix.shape\n",
    "# vocab_size, embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a539fab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\edayo\\Downloads\\4y2t\\THSST-2\\ug_thesis\\ER_GAT\\data/wiki-news-300d-1M.vec exists\n"
     ]
    }
   ],
   "source": [
    "file_path = os.path.join(os.getcwd(), \"data/wiki-news-300d-1M.vec\")\n",
    "if os.path.isfile(file_path):\n",
    "    print(f\"{file_path} exists\")\n",
    "else:\n",
    "    print(f\"The file does not exist in the current directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c74680f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = Vectors(name=\"wiki-news-300d-1M.vec\", url=\"data/\", cache=\"data/\")\n",
    "vectors.cache(name=\"data/wiki-news-300d-1M.vec\", url=\"data/\", cache=\"data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "89ca952d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([999994, 300])\n"
     ]
    }
   ],
   "source": [
    "print(vectors.vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b27c37d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Vocab(counter=collections.Counter(_read_words(X_train.Utterance)),\n",
    "                  vectors=vectors,\n",
    "                  specials=['<pad>', '<unk>'],\n",
    "                  min_freq=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f41e9829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total num. of words: 2120, word vector dimension: 300\n"
     ]
    }
   ],
   "source": [
    "# print word embedding statistics \n",
    "wv_size = vocab.vectors.size() \n",
    "print('Total num. of words: {}, word vector dimension: {}'.format( \n",
    "   wv_size[0], \n",
    "   wv_size[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0db604a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WORDEBD(\n",
       "  (embedding_layer): Embedding(2120, 300)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ebd = WORDEBD(vocab, False)\n",
    "ebd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5238db3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Munch({\n",
    "    \"cnn_filter_sizes\":[3,4,5],\n",
    "    \"cnn_num_filters\":100,\n",
    "    \"cuda\":-1,\n",
    "    \"mode\":\"train\",\n",
    "    \"snapshot\":'',\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d7c0f2",
   "metadata": {},
   "source": [
    "Creating an embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "87436c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNNLSTMseq(ebd, args) # ProtoSeq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8f3a4969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/02/20 20:56:19, Building embedding\n"
     ]
    }
   ],
   "source": [
    "print(\"{}, Building embedding\".format(\n",
    "    datetime.datetime.now().strftime('%y/%m/%d %H:%M:%S')), flush=True),\n",
    "if args.snapshot != '':\n",
    "    if args.multitask:\n",
    "        print(\"{}, Loading pretrained embedding from {}\".format(\n",
    "            datetime.datetime.now().strftime('%y/%m/%d %H:%M:%S'),\n",
    "            '%s_%s.ebd' % (args.snapshot, args.task),\n",
    "            ))\n",
    "        model.load_state_dict(  torch.load( '%s_%s.ebd' % (args.snapshot, args.task) ), strict=False  )\n",
    "    else:   \n",
    "        # load pretrained models,\n",
    "        print(\"{}, Loading pretrained embedding from {}\".format(\n",
    "            datetime.datetime.now().strftime('%y/%m/%d %H:%M:%S'),\n",
    "            '{}.ebd'.format(args.snapshot)\n",
    "            ))\n",
    "        model.load_state_dict(  torch.load( '{}.ebd'.format(args.snapshot) ), strict=False  )\n",
    "# if args.cuda != -1: ,\n",
    "#     model.cuda(args.cuda),\n",
    "# else: ,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "481c95c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNLSTMseq(\n",
       "  (ebd): WORDEBD(\n",
       "    (embedding_layer): Embedding(2120, 300)\n",
       "  )\n",
       "  (convs): ModuleList(\n",
       "    (0): Conv1d(300, 100, kernel_size=(3,), stride=(1,))\n",
       "    (1): Conv1d(300, 100, kernel_size=(4,), stride=(1,))\n",
       "    (2): Conv1d(300, 100, kernel_size=(5,), stride=(1,))\n",
       "  )\n",
       "  (lstm): LSTM(300, 150, bidirectional=True)\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "705921fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert everything into np array for fast data loading\n",
    "# _X_train = _data_to_nparray(X_train, vocab, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ff983f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d87fc320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNLSTMseq(\n",
       "  (ebd): WORDEBD(\n",
       "    (embedding_layer): Embedding(2120, 300)\n",
       "  )\n",
       "  (convs): ModuleList(\n",
       "    (0): Conv1d(300, 100, kernel_size=(3,), stride=(1,))\n",
       "    (1): Conv1d(300, 100, kernel_size=(4,), stride=(1,))\n",
       "    (2): Conv1d(300, 100, kernel_size=(5,), stride=(1,))\n",
       "  )\n",
       "  (lstm): LSTM(300, 150, bidirectional=True)\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5246b15",
   "metadata": {},
   "source": [
    "Testing on smaller data. Uncomment to see the size of updated representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d9000ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 300])\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# sample data \n",
    "data = [ \n",
    "#     [\"how are you\", \"I am great how about you\", \"good too\"], \n",
    "    [\"hes\"], \n",
    "    # ... more conversations ... \n",
    "] \n",
    "tmp_in = []         \n",
    "for conversation in data: \n",
    "    turn_indices = [torch.tensor([vocab.stoi[word] if word in vocab.stoi else vocab.stoi['<unk>'] for word in turn]) \n",
    "                for turn in conversation] \n",
    "#     print((turn_indices)) \n",
    "    # Pad sequences to a fixed length (adjust this based on your model requirements) \n",
    "    max_seq_len = max(max(len(turn), 5) for turn in turn_indices) \n",
    " \n",
    "    padded_turns = [torch.nn.functional.pad(turn, pad=(0, max_seq_len - len(turn))) for turn in turn_indices] \n",
    " \n",
    "    # Stack the padded turns along a new dimension \n",
    "    batched_input = torch.stack(padded_turns) \n",
    "    input_data = {'Utterance': batched_input} \n",
    "    tmp_in = max_seq_len \n",
    "    print(model.ebd(input_data[\"Utterance\"], None).size()) \n",
    "    print(len(model.ebd(input_data[\"Utterance\"], None))) \n",
    " \n",
    "    model(input_data) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d75d57",
   "metadata": {},
   "source": [
    "This is just a duplicate of code above. Using this on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "22c69a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges = find_value_ranges(X_train[\"Dialogue_ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "200bbb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_representations = [] \n",
    " \n",
    "checkFile = os.path.isfile(\"embed/updated_representation_list.pkl\") \n",
    " \n",
    "if checkFile is False: \n",
    "    for range_pair in ranges: \n",
    "        start_idx, end_idx = range_pair \n",
    "    #     print(start_idx , \\   \\\", end_idx) \n",
    "        conversation = X_train['Utterance'][start_idx:end_idx+1] \n",
    "    #     conversation = X_train['Utterance'][247:249] \n",
    " \n",
    "        turn_indices = [torch.tensor([vocab.stoi[word] if word in vocab.stoi else vocab.stoi['<unk>'] for word in turn]) \n",
    "                    for turn in conversation] \n",
    "        max_seq_len = max(max(len(turn), 5) for turn in turn_indices) \n",
    "        padded_turns = [torch.nn.functional.pad(turn, pad=(0, max_seq_len - len(turn))) for turn in turn_indices] \n",
    " \n",
    "        # Stack the padded turns along a new dimension \n",
    "        batched_input = torch.stack(padded_turns) \n",
    "        input_data = {'Utterance': batched_input} \n",
    "        output_representation = model(input_data) \n",
    " \n",
    "        updated_representations.append(output_representation) \n",
    "     \n",
    "     \n",
    "    file_path = 'embed/updated_representation_list.pkl' \n",
    "    # Save the list to a file using pickle \n",
    "    with open(file_path, 'wb') as file: \n",
    "        pickle.dump(updated_representations, file) \n",
    "     \n",
    "else: \n",
    "    file_path = 'embed/updated_representation_list.pkl' \n",
    " \n",
    "    # Load the list from the file using pickle \n",
    "    with open(file_path, 'rb') as file: \n",
    "        updated_representations = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5c3d1152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 300])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_representations[38].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4aea66e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(_X_train[\"text\"]))\n",
    "# print(len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "447aa6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ranges = find_value_ranges(X_train[\"Dialogue_ID\"])\n",
    "# ranges[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a1821fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkFile = os.path.isfile( \"data/dump/speaker_encoder.pkl\") \n",
    "encoded_speaker_list = [] \n",
    "if checkFile is False: \n",
    "    for range_pair in ranges: \n",
    "        start_idx, end_idx = range_pair \n",
    "        speaker_per_dialog = X_train['Speaker'][start_idx:end_idx+1].copy() \n",
    "        speaker_feature = set(speaker_per_dialog) \n",
    "        speaker_encoder = {feature: i for i, feature in enumerate(speaker_feature)} \n",
    "        speaker_decoder = {i: feature for i, feature in enumerate(speaker_feature)} \n",
    "        # print( \"ID:  \",  range_pair,    \", speaker_encoder) \n",
    "        # print( \"ID:  \",  speaker_per_dialog) \n",
    " \n",
    "        encoded_speaker = speaker_per_dialog.replace(speaker_encoder) \n",
    "        encoded_speaker_list.append(encoded_speaker) \n",
    " \n",
    "    file_path = 'data/dump/speaker_encoder.pkl' \n",
    "    with open(file_path, 'wb') as file: \n",
    "        pickle.dump([encoded_speaker_list, ranges], file) \n",
    "#     pickle.dump([encoded_speaker_list, ranges], open('data/dump/speaker_encoder.pkl')) \n",
    "else: \n",
    "    file = open('data/dump/speaker_encoder.pkl',  \"rb\") \n",
    "    encoded_speaker_list = pickle.load(file) \n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53400cc5",
   "metadata": {},
   "source": [
    "To check if there are 2 speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fa2f5daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for range_pair in ranges: \n",
    "#     start_idx, end_idx = range_pair \n",
    "#     speaker_per_dialog = X_train[['Dialogue_ID','Speaker']][start_idx:end_idx+1].copy() \n",
    "#     speaker_feature = set(speaker_per_dialog[\"Speaker\"])\n",
    "#     print(start_idx, end_idx ,speaker_feature)\n",
    "#     print(list(speaker_per_dialog[\"Dialogue_ID\"]))\n",
    "#     speaker_encoder = {feature: i for i, feature in enumerate(speaker_feature)} \n",
    "#     speaker_decoder = {i: feature for i, feature in enumerate(speaker_feature)} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fd6c294c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded_speaker_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
