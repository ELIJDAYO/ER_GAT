{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35a857cc",
   "metadata": {},
   "source": [
    "\"FC layers referenced from https://towardsdatascience.com/math-neural-network-from-scratch-in-python-d6da9f29ce65\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "176f72e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, precision_recall_fscore_support\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, chi2\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import plotly.graph_objs as go\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.io as pio\n",
    "from sklearn.utils import class_weight\n",
    "import tqdm as notebook_tqdm\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cebd6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b987c8ae",
   "metadata": {},
   "source": [
    "<h3> Declare functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6a4fb045",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCLayer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(FCLayer, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "class ActivationLayer(nn.Module):\n",
    "    def __init__(self, activation_fn):\n",
    "        super(ActivationLayer, self).__init__()\n",
    "        self.activation_fn = activation_fn\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation_fn(x)\n",
    "        return x\n",
    "\n",
    "def tanh(x):\n",
    "    return torch.tanh(x)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return torch.sigmoid(x)\n",
    "\n",
    "class MyNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(MyNetwork, self).__init__()\n",
    "        self.fc1 = FCLayer(input_dim, hidden_dim)\n",
    "        self.activation1 = ActivationLayer(tanh)\n",
    "        self.fc2 = FCLayer(hidden_dim, output_dim)\n",
    "        self.activation2 = ActivationLayer(sigmoid)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.activation1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.activation2(x)\n",
    "        return x\n",
    "\n",
    "# loss function and its derivative\n",
    "def mse(y_true, y_pred):\n",
    "    return np.mean(np.power(y_true - y_pred, 2))\n",
    "\n",
    "def mse_prime(y_true, y_pred):\n",
    "    return 2 * (y_pred - y_true) / y_true.size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "246bf76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to balance class distribution using oversampling\n",
    "def oversample_data(X_train, Y_train, num_classes):\n",
    "    # Determine the class with the maximum number of instances\n",
    "    max_class_count = np.max(np.bincount(Y_train))\n",
    "    # Generate indices for oversampling each class\n",
    "    indices_list = [np.where(Y_train == i)[0] for i in range(num_classes)]\n",
    "    # Oversample minority classes to match the count of the majority class\n",
    "    for i, indices in enumerate(indices_list):\n",
    "        if len(indices) < max_class_count:\n",
    "            oversampled_indices = np.random.choice(indices, size=max_class_count - len(indices), replace=True)\n",
    "            X_train = np.concatenate((X_train, X_train[oversampled_indices]), axis=0)\n",
    "            Y_train = np.concatenate((Y_train, Y_train[oversampled_indices]), axis=0)\n",
    "    return X_train, Y_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7503aae",
   "metadata": {},
   "source": [
    "<h4> Extract train labels and label encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "72c216ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"data/dump/labels_train.pkl\"\n",
    "with open(file_path, 'rb') as file:\n",
    "    y_train = pickle.load(file)\n",
    "y_train = torch.tensor(y_train)\n",
    "    \n",
    "file_path = 'data/dump/label_decoder.pkl'\n",
    "with open(file_path, 'rb') as file:\n",
    "    label_decoder = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7136ff",
   "metadata": {},
   "source": [
    "<h4> Extract test labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "117dcaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"data/dump/labels_test.pkl\"\n",
    "with open(file_path, 'rb') as file:\n",
    "    file = open('data/dump/labels_test.pkl', 'rb')\n",
    "    y_test = pickle.load(file)\n",
    "y_test = torch.tensor(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f3e716",
   "metadata": {},
   "source": [
    "<h4> Getting BERT and GAT outputs for train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7e3426c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'embed/u_prime_BERT_train.pkl'\n",
    "with open(file_path, 'rb') as file:\n",
    "    u_primes = pickle.load(file)\n",
    "\n",
    "    concatenated_tensors = []\n",
    "    for dialogue_tensor in u_primes:\n",
    "        concatenated_tensors.extend(dialogue_tensor)\n",
    "\n",
    "    tensorUtterancesTrain = torch.stack(concatenated_tensors)\n",
    "\n",
    "file_path = \"data/dump/h_prime_BERT-GAT_train.pkl\"\n",
    "with open(file_path, 'rb') as file:\n",
    "    cherryPickedNodesTrain, _ = pickle.load(file)\n",
    "\n",
    "file_path = \"data/dump/h_prime_BERT-EGAT_train.pkl\"\n",
    "with open(file_path, 'rb') as file:\n",
    "    allNodeFeatsTrain, _ = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e9766f",
   "metadata": {},
   "source": [
    "<h4> Getting BERT and GAT outputs for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0fcf3af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'embed/u_prime_BERT_test.pkl'\n",
    "with open(file_path, 'rb') as file:\n",
    "    u_primes = pickle.load(file)\n",
    "\n",
    "    concatenated_tensors = []\n",
    "    for dialogue_tensor in u_primes:\n",
    "        concatenated_tensors.extend(dialogue_tensor)\n",
    "\n",
    "    tensorUtterancesTest = torch.stack(concatenated_tensors)\n",
    "\n",
    "file_path = \"data/dump/h_prime_BERT-GAT_test.pkl\"\n",
    "with open(file_path, 'rb') as file:\n",
    "    cherryPickedNodesTest, _ = pickle.load(file)\n",
    "\n",
    "file_path = \"data/dump/h_prime_BERT-EGAT_test.pkl\"\n",
    "with open(file_path, 'rb') as file:\n",
    "    allNodeFeatsTest, _ = pickle.load(file)\n",
    "    \n",
    "_ = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76361e00",
   "metadata": {},
   "source": [
    "<h4> Getting BERT and GAT outputs for the valid set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43e017b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO do the same code as above once you have u' and h' of valid set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875e7687",
   "metadata": {},
   "source": [
    "EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e174164",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# # Checking the structure of graph\n",
    "# for n in range(10):\n",
    "#     tensor_data_np = tensor_utterances[n].detach().numpy()\n",
    "\n",
    "#     # Plot the data\n",
    "#     plt.figure(figsize=(10, 5))\n",
    "#     plt.plot(range(len(tensor_data_np)), tensor_data_np)\n",
    "#     plt.title('Line Graph of Tensor Data')\n",
    "#     plt.xlabel('Index')\n",
    "#     plt.ylabel('Value')\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "479a3b1f",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# # Normalize the h' (1st GAT)\n",
    "# data = cherry_picked_nodes.detach().numpy()\n",
    "# data_normalized = data / np.linalg.norm(data, axis=1, keepdims=True)\n",
    "\n",
    "# # Compute pairwise cosine similarities\n",
    "# similarities = cosine_similarity(data_normalized)\n",
    "\n",
    "# # Print or analyze the similarity matrix\n",
    "# # print(similarities)\n",
    "# plt.hist(similarities.flatten(), bins=50, density=True)\n",
    "# plt.title('Distribution of Cosine Similarities')\n",
    "# plt.xlabel('Cosine Similarity')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a070ce4",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# # Normalize the h' (2nd GAT)\n",
    "# data = all_node_feats.detach().numpy()\n",
    "# data_normalized = data / np.linalg.norm(data, axis=1, keepdims=True)\n",
    "\n",
    "# # Compute pairwise cosine similarities\n",
    "# similarities = cosine_similarity(data_normalized)\n",
    "\n",
    "# # Print or analyze the similarity matrix\n",
    "# # print(similarities)\n",
    "# plt.hist(similarities.flatten(), bins=50, density=True)\n",
    "# plt.title('Distribution of Cosine Similarities')\n",
    "# plt.xlabel('Cosine Similarity')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a43fa315",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# # Normalize the u' or updated_representations\n",
    "# data = tensor_utterances.detach().numpy()\n",
    "# data_normalized = data / np.linalg.norm(data, axis=1, keepdims=True)\n",
    "\n",
    "# # Compute pairwise cosine similarities\n",
    "# similarities = cosine_similarity(data_normalized)\n",
    "\n",
    "# plt.hist(similarities.flatten(), bins=50, density=True)\n",
    "# plt.title('Distribution of Cosine Similarities')\n",
    "# plt.xlabel('Cosine Similarity')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40320052",
   "metadata": {},
   "source": [
    "<h3> Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c909e8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = tensor_utterances\n",
    "# Y_train = y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510f143f",
   "metadata": {},
   "source": [
    "Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "caf09478",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# # Define the number of features (k) to select\n",
    "# k = 100  # Adjust this value as needed\n",
    "\n",
    "# # Initialize SelectKBest with the desired score function (e.g., f_classif for classification tasks)\n",
    "# selector = SelectKBest(score_func=f_classif, k=k)\n",
    "\n",
    "# # Fit SelectKBest on the training data and target variable\n",
    "# selector.fit(X_train, Y_train)\n",
    "\n",
    "# # Get the indices of the selected features\n",
    "# selected_indices = selector.get_support(indices=True)\n",
    "\n",
    "# # Get the scores of the selected features\n",
    "# feature_scores = selector.scores_[selected_indices]\n",
    "\n",
    "# # Display the scores along with their corresponding indices\n",
    "# # for idx, score in zip(selected_indices, feature_scores):\n",
    "# #     print(f\"Feature index: {idx}, Score: {score}\")\n",
    "\n",
    "# X_train_selected = X_train[:, selected_indices]\n",
    "# print(X_train_selected.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0264084c",
   "metadata": {},
   "source": [
    "Pass u' (BERT) and h' (GAT or EGAT) into this method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6501b577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_selected_features(encoded_features, labels, top_n):\n",
    "    # Apply Min-Max scaling to make the data non-negative\n",
    "    scaler = MinMaxScaler()\n",
    "    features_scaled = scaler.fit_transform(encoded_features)\n",
    "\n",
    "    # Initialize SelectKBest with the desired score function (e.g., f_classif for classification tasks)\n",
    "    selector = SelectKBest(score_func=f_classif, k=100)\n",
    "    # Assuming feature is your feature matrix (12840 instances x 300 dimensions)\n",
    "    # and y_train is your target labels\n",
    "\n",
    "    # Initialize a dictionary to store the indices of top features for each class\n",
    "    top_features_by_class = {}\n",
    "    top_scores = {}\n",
    "    # Calculate the relevance of each feature to each class using chi-squared test\n",
    "    for label in range(7):  # Assuming you have 7 classes\n",
    "        # Create a binary mask indicating instances belonging to the current class\n",
    "        mask = (labels == label)\n",
    "\n",
    "        # SelectKBest with chi2 as the scoring function\n",
    "        selector = SelectKBest(score_func=chi2, k=top_n)  # Select top 20 features\n",
    "        selector.fit(features_scaled, mask)  # Fit SelectKBest to the data\n",
    "        # Get the indices of the top 20 features\n",
    "        top_features_indices = np.argsort(selector.scores_)[-top_n:]\n",
    "        scores = selector.scores_[top_features_indices]\n",
    "        # Store the indices in the dictionary\n",
    "        top_features_by_class[label] = top_features_indices\n",
    "        top_scores[label] = scores\n",
    "\n",
    "    # Print the top features for each class\n",
    "    # for label, indices in top_features_by_class.items():\n",
    "    #     print(f\"Label {label_decoder[label]}: idx {', '.join(map(str, indices))}\")\n",
    "    #     print(top_scores[label])\n",
    "\n",
    "    concatenated_features_set = set()\n",
    "    for label, indices in top_features_by_class.items():\n",
    "        concatenated_features_set.update(indices)\n",
    "\n",
    "    concatenated_features_indices = list(concatenated_features_set)\n",
    "\n",
    "    concatenated_features_indices = np.array(concatenated_features_indices)\n",
    "\n",
    "    # Select the desired features\n",
    "    selected_features = encoded_features[:, concatenated_features_indices]\n",
    "#     print(selected_features.shape)\n",
    "    return selected_features, concatenated_features_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b050a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac1af030",
   "metadata": {},
   "source": [
    "Selected h'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74744ee3",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# X_train = all_node_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "13cad676",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# # Apply Min-Max scaling to make the data non-negative\n",
    "# scaler = MinMaxScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# # Initialize SelectKBest with the desired score function (e.g., f_classif for classification tasks)\n",
    "# selector = SelectKBest(score_func=f_classif, k=100)\n",
    "# # Assuming X_train is your feature matrix (12840 instances x 300 dimensions)\n",
    "# # and y_train is your target labels\n",
    "\n",
    "# # Initialize a dictionary to store the indices of top features for each class\n",
    "# top_features_by_class = {}\n",
    "# top_scores = {}\n",
    "# # Calculate the relevance of each feature to each class using chi-squared test\n",
    "# for label in range(7):  # Assuming you have 7 classes\n",
    "#     # Create a binary mask indicating instances belonging to the current class\n",
    "#     mask = (Y_train == label)\n",
    "\n",
    "#     # SelectKBest with chi2 as the scoring function\n",
    "#     selector = SelectKBest(score_func=chi2, k=20)  # Select top 20 features\n",
    "#     selector.fit(X_train_scaled, mask)  # Fit SelectKBest to the data\n",
    "#     # Get the indices of the top 20 features\n",
    "#     top_features_indices = np.argsort(selector.scores_)[-20:]\n",
    "#     scores = selector.scores_[top_features_indices]\n",
    "#     # Store the indices in the dictionary\n",
    "#     top_features_by_class[label] = top_features_indices\n",
    "#     top_scores[label] = scores\n",
    "    \n",
    "# # Print the top features for each class\n",
    "# for label, indices in top_features_by_class.items():\n",
    "#     print(f\"Label {label_decoder[label]}: idx {', '.join(map(str, indices))}\")\n",
    "#     print(top_scores[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37ad95c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12840, 102])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca3e54f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_features1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc72c402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_features2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "46d79a94",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# pca = PCA(n_components=2)\n",
    "# pca_result = pca.fit_transform(selected_features.detach().numpy())\n",
    "\n",
    "# # Plot the PCA result with color-coded labels\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# for label in np.unique(Y_train):\n",
    "#     indices = Y_train == label\n",
    "#     plt.scatter(pca_result[indices, 0], pca_result[indices, 1], label=f'{label_decoder[label]}', alpha=0.5)\n",
    "#     plt.title('PCA Visualization of Selected Utterance Embeddings (Train) with Color-Coded Labels')\n",
    "#     plt.xlabel('Principal Component 1')\n",
    "#     plt.ylabel('Principal Component 2')\n",
    "#     plt.legend()\n",
    "#     plt.grid(True)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9891e235",
   "metadata": {},
   "source": [
    "3d plottly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "efccc17d",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# X_train = selected_features\n",
    "# X_train = X_train / np.linalg.norm(X_train, axis=1, keepdims=True)\n",
    "# # Perform T-SNE dimensionality reduction\n",
    "# tsne = TSNE(n_components=3, random_state=42)\n",
    "# X_tsne = tsne.fit_transform(X_train)\n",
    "\n",
    "# # Create a Plotly scatter plot\n",
    "# fig = go.Figure(data=[go.Scatter3d(\n",
    "#     x=X_tsne[:, 0],\n",
    "#     y=X_tsne[:, 1],\n",
    "#     z=X_tsne[:, 2],\n",
    "#     mode='markers',\n",
    "#     marker=dict(\n",
    "#         size=3,\n",
    "#         color=Y_train,  # Assuming Y_train contains labels for coloring\n",
    "#         colorscale='Viridis',  # You can choose a different colorscale\n",
    "#         opacity=0.8\n",
    "#     )\n",
    "# )])\n",
    "\n",
    "# # Update layout\n",
    "# fig.update_layout(title='3D T-SNE Plot', autosize=False,\n",
    "#                   width=800, height=800)\n",
    "\n",
    "# # Show the plot\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca73f7e2",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Save the plot as an HTML file\n",
    "# pio.write_html(fig, '3d_tsne_plot.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0feaf772",
   "metadata": {},
   "source": [
    "Selected features of train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "cd9e733c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sizes of different combination of train data\n",
      " FeatureSelected+BERT+EGAT:  torch.Size([12840, 227]) \n",
      " FeatureSelected+BERT+GAT:  torch.Size([12840, 227]) \n",
      " BERT:  torch.Size([12840, 768]) \n",
      " FeatureSelected+BERT:  torch.Size([12840, 114])\n"
     ]
    }
   ],
   "source": [
    "# BERT+EGAT\n",
    "selectedUPrime, BERT_trainIndices = get_selected_features(tensorUtterancesTrain, y_train, 20)\n",
    "selectedHPrime, GAT_trainIndices1 = get_selected_features(allNodeFeatsTrain, y_train, 20)\n",
    "concatenatedRepresentationTrain1 = torch.cat((selectedUPrime, selectedHPrime), dim=1)\n",
    "# BERT+GAT\n",
    "selectedHPrime, GAT_trainIndices2 = get_selected_features(allNodeFeatsTrain, y_train, 20)\n",
    "concatenatedRepresentationTrain2 = torch.cat((selectedUPrime, selectedHPrime), dim=1)\n",
    "# raw-BERT\n",
    "rawCtxRepresentationTrain = tensorUtterancesTrain\n",
    "# selected-BERT\n",
    "ctxRepresentationTrain = selectedUPrime\n",
    "\n",
    "print(\"Sizes of different combination of train data\\n\",\n",
    "      \"FeatureSelected+BERT+EGAT: \", concatenatedRepresentationTrain1.shape, \"\\n\",\n",
    "      \"FeatureSelected+BERT+GAT: \", concatenatedRepresentationTrain2.shape, \"\\n\",\n",
    "      \"BERT: \", rawCtxRepresentationTrain.shape, \"\\n\",\n",
    "      \"FeatureSelected+BERT: \", ctxRepresentationTrain.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98673cd",
   "metadata": {},
   "source": [
    "Selected features of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "69ee1a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sizes of different combination of train data\n",
      " FeatureSelected+BERT+EGAT:  torch.Size([3400, 227]) \n",
      " FeatureSelected+BERT+GAT:  torch.Size([3400, 227]) \n",
      " BERT:  torch.Size([3400, 768]) \n",
      " FeatureSelected+BERT:  torch.Size([3400, 114])\n"
     ]
    }
   ],
   "source": [
    "# BERT+EGAT\n",
    "selectedUPrime = tensorUtterancesTest[:, BERT_trainIndices]\n",
    "selectedHPrime = allNodeFeatsTest[:, GAT_trainIndices1]\n",
    "concatenatedRepresentationTest1 = torch.cat((selectedUPrime, selectedHPrime), dim=1)\n",
    "# BERT+GAT\n",
    "selectedHPrime = allNodeFeatsTest[:, GAT_trainIndices2]\n",
    "concatenatedRepresentationTest2 = torch.cat((selectedUPrime, selectedHPrime), dim=1)\n",
    "# raw-BERT\n",
    "rawCtxRepresentationTest = tensorUtterancesTest\n",
    "# selected-BERT\n",
    "ctxRepresentationTest = selectedUPrime\n",
    "\n",
    "print(\"Sizes of different combination of train data\\n\",\n",
    "      \"FeatureSelected+BERT+EGAT: \", concatenatedRepresentationTest1.shape, \"\\n\",\n",
    "      \"FeatureSelected+BERT+GAT: \", concatenatedRepresentationTest2.shape, \"\\n\",\n",
    "      \"BERT: \", rawCtxRepresentationTest.shape, \"\\n\",\n",
    "      \"FeatureSelected+BERT: \", ctxRepresentationTest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265dc4c4",
   "metadata": {},
   "source": [
    "1. Prep data - normalize and create data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ebb893e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loader(features, labels, isTrain):\n",
    "    num_instances = len(features)\n",
    "    num_classes = 7\n",
    "\n",
    "    # Rescale input features\n",
    "    # selected_features = concatenated_representation / np.linalg.norm(concatenated_representation, axis=1, keepdims=True)\n",
    "\n",
    "    # Apply data resampling (oversampling) to balance class distribution\n",
    "    if isTrain:\n",
    "        X_set, Y_set = oversample_data(features, labels, num_classes)\n",
    "    else:\n",
    "        X_set, Y_set = features, labels\n",
    "\n",
    "    # Calculate class weights for class weighting\n",
    "#     class_counts = np.bincount(labels)\n",
    "#     total_instances = np.sum(class_counts)\n",
    "    # class_weights = torch.tensor([total_instances / (num_classes * count) for count in class_counts], dtype=torch.float32)\n",
    "\n",
    "    # Convert data to PyTorch tensors\n",
    "    X_tensor = torch.tensor(X_set, dtype=torch.float32).clone().detach()\n",
    "    Y_tensor = torch.tensor(Y_set, dtype=torch.long).clone().detach()\n",
    "    # print(X_train_tensor.shape, Y_train_tensor.shape)\n",
    "    # X_train_tensor = torch.tensor(selected_features)\n",
    "    # Y_train_tensor = torch.tensor(y_train)\n",
    "\n",
    "    unique_labels, label_counts = np.unique(Y_set, return_counts=True)\n",
    "\n",
    "    # Print the counts for each unique label\n",
    "    for label, count in zip(unique_labels, label_counts):\n",
    "        print(f\"Label {label_decoder[label]}: {count} occurrences\")\n",
    "\n",
    "    print(X_tensor.shape, Y_tensor.shape)\n",
    "    # Create a TensorDataset\n",
    "    dataset = TensorDataset(X_tensor, Y_tensor)\n",
    "\n",
    "    # Define batch size for DataLoader\n",
    "    batch_size = 1\n",
    "\n",
    "    # Create a PyTorch DataLoader\n",
    "    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    return train_loader, X_tensor, Y_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861ebf30",
   "metadata": {},
   "source": [
    "2. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9a71c886",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(dataLoader, input_dim, output_dim, num_epochs, num_classes):\n",
    "    # Initialize the model\n",
    "    model = MyNetwork(input_dim, output_dim, num_classes)\n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "    # Train the model\n",
    "    print_interval = 1  # Print tqdm every 10 epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_instances = 0\n",
    "        for inputs, labels in tqdm(dataLoader, desc=f'Epoch {epoch+1}/{num_epochs}', leave=False):\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "            total_instances += labels.size(0)\n",
    "\n",
    "        # Print average loss and accuracy per epoch\n",
    "        if (epoch + 1) % print_interval == 0:\n",
    "            epoch_loss = total_loss / len(dataLoader.dataset)\n",
    "            epoch_accuracy = correct_predictions / total_instances\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b435c98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_emotions(model, X_tensor, Y_tensor, isTrain):\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Predict on the training data\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_tensor)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    # Convert predicted tensor to numpy array\n",
    "    predicted = predicted.numpy()\n",
    "\n",
    "    # Calculate F1 score per class\n",
    "    f1_per_class = f1_score(Y_tensor, predicted, average=None)\n",
    "    f1 = f1_score(Y_tensor, predicted, average='macro')\n",
    "    if isTrain:\n",
    "        print(f'Train F1 Score: {f1:.4f}')\n",
    "    else:\n",
    "        print(f'Test F1 Score: {f1:.4f}')\n",
    "\n",
    "    unique_labels, label_counts = np.unique(predicted, return_counts=True)\n",
    "\n",
    "    # Print F1 score for each class\n",
    "    for i, f1 in enumerate(f1_per_class):\n",
    "        print(f'F1 Score for Class {label_decoder[i]}: {f1:.4f}')\n",
    "\n",
    "    # Print the counts for each unique label\n",
    "    for label, count in zip(unique_labels, label_counts):\n",
    "        print(f\"Label {label_decoder[label]}: {count} occurrences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0566c5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO create table of loss and accuracy during training\n",
    "# TODO also compute the time it takes to complete the train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9f7074",
   "metadata": {},
   "source": [
    "<h4> Train and validate BERT+EGAT given 2 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f085abb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label anger: 5960 occurrences\n",
      "Label disgust: 5960 occurrences\n",
      "Label fear: 5960 occurrences\n",
      "Label joy: 5960 occurrences\n",
      "Label neutral: 5960 occurrences\n",
      "Label sadness: 5960 occurrences\n",
      "Label surprise: 5960 occurrences\n",
      "torch.Size([41720, 227]) torch.Size([41720])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Loss: 1.8432, Accuracy: 0.3098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Loss: 1.7574, Accuracy: 0.3779\n",
      "Training F1 Score: 0.3981\n",
      "F1 Score for Class anger: 0.2814\n",
      "F1 Score for Class disgust: 0.4454\n",
      "F1 Score for Class fear: 0.4588\n",
      "F1 Score for Class joy: 0.4180\n",
      "F1 Score for Class neutral: 0.3400\n",
      "F1 Score for Class sadness: 0.3426\n",
      "F1 Score for Class surprise: 0.5007\n",
      "Label anger: 4673 occurrences\n",
      "Label disgust: 6756 occurrences\n",
      "Label fear: 5460 occurrences\n",
      "Label joy: 4867 occurrences\n",
      "Label neutral: 7234 occurrences\n",
      "Label sadness: 5325 occurrences\n",
      "Label surprise: 7405 occurrences\n"
     ]
    }
   ],
   "source": [
    "dataLoader, X_trainTensor, Y_trainTensor = get_data_loader(concatenatedRepresentationTrain1, y_train, True)\n",
    "# TODO 3rd argument is tunable\n",
    "fcClf = model_train(dataLoader, \n",
    "                    input_dim=X_trainTensor.shape[1], \n",
    "                    output_dim=20, \n",
    "                    num_epochs=2, \n",
    "                    num_classes=7)\n",
    "classify_emotions(fcClf, X_trainTensor, Y_trainTensor, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0a681aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label anger: 516 occurrences\n",
      "Label disgust: 99 occurrences\n",
      "Label fear: 60 occurrences\n",
      "Label joy: 495 occurrences\n",
      "Label neutral: 1615 occurrences\n",
      "Label sadness: 263 occurrences\n",
      "Label surprise: 352 occurrences\n",
      "torch.Size([3400, 227]) torch.Size([3400])\n",
      "Training F1 Score: 0.1284\n",
      "F1 Score for Class anger: 0.1551\n",
      "F1 Score for Class disgust: 0.0665\n",
      "F1 Score for Class fear: 0.0112\n",
      "F1 Score for Class joy: 0.1614\n",
      "F1 Score for Class neutral: 0.3280\n",
      "F1 Score for Class sadness: 0.0774\n",
      "F1 Score for Class surprise: 0.0992\n",
      "Label anger: 348 occurrences\n",
      "Label disgust: 412 occurrences\n",
      "Label fear: 297 occurrences\n",
      "Label joy: 558 occurrences\n",
      "Label neutral: 873 occurrences\n",
      "Label sadness: 357 occurrences\n",
      "Label surprise: 555 occurrences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_1452\\2284308149.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set, dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_1452\\2284308149.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set, dtype=torch.long).clone().detach()\n"
     ]
    }
   ],
   "source": [
    "# Predict the test set\n",
    "_, X_testTensor, Y_testTensor = get_data_loader(concatenatedRepresentationTest1, y_test, False)\n",
    "classify_emotions(fcClf, X_testTensor, Y_testTensor, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7e5533",
   "metadata": {},
   "source": [
    "<h4> Train and validate BERT+GAT given 2 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "db41b319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label anger: 5960 occurrences\n",
      "Label disgust: 5960 occurrences\n",
      "Label fear: 5960 occurrences\n",
      "Label joy: 5960 occurrences\n",
      "Label neutral: 5960 occurrences\n",
      "Label sadness: 5960 occurrences\n",
      "Label surprise: 5960 occurrences\n",
      "torch.Size([41720, 227]) torch.Size([41720])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Loss: 1.8432, Accuracy: 0.3084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Loss: 1.7602, Accuracy: 0.3755\n",
      "Training F1 Score: 0.3780\n",
      "F1 Score for Class anger: 0.2380\n",
      "F1 Score for Class disgust: 0.4426\n",
      "F1 Score for Class fear: 0.4328\n",
      "F1 Score for Class joy: 0.4494\n",
      "F1 Score for Class neutral: 0.3082\n",
      "F1 Score for Class sadness: 0.2854\n",
      "F1 Score for Class surprise: 0.4893\n",
      "Label anger: 3033 occurrences\n",
      "Label disgust: 6110 occurrences\n",
      "Label fear: 5750 occurrences\n",
      "Label joy: 7529 occurrences\n",
      "Label neutral: 5707 occurrences\n",
      "Label sadness: 3823 occurrences\n",
      "Label surprise: 9768 occurrences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "dataLoader, X_trainTensor, Y_trainTensor = get_data_loader(concatenatedRepresentationTrain2, y_train, True)\n",
    "# TODO 3rd argument is tunable\n",
    "fcClf = model_train(dataLoader, \n",
    "                    input_dim=X_trainTensor.shape[1], \n",
    "                    output_dim=20, \n",
    "                    num_epochs=2, \n",
    "                    num_classes=7)\n",
    "classify_emotions(fcClf, X_trainTensor, Y_trainTensor, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1c82764e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label anger: 516 occurrences\n",
      "Label disgust: 99 occurrences\n",
      "Label fear: 60 occurrences\n",
      "Label joy: 495 occurrences\n",
      "Label neutral: 1615 occurrences\n",
      "Label sadness: 263 occurrences\n",
      "Label surprise: 352 occurrences\n",
      "torch.Size([3400, 227]) torch.Size([3400])\n",
      "Training F1 Score: 0.1230\n",
      "F1 Score for Class anger: 0.1178\n",
      "F1 Score for Class disgust: 0.0674\n",
      "F1 Score for Class fear: 0.0110\n",
      "F1 Score for Class joy: 0.1861\n",
      "F1 Score for Class neutral: 0.2777\n",
      "F1 Score for Class sadness: 0.0696\n",
      "F1 Score for Class surprise: 0.1314\n",
      "Label anger: 231 occurrences\n",
      "Label disgust: 346 occurrences\n",
      "Label fear: 304 occurrences\n",
      "Label joy: 816 occurrences\n",
      "Label neutral: 675 occurrences\n",
      "Label sadness: 254 occurrences\n",
      "Label surprise: 774 occurrences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_1452\\2284308149.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set, dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_1452\\2284308149.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set, dtype=torch.long).clone().detach()\n"
     ]
    }
   ],
   "source": [
    "# Predict the test set\n",
    "_, X_testTensor, Y_testTensor = get_data_loader(concatenatedRepresentationTest2, y_test, False)\n",
    "classify_emotions(fcClf, X_testTensor, Y_testTensor, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240eda51",
   "metadata": {},
   "source": [
    "<h4> Train and validate BERT (x feature selection) given 2 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3cbf7c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label anger: 5960 occurrences\n",
      "Label disgust: 5960 occurrences\n",
      "Label fear: 5960 occurrences\n",
      "Label joy: 5960 occurrences\n",
      "Label neutral: 5960 occurrences\n",
      "Label sadness: 5960 occurrences\n",
      "Label surprise: 5960 occurrences\n",
      "torch.Size([41720, 768]) torch.Size([41720])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Loss: 1.7511, Accuracy: 0.3875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Loss: 1.6316, Accuracy: 0.4807\n",
      "Train F1 Score: 0.4958\n",
      "F1 Score for Class anger: 0.3838\n",
      "F1 Score for Class disgust: 0.6268\n",
      "F1 Score for Class fear: 0.6158\n",
      "F1 Score for Class joy: 0.4928\n",
      "F1 Score for Class neutral: 0.3800\n",
      "F1 Score for Class sadness: 0.3978\n",
      "F1 Score for Class surprise: 0.5736\n",
      "Label anger: 5514 occurrences\n",
      "Label disgust: 9940 occurrences\n",
      "Label fear: 5856 occurrences\n",
      "Label joy: 5298 occurrences\n",
      "Label neutral: 5402 occurrences\n",
      "Label sadness: 3553 occurrences\n",
      "Label surprise: 6157 occurrences\n"
     ]
    }
   ],
   "source": [
    "dataLoader, X_trainTensor, Y_trainTensor = get_data_loader(rawCtxRepresentationTrain, y_train, True)\n",
    "# TODO 3rd argument is tunable\n",
    "fcClf = model_train(dataLoader, \n",
    "                    input_dim=X_trainTensor.shape[1], \n",
    "                    output_dim=50, \n",
    "                    num_epochs=2, \n",
    "                    num_classes=7)\n",
    "classify_emotions(fcClf, X_trainTensor, Y_trainTensor, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "6d36ad6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label anger: 516 occurrences\n",
      "Label disgust: 99 occurrences\n",
      "Label fear: 60 occurrences\n",
      "Label joy: 495 occurrences\n",
      "Label neutral: 1615 occurrences\n",
      "Label sadness: 263 occurrences\n",
      "Label surprise: 352 occurrences\n",
      "torch.Size([3400, 768]) torch.Size([3400])\n",
      "Test F1 Score: 0.1247\n",
      "F1 Score for Class anger: 0.1617\n",
      "F1 Score for Class disgust: 0.0646\n",
      "F1 Score for Class fear: 0.0060\n",
      "F1 Score for Class joy: 0.1737\n",
      "F1 Score for Class neutral: 0.3011\n",
      "F1 Score for Class sadness: 0.0607\n",
      "F1 Score for Class surprise: 0.1049\n",
      "Label anger: 461 occurrences\n",
      "Label disgust: 551 occurrences\n",
      "Label fear: 275 occurrences\n",
      "Label joy: 645 occurrences\n",
      "Label neutral: 736 occurrences\n",
      "Label sadness: 264 occurrences\n",
      "Label surprise: 468 occurrences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_1452\\2284308149.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set, dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_1452\\2284308149.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set, dtype=torch.long).clone().detach()\n"
     ]
    }
   ],
   "source": [
    "# Predict the test set\n",
    "_, X_testTensor, Y_testTensor = get_data_loader(rawCtxRepresentationTest, y_test, False)\n",
    "classify_emotions(fcClf, X_testTensor, Y_testTensor, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793336f2",
   "metadata": {},
   "source": [
    "<h4> Train and validate BERT (o feature selection) given 2 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4309cdb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label anger: 5960 occurrences\n",
      "Label disgust: 5960 occurrences\n",
      "Label fear: 5960 occurrences\n",
      "Label joy: 5960 occurrences\n",
      "Label neutral: 5960 occurrences\n",
      "Label sadness: 5960 occurrences\n",
      "Label surprise: 5960 occurrences\n",
      "torch.Size([41720, 114]) torch.Size([41720])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Loss: 1.8229, Accuracy: 0.3227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Loss: 1.7423, Accuracy: 0.3817\n",
      "Train F1 Score: 0.3853\n",
      "F1 Score for Class anger: 0.2409\n",
      "F1 Score for Class disgust: 0.4296\n",
      "F1 Score for Class fear: 0.4482\n",
      "F1 Score for Class joy: 0.4354\n",
      "F1 Score for Class neutral: 0.3468\n",
      "F1 Score for Class sadness: 0.3023\n",
      "F1 Score for Class surprise: 0.4939\n",
      "Label anger: 3878 occurrences\n",
      "Label disgust: 7479 occurrences\n",
      "Label fear: 6252 occurrences\n",
      "Label joy: 4900 occurrences\n",
      "Label neutral: 7142 occurrences\n",
      "Label sadness: 4500 occurrences\n",
      "Label surprise: 7569 occurrences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "dataLoader, X_trainTensor, Y_trainTensor = get_data_loader(ctxRepresentationTrain, y_train, True)\n",
    "# TODO 3rd argument is tunable\n",
    "fcClf = model_train(dataLoader, \n",
    "                    input_dim=X_trainTensor.shape[1], \n",
    "                    output_dim=50, \n",
    "                    num_epochs=2, \n",
    "                    num_classes=7)\n",
    "classify_emotions(fcClf, X_trainTensor, Y_trainTensor, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "d0773393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label anger: 516 occurrences\n",
      "Label disgust: 99 occurrences\n",
      "Label fear: 60 occurrences\n",
      "Label joy: 495 occurrences\n",
      "Label neutral: 1615 occurrences\n",
      "Label sadness: 263 occurrences\n",
      "Label surprise: 352 occurrences\n",
      "torch.Size([3400, 114]) torch.Size([3400])\n",
      "Test F1 Score: 0.1248\n",
      "F1 Score for Class anger: 0.1312\n",
      "F1 Score for Class disgust: 0.0577\n",
      "F1 Score for Class fear: 0.0098\n",
      "F1 Score for Class joy: 0.1586\n",
      "F1 Score for Class neutral: 0.3388\n",
      "F1 Score for Class sadness: 0.0704\n",
      "F1 Score for Class surprise: 0.1070\n",
      "Label anger: 292 occurrences\n",
      "Label disgust: 421 occurrences\n",
      "Label fear: 349 occurrences\n",
      "Label joy: 564 occurrences\n",
      "Label neutral: 876 occurrences\n",
      "Label sadness: 334 occurrences\n",
      "Label surprise: 564 occurrences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_1452\\2284308149.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set, dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_1452\\2284308149.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set, dtype=torch.long).clone().detach()\n"
     ]
    }
   ],
   "source": [
    "# Predict the test set\n",
    "_, X_testTensor, Y_testTensor = get_data_loader(ctxRepresentationTest, y_test, False)\n",
    "classify_emotions(fcClf, X_testTensor, Y_testTensor, False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
