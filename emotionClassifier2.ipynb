{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35a857cc",
   "metadata": {},
   "source": [
    "\"FC layers referenced from https://towardsdatascience.com/math-neural-network-from-scratch-in-python-d6da9f29ce65\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "176f72e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, precision_recall_fscore_support\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, chi2\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import plotly.graph_objs as go\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.io as pio\n",
    "from sklearn.utils import class_weight\n",
    "import tqdm as notebook_tqdm\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4cebd6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1470c3",
   "metadata": {},
   "source": [
    "<h3> Declare functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6a4fb045",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCLayer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(FCLayer, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "class ActivationLayer(nn.Module):\n",
    "    def __init__(self, activation_fn):\n",
    "        super(ActivationLayer, self).__init__()\n",
    "        self.activation_fn = activation_fn\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation_fn(x)\n",
    "        return x\n",
    "\n",
    "def tanh(x):\n",
    "    return torch.tanh(x)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return torch.sigmoid(x)\n",
    "\n",
    "class MyNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(MyNetwork, self).__init__()\n",
    "        self.fc1 = FCLayer(input_dim, hidden_dim)\n",
    "        self.activation1 = ActivationLayer(tanh)\n",
    "        self.fc2 = FCLayer(hidden_dim, output_dim)\n",
    "        self.activation2 = ActivationLayer(sigmoid)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.activation1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.activation2(x)\n",
    "        return x\n",
    "\n",
    "# loss function and its derivative\n",
    "def mse(y_true, y_pred):\n",
    "    return np.mean(np.power(y_true - y_pred, 2))\n",
    "\n",
    "def mse_prime(y_true, y_pred):\n",
    "    return 2 * (y_pred - y_true) / y_true.size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "246bf76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to balance class distribution using oversampling\n",
    "def oversample_data(X_train, Y_train, num_classes):\n",
    "    # Determine the class with the maximum number of instances\n",
    "    max_class_count = np.max(np.bincount(Y_train))\n",
    "    # Generate indices for oversampling each class\n",
    "    indices_list = [np.where(Y_train == i)[0] for i in range(num_classes)]\n",
    "    # Oversample minority classes to match the count of the majority class\n",
    "    for i, indices in enumerate(indices_list):\n",
    "        if len(indices) < max_class_count:\n",
    "            oversampled_indices = np.random.choice(indices, size=max_class_count - len(indices), replace=True)\n",
    "            X_train = np.concatenate((X_train, X_train[oversampled_indices]), axis=0)\n",
    "            Y_train = np.concatenate((Y_train, Y_train[oversampled_indices]), axis=0)\n",
    "    return X_train, Y_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7503aae",
   "metadata": {},
   "source": [
    "<h4> Extract train labels and label encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "72c216ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"data/dump/labels_train.pkl\"\n",
    "with open(file_path, 'rb') as file:\n",
    "    y_train = pickle.load(file)\n",
    "y_train = torch.tensor(y_train)\n",
    "    \n",
    "file_path = 'data/dump/label_decoder.pkl'\n",
    "with open(file_path, 'rb') as file:\n",
    "    label_decoder = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7136ff",
   "metadata": {},
   "source": [
    "<h4> Extract test labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "117dcaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"data/dump/labels_test.pkl\"\n",
    "with open(file_path, 'rb') as file:\n",
    "    file = open('data/dump/labels_test.pkl', 'rb')\n",
    "    y_test = pickle.load(file)\n",
    "y_test = torch.tensor(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f3e716",
   "metadata": {},
   "source": [
    "<h4> Getting BERT and GAT outputs for train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7e3426c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'embed/u_prime_BERT_train.pkl'\n",
    "with open(file_path, 'rb') as file:\n",
    "    u_primes = pickle.load(file)\n",
    "\n",
    "    concatenated_tensors = []\n",
    "    for dialogue_tensor in u_primes:\n",
    "        concatenated_tensors.extend(dialogue_tensor)\n",
    "\n",
    "    tensorUtterancesTrain = torch.stack(concatenated_tensors)\n",
    "\n",
    "file_path = \"embed/h_prime_BERT-GAT_train.pkl\"\n",
    "with open(file_path, 'rb') as file:\n",
    "    cherryPickedNodesTrain, _ = pickle.load(file)\n",
    "\n",
    "file_path = \"embed/h_prime_BERT-EGAT_train.pkl\"\n",
    "with open(file_path, 'rb') as file:\n",
    "    allNodeFeatsTrain, _ = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e9766f",
   "metadata": {},
   "source": [
    "<h4> Getting BERT and GAT outputs for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4ba9f3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'embed/u_prime_BERT_test.pkl'\n",
    "with open(file_path, 'rb') as file:\n",
    "    u_primes = pickle.load(file)\n",
    "\n",
    "    concatenated_tensors = []\n",
    "    for dialogue_tensor in u_primes:\n",
    "        concatenated_tensors.extend(dialogue_tensor)\n",
    "\n",
    "    tensorUtterancesTest = torch.stack(concatenated_tensors)\n",
    "\n",
    "file_path = \"embed/h_prime_BERT-GAT_test.pkl\"\n",
    "with open(file_path, 'rb') as file:\n",
    "    cherryPickedNodesTest, _ = pickle.load(file)\n",
    "\n",
    "file_path = \"embed/h_prime_BERT-EGAT_test.pkl\"\n",
    "with open(file_path, 'rb') as file:\n",
    "    allNodeFeatsTest, _ = pickle.load(file)\n",
    "    \n",
    "_ = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cba837d",
   "metadata": {},
   "source": [
    "<h4> Getting BERT and GAT outputs for the valid set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4a2f89a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO do the same code as above once you have u' and h' of valid set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875e7687",
   "metadata": {},
   "source": [
    "EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1e174164",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# # Checking the structure of graph\n",
    "# for n in range(10):\n",
    "#     tensor_data_np = tensor_utterances[n].detach().numpy()\n",
    "\n",
    "#     # Plot the data\n",
    "#     plt.figure(figsize=(10, 5))\n",
    "#     plt.plot(range(len(tensor_data_np)), tensor_data_np)\n",
    "#     plt.title('Line Graph of Tensor Data')\n",
    "#     plt.xlabel('Index')\n",
    "#     plt.ylabel('Value')\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "479a3b1f",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# # Normalize the h' (1st GAT)\n",
    "# data = cherry_picked_nodes.detach().numpy()\n",
    "# data_normalized = data / np.linalg.norm(data, axis=1, keepdims=True)\n",
    "\n",
    "# # Compute pairwise cosine similarities\n",
    "# similarities = cosine_similarity(data_normalized)\n",
    "\n",
    "# # Print or analyze the similarity matrix\n",
    "# # print(similarities)\n",
    "# plt.hist(similarities.flatten(), bins=50, density=True)\n",
    "# plt.title('Distribution of Cosine Similarities')\n",
    "# plt.xlabel('Cosine Similarity')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6a070ce4",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# # Normalize the h' (2nd GAT)\n",
    "# data = all_node_feats.detach().numpy()\n",
    "# data_normalized = data / np.linalg.norm(data, axis=1, keepdims=True)\n",
    "\n",
    "# # Compute pairwise cosine similarities\n",
    "# similarities = cosine_similarity(data_normalized)\n",
    "\n",
    "# # Print or analyze the similarity matrix\n",
    "# # print(similarities)\n",
    "# plt.hist(similarities.flatten(), bins=50, density=True)\n",
    "# plt.title('Distribution of Cosine Similarities')\n",
    "# plt.xlabel('Cosine Similarity')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a43fa315",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# # Normalize the u' or updated_representations\n",
    "# data = tensor_utterances.detach().numpy()\n",
    "# data_normalized = data / np.linalg.norm(data, axis=1, keepdims=True)\n",
    "\n",
    "# # Compute pairwise cosine similarities\n",
    "# similarities = cosine_similarity(data_normalized)\n",
    "\n",
    "# plt.hist(similarities.flatten(), bins=50, density=True)\n",
    "# plt.title('Distribution of Cosine Similarities')\n",
    "# plt.xlabel('Cosine Similarity')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40320052",
   "metadata": {},
   "source": [
    "<h3> Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c909e8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = tensor_utterances\n",
    "# Y_train = y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510f143f",
   "metadata": {},
   "source": [
    "Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "caf09478",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# # Define the number of features (k) to select\n",
    "# k = 100  # Adjust this value as needed\n",
    "\n",
    "# # Initialize SelectKBest with the desired score function (e.g., f_classif for classification tasks)\n",
    "# selector = SelectKBest(score_func=f_classif, k=k)\n",
    "\n",
    "# # Fit SelectKBest on the training data and target variable\n",
    "# selector.fit(X_train, Y_train)\n",
    "\n",
    "# # Get the indices of the selected features\n",
    "# selected_indices = selector.get_support(indices=True)\n",
    "\n",
    "# # Get the scores of the selected features\n",
    "# feature_scores = selector.scores_[selected_indices]\n",
    "\n",
    "# # Display the scores along with their corresponding indices\n",
    "# # for idx, score in zip(selected_indices, feature_scores):\n",
    "# #     print(f\"Feature index: {idx}, Score: {score}\")\n",
    "\n",
    "# X_train_selected = X_train[:, selected_indices]\n",
    "# print(X_train_selected.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0264084c",
   "metadata": {},
   "source": [
    "Pass u' (BERT) and h' (GAT or EGAT) into this method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6501b577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_norm_features(encoded_features):\n",
    "    scaler = MinMaxScaler()\n",
    "#       \"FeatureSelected+BERT+GAT: \", concatenatedRepresentationTrain2.shape, \"\\n\",\n",
    "    features_scaled = scaler.fit_transform(encoded_features.clone().detach())\n",
    "    return torch.tensor(features_scaled)\n",
    "\n",
    "def get_selected_features(encoded_features, labels, top_n):\n",
    "    # Apply Min-Max scaling to make the data non-negative\n",
    "    scaler = MinMaxScaler()\n",
    "    features_scaled = scaler.fit_transform(encoded_features)\n",
    "\n",
    "    # Initialize SelectKBest with the desired score function (e.g., f_classif for classification tasks)\n",
    "    selector = SelectKBest(score_func=f_classif, k=100)\n",
    "    # Assuming feature is your feature matrix (12840 instances x 300 dimensions)\n",
    "    # and y_train is your target labels\n",
    "\n",
    "    # Initialize a dictionary to store the indices of top features for each class\n",
    "    top_features_by_class = {}\n",
    "    top_scores = {}\n",
    "    # Calculate the relevance of each feature to each class using chi-squared test\n",
    "    for label in range(7):  # Assuming you have 7 classes\n",
    "        # Create a binary mask indicating instances belonging to the current class\n",
    "        mask = (labels == label)\n",
    "\n",
    "        # SelectKBest with chi2 as the scoring function\n",
    "        selector = SelectKBest(score_func=chi2, k=top_n)  # Select top 20 features\n",
    "        selector.fit(features_scaled, mask)  # Fit SelectKBest to the data\n",
    "        # Get the indices of the top 20 features\n",
    "        top_features_indices = np.argsort(selector.scores_)[-top_n:]\n",
    "        scores = selector.scores_[top_features_indices]\n",
    "        # Store the indices in the dictionary\n",
    "        top_features_by_class[label] = top_features_indices\n",
    "        top_scores[label] = scores\n",
    "\n",
    "    # Print the top features for each class\n",
    "    # for label, indices in top_features_by_class.items():\n",
    "    #     print(f\"Label {label_decoder[label]}: idx {', '.join(map(str, indices))}\")\n",
    "    #     print(top_scores[label])\n",
    "\n",
    "    concatenated_features_set = set()\n",
    "    for label, indices in top_features_by_class.items():\n",
    "        concatenated_features_set.update(indices)\n",
    "\n",
    "    concatenated_features_indices = list(concatenated_features_set)\n",
    "\n",
    "    concatenated_features_indices = np.array(concatenated_features_indices)\n",
    "\n",
    "    # Select the desired features\n",
    "    selected_features = encoded_features[:, concatenated_features_indices]\n",
    "#     print(selected_features.shape)\n",
    "    return selected_features, concatenated_features_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1af030",
   "metadata": {},
   "source": [
    "Selected h'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "74744ee3",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# X_train = all_node_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "13cad676",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# # Apply Min-Max scaling to make the data non-negative\n",
    "# scaler = MinMaxScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# # Initialize SelectKBest with the desired score function (e.g., f_classif for classification tasks)\n",
    "# selector = SelectKBest(score_func=f_classif, k=100)\n",
    "# # Assuming X_train is your feature matrix (12840 instances x 300 dimensions)\n",
    "# # and y_train is your target labels\n",
    "\n",
    "# # Initialize a dictionary to store the indices of top features for each class\n",
    "# top_features_by_class = {}\n",
    "# top_scores = {}\n",
    "# # Calculate the relevance of each feature to each class using chi-squared test\n",
    "# for label in range(7):  # Assuming you have 7 classes\n",
    "#     # Create a binary mask indicating instances belonging to the current class\n",
    "#     mask = (Y_train == label)\n",
    "\n",
    "#     # SelectKBest with chi2 as the scoring function\n",
    "#     selector = SelectKBest(score_func=chi2, k=20)  # Select top 20 features\n",
    "#     selector.fit(X_train_scaled, mask)  # Fit SelectKBest to the data\n",
    "#     # Get the indices of the top 20 features\n",
    "#     top_features_indices = np.argsort(selector.scores_)[-20:]\n",
    "#     scores = selector.scores_[top_features_indices]\n",
    "#     # Store the indices in the dictionary\n",
    "#     top_features_by_class[label] = top_features_indices\n",
    "#     top_scores[label] = scores\n",
    "    \n",
    "# # Print the top features for each class\n",
    "# for label, indices in top_features_by_class.items():\n",
    "#     print(f\"Label {label_decoder[label]}: idx {', '.join(map(str, indices))}\")\n",
    "#     print(top_scores[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ca3e54f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_features1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bc72c402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_features2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "46d79a94",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# pca = PCA(n_components=2)\n",
    "# pca_result = pca.fit_transform(selected_features.detach().numpy())\n",
    "\n",
    "# # Plot the PCA result with color-coded labels\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# for label in np.unique(Y_train):\n",
    "#     indices = Y_train == label\n",
    "#     plt.scatter(pca_result[indices, 0], pca_result[indices, 1], label=f'{label_decoder[label]}', alpha=0.5)\n",
    "#     plt.title('PCA Visualization of Selected Utterance Embeddings (Train) with Color-Coded Labels')\n",
    "#     plt.xlabel('Principal Component 1')\n",
    "#     plt.ylabel('Principal Component 2')\n",
    "#     plt.legend()\n",
    "#     plt.grid(True)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9891e235",
   "metadata": {},
   "source": [
    "3d plottly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "efccc17d",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# X_train = selected_features\n",
    "# X_train = X_train / np.linalg.norm(X_train, axis=1, keepdims=True)\n",
    "# # Perform T-SNE dimensionality reduction\n",
    "# tsne = TSNE(n_components=3, random_state=42)\n",
    "# X_tsne = tsne.fit_transform(X_train)\n",
    "\n",
    "# # Create a Plotly scatter plot\n",
    "# fig = go.Figure(data=[go.Scatter3d(\n",
    "#     x=X_tsne[:, 0],\n",
    "#     y=X_tsne[:, 1],\n",
    "#     z=X_tsne[:, 2],\n",
    "#     mode='markers',\n",
    "#     marker=dict(\n",
    "#         size=3,\n",
    "#         color=Y_train,  # Assuming Y_train contains labels for coloring\n",
    "#         colorscale='Viridis',  # You can choose a different colorscale\n",
    "#         opacity=0.8\n",
    "#     )\n",
    "# )])\n",
    "\n",
    "# # Update layout\n",
    "# fig.update_layout(title='3D T-SNE Plot', autosize=False,\n",
    "#                   width=800, height=800)\n",
    "\n",
    "# # Show the plot\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ca73f7e2",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Save the plot as an HTML file\n",
    "# pio.write_html(fig, '3d_tsne_plot.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0feaf772",
   "metadata": {},
   "source": [
    "Selected features of train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cd9e733c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT+EGAT\n",
    "# selectedUPrime, BERT_trainIndices = get_selected_features(tensorUtterancesTrain, y_train, 20)\n",
    "# selectedHPrime, GAT_trainIndices1 = get_selected_features(allNodeFeatsTrain, y_train, 20)\n",
    "# concatenatedRepresentationTrain1 = torch.cat((selectedUPrime, selectedHPrime), dim=1)\n",
    "# BERT+GAT\n",
    "# selectedHPrime, GAT_trainIndices2 = get_selected_features(allNodeFeatsTrain, y_train, 20)\n",
    "# concatenatedRepresentationTrain2 = torch.cat((selectedUPrime, selectedHPrime), dim=1)\n",
    "# raw-BERT\n",
    "rawCtxRepresentationTrain = get_norm_features(tensorUtterancesTrain)\n",
    "# selected-BERT\n",
    "# ctxRepresentationTrain = selectedUPrime\n",
    "\n",
    "# raw-BERT+GAT \n",
    "concatenatedRepresentationTrain1 = torch.cat((get_norm_features(tensorUtterancesTrain), \n",
    "                                              get_norm_features(cherryPickedNodesTrain)), dim=1)\n",
    "# raw-BERT+EGAT\n",
    "concatenatedRepresentationTrain2 = torch.cat((get_norm_features(tensorUtterancesTrain), \n",
    "                                              get_norm_features(allNodeFeatsTrain)), dim=1)\n",
    "\n",
    "# print(\"Sizes of different combination of train data\\n\",\n",
    "#       \"FeatureSelected+BERT+EGAT: \", concatenatedRepresentationTrain1.shape, \"\\n\",\n",
    "#       \"FeatureSelected+BERT+GAT: \", concatenatedRepresentationTrain2.shape, \"\\n\",\n",
    "#       \"BERT: \", rawCtxRepresentationTrain.shape, \"\\n\",\n",
    "#       \"FeatureSelected+BERT: \", ctxRepresentationTrain.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8756dd76",
   "metadata": {},
   "source": [
    "Selected features of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "84716dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT+EGAT\n",
    "# selectedUPrime = tensorUtterancesTest[:, BERT_trainIndices]\n",
    "# selectedHPrime = allNodeFeatsTest[:, GAT_trainIndices1]\n",
    "# concatenatedRepresentationTest1 = torch.cat((selectedUPrime, selectedHPrime), dim=1)\n",
    "# BERT+GAT\n",
    "# selectedHPrime = allNodeFeatsTest[:, GAT_trainIndices2]\n",
    "# concatenatedRepresentationTest2 = torch.cat((selectedUPrime, selectedHPrime), dim=1)\n",
    "# raw-BERT\n",
    "rawCtxRepresentationTest = get_norm_features(tensorUtterancesTest)\n",
    "# selected-BERT\n",
    "# ctxRepresentationTest = selectedUPrime\n",
    "# raw-BERT+GAT \n",
    "concatenatedRepresentationTest1 = torch.cat((get_norm_features(tensorUtterancesTest), \n",
    "                                             get_norm_features(cherryPickedNodesTest)), dim=1)\n",
    "# raw-BERT+EGAT\n",
    "concatenatedRepresentationTest2 = torch.cat((get_norm_features(tensorUtterancesTest), \n",
    "                                             get_norm_features(allNodeFeatsTest)), dim=1)\n",
    "\n",
    "# print(\"Sizes of different combination of train data\\n\",\n",
    "#       \"FeatureSelected+BERT+EGAT: \", concatenatedRepresentationTest1.shape, \"\\n\",\n",
    "#       \"FeatureSelected+BERT+GAT: \", concatenatedRepresentationTest2.shape, \"\\n\",\n",
    "#       \"BERT: \", rawCtxRepresentationTest.shape, \"\\n\",\n",
    "#       \"FeatureSelected+BERT: \", ctxRepresentationTest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265dc4c4",
   "metadata": {},
   "source": [
    "1. Prep data - normalize and create data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ebb893e7",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def prep_data(features, labels, isTrain):\n",
    "    num_instances = len(features)\n",
    "    num_classes = 7\n",
    "\n",
    "    # Rescale input features\n",
    "    # selected_features = concatenated_representation / np.linalg.norm(concatenated_representation, axis=1, keepdims=True)\n",
    "\n",
    "    # Apply data resampling (oversampling) to balance class distribution\n",
    "    if isTrain:\n",
    "        X_set, Y_set = oversample_data(features, labels, num_classes)\n",
    "    else:\n",
    "        X_set, Y_set = features, labels\n",
    "\n",
    "    # Calculate class weights for class weighting\n",
    "#     class_counts = np.bincount(labels)\n",
    "#     total_instances = np.sum(class_counts)\n",
    "    # class_weights = torch.tensor([total_instances / (num_classes * count) for count in class_counts], dtype=torch.float32)\n",
    "\n",
    "    # Convert data to PyTorch tensors\n",
    "    X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
    "    Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n",
    "    # print(X_train_tensor.shape, Y_train_tensor.shape)\n",
    "    # X_train_tensor = torch.tensor(selected_features)\n",
    "    # Y_train_tensor = torch.tensor(y_train)\n",
    "\n",
    "    unique_labels, label_counts = np.unique(Y_set, return_counts=True)\n",
    "\n",
    "    # Print the counts for each unique label\n",
    "    for label, count in zip(unique_labels, label_counts):\n",
    "        print(f\"Label {label_decoder[label]}: {count} occurrences\")\n",
    "\n",
    "    print(X_tensor.shape, Y_tensor.shape)\n",
    "    # Create a TensorDataset\n",
    "    dataset = TensorDataset(X_tensor, Y_tensor)\n",
    "\n",
    "    return X_tensor, Y_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861ebf30",
   "metadata": {},
   "source": [
    "2. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9a71c886",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(X_set, Y_set, input_dim, hidden_dim, num_epochs, num_classes):\n",
    "    # Initialize the model\n",
    "    model = MyNetwork(input_dim, hidden_dim, num_classes)\n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "    # Train the model\n",
    "    print_interval = 1  # Print tqdm every epoch\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_instances = 0\n",
    "        # Use tqdm for progress tracking\n",
    "        with tqdm(total=len(X_set), desc=f'Epoch {epoch+1}/{num_epochs}', leave=False) as pbar:\n",
    "            for inputs, labels in zip(X_set, Y_set):\n",
    "                inputs = torch.tensor(inputs.clone().detach(), dtype=torch.float32)\n",
    "                labels = torch.tensor(labels.clone().detach(), dtype=torch.long)\n",
    "                # Forward pass\n",
    "                outputs = model(inputs.unsqueeze(0))  # Add batch dimension\n",
    "                loss = criterion(outputs, labels.unsqueeze(0))  # Add batch dimension to labels\n",
    "\n",
    "                # Backward and optimize\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                total_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct_predictions += (predicted == labels).sum().item()\n",
    "                total_instances += 1\n",
    "                pbar.update(1)\n",
    "\n",
    "        # Print average loss and accuracy per epoch\n",
    "        if (epoch + 1) % print_interval == 0:\n",
    "            epoch_loss = total_loss / total_instances\n",
    "            epoch_accuracy = correct_predictions / total_instances\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}')\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b435c98b",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def classify_emotions(model, X_tensor, Y_tensor, isTrain):\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Predict on the training data\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_tensor)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    # Convert predicted tensor to numpy array\n",
    "    predicted = predicted.numpy()\n",
    "\n",
    "    # Calculate F1 score per class\n",
    "    f1_per_class = f1_score(Y_tensor, predicted, average=None)\n",
    "    f1 = f1_score(Y_tensor, predicted, average='macro')\n",
    "    if isTrain:\n",
    "        print(f'Train F1 Score: {f1:.4f}')\n",
    "    else:\n",
    "        print(f'Test F1 Score: {f1:.4f}')\n",
    "\n",
    "    unique_labels, label_counts = np.unique(predicted, return_counts=True)\n",
    "\n",
    "    # Print F1 score for each class\n",
    "    for i, f1 in enumerate(f1_per_class):\n",
    "        print(f'F1 Score for Class {label_decoder[i]}: {f1:.4f}')\n",
    "\n",
    "    # Print the counts for each unique label\n",
    "    for label, count in zip(unique_labels, label_counts):\n",
    "        print(f\"Label {label_decoder[label]}: {count} occurrences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2b72ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO create table of loss and accuracy during training\n",
    "# TODO also compute the time it takes to complete the train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a14b7b",
   "metadata": {},
   "source": [
    "<h4> Train and validate BERT+EGAT given 50 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "731a5a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_9580\\3259066277.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_9580\\3259066277.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label anger: 1500 occurrences\n",
      "Label disgust: 364 occurrences\n",
      "Label fear: 338 occurrences\n",
      "Label joy: 2312 occurrences\n",
      "Label neutral: 5960 occurrences\n",
      "Label sadness: 876 occurrences\n",
      "Label surprise: 1490 occurrences\n",
      "torch.Size([12840, 1536]) torch.Size([12840])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:   0%|                                                                            | 0/12840 [00:00<?, ?it/s]C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_9580\\3023422335.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs = torch.tensor(inputs.clone().detach(), dtype=torch.float32)\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_9580\\3023422335.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels.clone().detach(), dtype=torch.long)\n",
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 1.6696, Accuracy: 0.4655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50], Loss: 1.5932, Accuracy: 0.5313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50], Loss: 1.5674, Accuracy: 0.5590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50], Loss: 1.5561, Accuracy: 0.5673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50], Loss: 1.5481, Accuracy: 0.5789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50], Loss: 1.5403, Accuracy: 0.5847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/50], Loss: 1.5349, Accuracy: 0.5905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50], Loss: 1.5307, Accuracy: 0.5931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/50], Loss: 1.5273, Accuracy: 0.5961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Loss: 1.5263, Accuracy: 0.5964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/50], Loss: 1.5235, Accuracy: 0.5988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/50], Loss: 1.5223, Accuracy: 0.5978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/50], Loss: 1.5194, Accuracy: 0.6009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/50], Loss: 1.5178, Accuracy: 0.6026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/50], Loss: 1.5170, Accuracy: 0.6051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/50], Loss: 1.5156, Accuracy: 0.6051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/50], Loss: 1.5156, Accuracy: 0.6090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/50], Loss: 1.5121, Accuracy: 0.6071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/50], Loss: 1.5117, Accuracy: 0.6100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/50], Loss: 1.5107, Accuracy: 0.6125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/50], Loss: 1.5088, Accuracy: 0.6142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/50], Loss: 1.5092, Accuracy: 0.6126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/50], Loss: 1.5074, Accuracy: 0.6136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/50], Loss: 1.5051, Accuracy: 0.6151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/50], Loss: 1.5046, Accuracy: 0.6172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/50], Loss: 1.5038, Accuracy: 0.6190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/50], Loss: 1.5024, Accuracy: 0.6206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/50], Loss: 1.5016, Accuracy: 0.6199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/50], Loss: 1.5011, Accuracy: 0.6196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/50], Loss: 1.4999, Accuracy: 0.6198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/50], Loss: 1.4989, Accuracy: 0.6198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/50], Loss: 1.4996, Accuracy: 0.6223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/50], Loss: 1.4984, Accuracy: 0.6217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/50], Loss: 1.4972, Accuracy: 0.6217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/50], Loss: 1.4966, Accuracy: 0.6228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/50], Loss: 1.4972, Accuracy: 0.6251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/50], Loss: 1.4961, Accuracy: 0.6236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/50], Loss: 1.4958, Accuracy: 0.6249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/50], Loss: 1.4949, Accuracy: 0.6249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/50], Loss: 1.4938, Accuracy: 0.6240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/50], Loss: 1.4937, Accuracy: 0.6248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/50], Loss: 1.4935, Accuracy: 0.6280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/50], Loss: 1.4917, Accuracy: 0.6284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/50], Loss: 1.4913, Accuracy: 0.6293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/50], Loss: 1.4900, Accuracy: 0.6301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/50], Loss: 1.4890, Accuracy: 0.6296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/50], Loss: 1.4883, Accuracy: 0.6298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/50], Loss: 1.4871, Accuracy: 0.6314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/50], Loss: 1.4868, Accuracy: 0.6298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/50], Loss: 1.4862, Accuracy: 0.6303\n",
      "Train F1 Score: 0.3182\n",
      "F1 Score for Class anger: 0.4278\n",
      "F1 Score for Class disgust: 0.0000\n",
      "F1 Score for Class fear: 0.0000\n",
      "F1 Score for Class joy: 0.5429\n",
      "F1 Score for Class neutral: 0.7535\n",
      "F1 Score for Class sadness: 0.0000\n",
      "F1 Score for Class surprise: 0.5034\n",
      "Label anger: 917 occurrences\n",
      "Label joy: 2079 occurrences\n",
      "Label neutral: 9010 occurrences\n",
      "Label surprise: 834 occurrences\n"
     ]
    }
   ],
   "source": [
    "X_trainTensor, Y_trainTensor = prep_data(concatenatedRepresentationTrain2, y_train, False)\n",
    "fcClf = model_train(X_set=X_trainTensor, \n",
    "                    Y_set=Y_trainTensor,\n",
    "                    input_dim=X_trainTensor.shape[1], \n",
    "                    hidden_dim=256, \n",
    "                    num_epochs=30, \n",
    "                    num_classes=7)\n",
    "classify_emotions(fcClf, X_trainTensor, Y_trainTensor, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "50c657f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label anger: 516 occurrences\n",
      "Label disgust: 99 occurrences\n",
      "Label fear: 60 occurrences\n",
      "Label joy: 495 occurrences\n",
      "Label neutral: 1615 occurrences\n",
      "Label sadness: 263 occurrences\n",
      "Label surprise: 352 occurrences\n",
      "torch.Size([3400, 1536]) torch.Size([3400])\n",
      "Test F1 Score: 0.1267\n",
      "F1 Score for Class anger: 0.0882\n",
      "F1 Score for Class disgust: 0.0000\n",
      "F1 Score for Class fear: 0.0000\n",
      "F1 Score for Class joy: 0.1500\n",
      "F1 Score for Class neutral: 0.5642\n",
      "F1 Score for Class sadness: 0.0000\n",
      "F1 Score for Class surprise: 0.0849\n",
      "Label anger: 210 occurrences\n",
      "Label joy: 652 occurrences\n",
      "Label neutral: 2348 occurrences\n",
      "Label surprise: 190 occurrences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_9580\\3259066277.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_9580\\3259066277.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n"
     ]
    }
   ],
   "source": [
    "# Predict the test set\n",
    "X_testTensor, Y_testTensor = prep_data(concatenatedRepresentationTest2, y_test, False)\n",
    "classify_emotions(fcClf, X_testTensor, Y_testTensor, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e94626",
   "metadata": {},
   "source": [
    "<h4> Train and validate BERT+GAT given 2 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "57c145a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_9580\\3259066277.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_9580\\3259066277.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label anger: 1500 occurrences\n",
      "Label disgust: 364 occurrences\n",
      "Label fear: 338 occurrences\n",
      "Label joy: 2312 occurrences\n",
      "Label neutral: 5960 occurrences\n",
      "Label sadness: 876 occurrences\n",
      "Label surprise: 1490 occurrences\n",
      "torch.Size([12840, 1536]) torch.Size([12840])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3:   0%|                                                                             | 0/12840 [00:00<?, ?it/s]C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_9580\\3023422335.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs = torch.tensor(inputs.clone().detach(), dtype=torch.float32)\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_9580\\3023422335.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels.clone().detach(), dtype=torch.long)\n",
      "                                                                                                                       \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [100]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m X_trainTensor, Y_trainTensor \u001b[38;5;241m=\u001b[39m prep_data(concatenatedRepresentationTrain1, y_train, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m----> 2\u001b[0m fcClf \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_trainTensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mY_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mY_trainTensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                    \u001b[49m\u001b[43minput_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_trainTensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mhidden_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m classify_emotions(fcClf, X_trainTensor, Y_trainTensor, \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Input \u001b[1;32mIn [85]\u001b[0m, in \u001b[0;36mmodel_train\u001b[1;34m(X_set, Y_set, input_dim, hidden_dim, num_epochs, num_classes)\u001b[0m\n\u001b[0;32m     23\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     24\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 25\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     28\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\optimizer.py:373\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    368\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    369\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    370\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    371\u001b[0m             )\n\u001b[1;32m--> 373\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    374\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    376\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\adam.py:163\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    152\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    155\u001b[0m         group,\n\u001b[0;32m    156\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    160\u001b[0m         max_exp_avg_sqs,\n\u001b[0;32m    161\u001b[0m         state_steps)\n\u001b[1;32m--> 163\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\adam.py:311\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    309\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 311\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    327\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\adam.py:385\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[0;32m    384\u001b[0m exp_avg\u001b[38;5;241m.\u001b[39mlerp_(grad, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1)\n\u001b[1;32m--> 385\u001b[0m \u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddcmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconj\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m capturable \u001b[38;5;129;01mor\u001b[39;00m differentiable:\n\u001b[0;32m    388\u001b[0m     step \u001b[38;5;241m=\u001b[39m step_t\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_trainTensor, Y_trainTensor = prep_data(concatenatedRepresentationTrain1, y_train, True)\n",
    "fcClf = model_train(X_set=X_trainTensor, \n",
    "                    Y_set=Y_trainTensor,\n",
    "                    input_dim=X_trainTensor.shape[1], \n",
    "                    hidden_dim=256, \n",
    "                    num_epochs=3, \n",
    "                    num_classes=7)\n",
    "classify_emotions(fcClf, X_trainTensor, Y_trainTensor, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5aa10a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label anger: 516 occurrences\n",
      "Label disgust: 99 occurrences\n",
      "Label fear: 60 occurrences\n",
      "Label joy: 495 occurrences\n",
      "Label neutral: 1615 occurrences\n",
      "Label sadness: 263 occurrences\n",
      "Label surprise: 352 occurrences\n",
      "torch.Size([3400, 1536]) torch.Size([3400])\n",
      "Test F1 Score: 0.1289\n",
      "F1 Score for Class anger: 0.1142\n",
      "F1 Score for Class disgust: 0.0000\n",
      "F1 Score for Class fear: 0.0000\n",
      "F1 Score for Class joy: 0.1230\n",
      "F1 Score for Class neutral: 0.5940\n",
      "F1 Score for Class sadness: 0.0000\n",
      "F1 Score for Class surprise: 0.0713\n",
      "Label anger: 237 occurrences\n",
      "Label joy: 367 occurrences\n",
      "Label neutral: 2671 occurrences\n",
      "Label surprise: 125 occurrences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_9580\\3259066277.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_9580\\3259066277.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n"
     ]
    }
   ],
   "source": [
    "# Predict the test set\n",
    "X_testTensor, Y_testTensor = prep_data(concatenatedRepresentationTest1, y_test, False)\n",
    "classify_emotions(fcClf, X_testTensor, Y_testTensor, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5dc686",
   "metadata": {},
   "source": [
    "<h4> Train and validate BERT (x feature selection) given 2 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "665f4578",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_9580\\3259066277.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_9580\\3259066277.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label anger: 1500 occurrences\n",
      "Label disgust: 364 occurrences\n",
      "Label fear: 338 occurrences\n",
      "Label joy: 2312 occurrences\n",
      "Label neutral: 5960 occurrences\n",
      "Label sadness: 876 occurrences\n",
      "Label surprise: 1490 occurrences\n",
      "torch.Size([12840, 768]) torch.Size([12840])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:   0%|                                                                             | 0/12840 [00:00<?, ?it/s]C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_9580\\3023422335.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs = torch.tensor(inputs.clone().detach(), dtype=torch.float32)\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_9580\\3023422335.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels.clone().detach(), dtype=torch.long)\n",
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 1.6455, Accuracy: 0.4814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5], Loss: 1.5698, Accuracy: 0.5593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5], Loss: 1.5531, Accuracy: 0.5776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5], Loss: 1.5454, Accuracy: 0.5844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5], Loss: 1.5399, Accuracy: 0.5887\n",
      "Train F1 Score: 0.1568\n",
      "F1 Score for Class anger: 0.1164\n",
      "F1 Score for Class disgust: 0.0000\n",
      "F1 Score for Class fear: 0.0000\n",
      "F1 Score for Class joy: 0.2452\n",
      "F1 Score for Class neutral: 0.6594\n",
      "F1 Score for Class sadness: 0.0000\n",
      "F1 Score for Class surprise: 0.0766\n",
      "Label anger: 184 occurrences\n",
      "Label joy: 526 occurrences\n",
      "Label neutral: 12054 occurrences\n",
      "Label surprise: 76 occurrences\n"
     ]
    }
   ],
   "source": [
    "X_trainTensor, Y_trainTensor = prep_data(rawCtxRepresentationTrain, y_train, False)\n",
    "fcClf = model_train(X_set=X_trainTensor, \n",
    "                    Y_set=Y_trainTensor,\n",
    "                    input_dim=X_trainTensor.shape[1], \n",
    "                    hidden_dim=256, \n",
    "                    num_epochs=5, \n",
    "                    num_classes=7)\n",
    "classify_emotions(fcClf, X_trainTensor, Y_trainTensor, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "052cd879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label anger: 516 occurrences\n",
      "Label disgust: 99 occurrences\n",
      "Label fear: 60 occurrences\n",
      "Label joy: 495 occurrences\n",
      "Label neutral: 1615 occurrences\n",
      "Label sadness: 263 occurrences\n",
      "Label surprise: 352 occurrences\n",
      "torch.Size([3400, 768]) torch.Size([3400])\n",
      "Test F1 Score: 0.1132\n",
      "F1 Score for Class anger: 0.0524\n",
      "F1 Score for Class disgust: 0.0000\n",
      "F1 Score for Class fear: 0.0000\n",
      "F1 Score for Class joy: 0.1091\n",
      "F1 Score for Class neutral: 0.6159\n",
      "F1 Score for Class sadness: 0.0000\n",
      "F1 Score for Class surprise: 0.0153\n",
      "Label anger: 95 occurrences\n",
      "Label joy: 275 occurrences\n",
      "Label neutral: 2990 occurrences\n",
      "Label surprise: 40 occurrences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_9580\\3259066277.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X_set.clone().detach(), dtype=torch.float32).clone().detach()\n",
      "C:\\Users\\edayo\\AppData\\Local\\Temp\\ipykernel_9580\\3259066277.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y_set.clone().detach(), dtype=torch.long).clone().detach()\n"
     ]
    }
   ],
   "source": [
    "# Predict the test set\n",
    "X_testTensor, Y_testTensor = prep_data(rawCtxRepresentationTest, y_test, False)\n",
    "classify_emotions(fcClf, X_testTensor, Y_testTensor, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cac86ff",
   "metadata": {},
   "source": [
    "<h4> Train and validate BERT (o feature selection) given 2 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3189c7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataLoader, X_trainTensor, Y_trainTensor = get_data_loader(ctxRepresentationTrain, y_train, True)\n",
    "# # TODO 3rd argument is tunable\n",
    "# fcClf = model_train(dataLoader, \n",
    "#                     input_dim=X_trainTensor.shape[1], \n",
    "#                     output_dim=50, \n",
    "#                     num_epochs=2, \n",
    "#                     num_classes=7)\n",
    "# classify_emotions(fcClf, X_trainTensor, Y_trainTensor, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1847bae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Predict the test set\n",
    "# _, X_testTensor, Y_testTensor = get_data_loader(ctxRepresentationTest, y_test, False)\n",
    "# classify_emotions(fcClf, X_testTensor, Y_testTensor, False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
