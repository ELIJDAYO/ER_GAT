{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35a857cc",
   "metadata": {},
   "source": [
    "\"FC layers referenced from https://towardsdatascience.com/math-neural-network-from-scratch-in-python-d6da9f29ce65\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "176f72e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, precision_recall_fscore_support\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, chi2\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import plotly.graph_objs as go\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.io as pio\n",
    "from sklearn.utils import class_weight\n",
    "import tqdm as notebook_tqdm\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cebd6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a4fb045",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCLayer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(FCLayer, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "class ActivationLayer(nn.Module):\n",
    "    def __init__(self, activation_fn):\n",
    "        super(ActivationLayer, self).__init__()\n",
    "        self.activation_fn = activation_fn\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation_fn(x)\n",
    "        return x\n",
    "\n",
    "def tanh(x):\n",
    "    return torch.tanh(x)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return torch.sigmoid(x)\n",
    "\n",
    "class MyNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(MyNetwork, self).__init__()\n",
    "        self.fc1 = FCLayer(input_dim, hidden_dim)\n",
    "        self.activation1 = ActivationLayer(tanh)\n",
    "        self.fc2 = FCLayer(hidden_dim, output_dim)\n",
    "        self.activation2 = ActivationLayer(sigmoid)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.activation1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.activation2(x)\n",
    "        return x\n",
    "\n",
    "# loss function and its derivative\n",
    "def mse(y_true, y_pred):\n",
    "    return np.mean(np.power(y_true - y_pred, 2))\n",
    "\n",
    "def mse_prime(y_true, y_pred):\n",
    "    return 2 * (y_pred - y_true) / y_true.size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "246bf76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to balance class distribution using oversampling\n",
    "def oversample_data(X_train, Y_train):\n",
    "    # Determine the class with the maximum number of instances\n",
    "    max_class_count = np.max(np.bincount(Y_train))\n",
    "    # Generate indices for oversampling each class\n",
    "    indices_list = [np.where(Y_train == i)[0] for i in range(num_classes)]\n",
    "    # Oversample minority classes to match the count of the majority class\n",
    "    for i, indices in enumerate(indices_list):\n",
    "        if len(indices) < max_class_count:\n",
    "            oversampled_indices = np.random.choice(indices, size=max_class_count - len(indices), replace=True)\n",
    "            X_train = np.concatenate((X_train, X_train[oversampled_indices]), axis=0)\n",
    "            Y_train = np.concatenate((Y_train, Y_train[oversampled_indices]), axis=0)\n",
    "    return X_train, Y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72c216ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading files\n",
    "checkFile = os.path.isfile(\"data/dump/train_labels.pkl\")\n",
    "\n",
    "if not checkFile:\n",
    "    print(\"Please run the context_encoder notebook to save label file\")\n",
    "    \n",
    "else:\n",
    "    file = open('data/dump/train_labels.pkl', 'rb')\n",
    "    y_train = pickle.load(file)\n",
    "    y_train = torch.tensor(y_train)\n",
    "    file.close()\n",
    "    \n",
    "file = open('data/dump/label_decoder.pkl', 'rb')\n",
    "label_decoder = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e3426c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12840, 300]) torch.Size([12840, 300])\n"
     ]
    }
   ],
   "source": [
    "# loading files 2\n",
    "file_path = 'embed/updated_representation.pkl'\n",
    "\n",
    "# Load the list from the file using pickle\n",
    "with open(file_path, 'rb') as file:\n",
    "    updated_representations = pickle.load(file)\n",
    "\n",
    "    # Concatenate all the tensors representing individual utterances\n",
    "    concatenated_tensors = []\n",
    "    for dialogue_tensor in updated_representations:\n",
    "        concatenated_tensors.extend(dialogue_tensor)\n",
    "\n",
    "# Convert the concatenated list of tensors into a single tensor\n",
    "tensor_utterances = torch.stack(concatenated_tensors)\n",
    "\n",
    "checkFile = os.path.isfile(\"data/dump/1st_gat.pkl\")\n",
    "if not checkFile:\n",
    "    print(\"Run relation-type encoder before running classifier\")\n",
    "    \n",
    "else:\n",
    "    file = open('data/dump/1st_gat.pkl', 'rb')\n",
    "    cherry_picked_nodes, _ = pickle.load(file)\n",
    "    file.close()\n",
    "\n",
    "checkFile = os.path.isfile(\"data/dump/2nd_gat.pkl\")\n",
    "if not checkFile:\n",
    "    print(\"Run relation-type encoder before running classifier\")\n",
    "    \n",
    "else:\n",
    "    file = open('data/dump/2nd_gat.pkl', 'rb')\n",
    "    all_node_feats, _ = pickle.load(file)\n",
    "    file.close()\n",
    "    \n",
    "_ = None\n",
    "print(cherry_picked_nodes.shape, all_node_feats.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875e7687",
   "metadata": {},
   "source": [
    "EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e174164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Checking the structure of graph\n",
    "# for n in range(10):\n",
    "#     tensor_data_np = tensor_utterances[n].detach().numpy()\n",
    "\n",
    "#     # Plot the data\n",
    "#     plt.figure(figsize=(10, 5))\n",
    "#     plt.plot(range(len(tensor_data_np)), tensor_data_np)\n",
    "#     plt.title('Line Graph of Tensor Data')\n",
    "#     plt.xlabel('Index')\n",
    "#     plt.ylabel('Value')\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "479a3b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Normalize the h' (1st GAT)\n",
    "# data = cherry_picked_nodes.detach().numpy()\n",
    "# data_normalized = data / np.linalg.norm(data, axis=1, keepdims=True)\n",
    "\n",
    "# # Compute pairwise cosine similarities\n",
    "# similarities = cosine_similarity(data_normalized)\n",
    "\n",
    "# # Print or analyze the similarity matrix\n",
    "# # print(similarities)\n",
    "# plt.hist(similarities.flatten(), bins=50, density=True)\n",
    "# plt.title('Distribution of Cosine Similarities')\n",
    "# plt.xlabel('Cosine Similarity')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a070ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Normalize the h' (2nd GAT)\n",
    "# data = all_node_feats.detach().numpy()\n",
    "# data_normalized = data / np.linalg.norm(data, axis=1, keepdims=True)\n",
    "\n",
    "# # Compute pairwise cosine similarities\n",
    "# similarities = cosine_similarity(data_normalized)\n",
    "\n",
    "# # Print or analyze the similarity matrix\n",
    "# # print(similarities)\n",
    "# plt.hist(similarities.flatten(), bins=50, density=True)\n",
    "# plt.title('Distribution of Cosine Similarities')\n",
    "# plt.xlabel('Cosine Similarity')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a43fa315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Normalize the u' or updated_representations\n",
    "# data = tensor_utterances.detach().numpy()\n",
    "# data_normalized = data / np.linalg.norm(data, axis=1, keepdims=True)\n",
    "\n",
    "# # Compute pairwise cosine similarities\n",
    "# similarities = cosine_similarity(data_normalized)\n",
    "\n",
    "# plt.hist(similarities.flatten(), bins=50, density=True)\n",
    "# plt.title('Distribution of Cosine Similarities')\n",
    "# plt.xlabel('Cosine Similarity')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40320052",
   "metadata": {},
   "source": [
    "Prep data and EDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c909e8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tensor_utterances\n",
    "Y_train = y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510f143f",
   "metadata": {},
   "source": [
    "Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "caf09478",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# # Define the number of features (k) to select\n",
    "# k = 100  # Adjust this value as needed\n",
    "\n",
    "# # Initialize SelectKBest with the desired score function (e.g., f_classif for classification tasks)\n",
    "# selector = SelectKBest(score_func=f_classif, k=k)\n",
    "\n",
    "# # Fit SelectKBest on the training data and target variable\n",
    "# selector.fit(X_train, Y_train)\n",
    "\n",
    "# # Get the indices of the selected features\n",
    "# selected_indices = selector.get_support(indices=True)\n",
    "\n",
    "# # Get the scores of the selected features\n",
    "# feature_scores = selector.scores_[selected_indices]\n",
    "\n",
    "# # Display the scores along with their corresponding indices\n",
    "# # for idx, score in zip(selected_indices, feature_scores):\n",
    "# #     print(f\"Feature index: {idx}, Score: {score}\")\n",
    "\n",
    "# X_train_selected = X_train[:, selected_indices]\n",
    "# print(X_train_selected.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0264084c",
   "metadata": {},
   "source": [
    "Selected feature u'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6501b577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label anger: idx 136, 172, 268, 15, 115, 114, 92, 79, 5, 30, 11, 39, 63, 48, 116, 54, 46, 29, 126, 73\n",
      "[3.1583449  3.1658403  3.26870161 3.30502297 3.36981681 3.50353464\n",
      " 3.61726079 3.66916384 3.80734836 4.42814906 4.815598   4.96967837\n",
      " 5.15128943 5.49479333 5.76961121 6.13670325 6.37304263 6.70896888\n",
      " 7.08513609 7.24567632]\n",
      "Label fear: idx 207, 29, 201, 126, 209, 188, 39, 173, 131, 11, 54, 152, 235, 134, 266, 28, 268, 41, 88, 140\n",
      "[0.73271283 0.73879169 0.74346923 0.78549551 0.85724577 0.89225648\n",
      " 0.90074511 0.91654341 0.94887727 0.9653221  0.99217627 0.99945618\n",
      " 1.04076324 1.09991743 1.14010272 1.15816903 1.24364936 1.27709152\n",
      " 1.34091566 1.77393706]\n",
      "Label neutral: idx 114, 131, 42, 3, 18, 46, 156, 2, 32, 79, 39, 11, 134, 148, 202, 57, 116, 54, 140, 248\n",
      "[1.05383006 1.06984748 1.1120533  1.13951188 1.19099611 1.20606924\n",
      " 1.21872104 1.21980425 1.28606865 1.30701102 1.32600717 1.36228032\n",
      " 1.36633109 1.38971465 1.46947126 1.52682526 1.58884734 1.97915876\n",
      " 2.19278263 2.44663865]\n",
      "Label sadness: idx 140, 268, 279, 131, 34, 15, 63, 126, 42, 46, 127, 134, 54, 79, 73, 82, 70, 48, 11, 83\n",
      "[3.52780989 3.56712423 3.57009387 3.5896056  3.64744078 3.86619171\n",
      " 3.92980138 3.98185638 4.0227575  4.15440739 4.18433381 4.61746688\n",
      " 4.74501621 4.8856863  5.21887603 5.49248246 5.66013131 6.02570333\n",
      " 7.44190488 7.64600595]\n",
      "Label surprise: idx 279, 188, 82, 34, 152, 46, 207, 103, 126, 166, 79, 127, 48, 268, 73, 83, 15, 63, 172, 11\n",
      "[3.79399546 3.92527458 3.93473026 4.13555094 4.14364834 4.35439597\n",
      " 4.49684685 4.50879278 4.56744226 5.02610719 5.27364562 5.32486921\n",
      " 5.64362372 5.8714134  5.89737345 6.12177194 6.75746917 7.22622412\n",
      " 8.30099331 9.34077076]\n",
      "Label joy: idx 139, 47, 144, 70, 203, 12, 197, 46, 28, 39, 5, 48, 115, 54, 30, 116, 126, 29, 34, 73\n",
      "[0.97961912 0.9819931  0.98346562 0.99251104 1.00188779 1.00332396\n",
      " 1.04342859 1.06930058 1.2184349  1.26713047 1.31488088 1.41373191\n",
      " 1.46046531 1.51856004 1.60091223 1.84993153 1.86989043 1.99120679\n",
      " 2.01949504 2.17393671]\n",
      "Label disgust: idx 273, 63, 172, 186, 279, 54, 15, 127, 46, 83, 114, 208, 103, 126, 11, 202, 116, 79, 73, 48\n",
      "[0.87904151 0.87934384 0.88654776 0.88800977 0.89090272 0.93045567\n",
      " 0.95839309 1.05532108 1.075711   1.09254482 1.16867863 1.26946065\n",
      " 1.28700246 1.34017729 1.34192662 1.35325989 1.42715319 1.45833175\n",
      " 1.46617287 1.87547456]\n"
     ]
    }
   ],
   "source": [
    "# Apply Min-Max scaling to make the data non-negative\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Initialize SelectKBest with the desired score function (e.g., f_classif for classification tasks)\n",
    "selector = SelectKBest(score_func=f_classif, k=100)\n",
    "# Assuming X_train is your feature matrix (12840 instances x 300 dimensions)\n",
    "# and y_train is your target labels\n",
    "\n",
    "# Initialize a dictionary to store the indices of top features for each class\n",
    "top_features_by_class = {}\n",
    "top_scores = {}\n",
    "# Calculate the relevance of each feature to each class using chi-squared test\n",
    "for label in range(7):  # Assuming you have 7 classes\n",
    "    # Create a binary mask indicating instances belonging to the current class\n",
    "    mask = (Y_train == label)\n",
    "\n",
    "    # SelectKBest with chi2 as the scoring function\n",
    "    selector = SelectKBest(score_func=chi2, k=20)  # Select top 20 features\n",
    "    selector.fit(X_train_scaled, mask)  # Fit SelectKBest to the data\n",
    "    # Get the indices of the top 20 features\n",
    "    top_features_indices = np.argsort(selector.scores_)[-20:]\n",
    "    scores = selector.scores_[top_features_indices]\n",
    "    # Store the indices in the dictionary\n",
    "    top_features_by_class[label] = top_features_indices\n",
    "    top_scores[label] = scores\n",
    "    \n",
    "# Print the top features for each class\n",
    "for label, indices in top_features_by_class.items():\n",
    "    print(f\"Label {label_decoder[label]}: idx {', '.join(map(str, indices))}\")\n",
    "    print(top_scores[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "997102e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_features_set = set()\n",
    "for label, indices in top_features_by_class.items():\n",
    "    concatenated_features_set.update(indices)\n",
    "\n",
    "concatenated_features_indices = list(concatenated_features_set)\n",
    "\n",
    "# concatenated_features_indices = []\n",
    "# for indices in top_features_by_class.values():\n",
    "#     concatenated_features_indices.extend(indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "018bc3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12840, 61])\n"
     ]
    }
   ],
   "source": [
    "concatenated_features_indices = np.array(concatenated_features_indices)\n",
    "\n",
    "# Select the desired features from X_train\n",
    "selected_features1 = tensor_utterances[:, concatenated_features_indices]\n",
    "print(selected_features1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1af030",
   "metadata": {},
   "source": [
    "Selected h'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74744ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = all_node_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13cad676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label anger: idx 211, 201, 57, 222, 246, 173, 36, 117, 174, 273, 282, 210, 212, 215, 140, 45, 284, 113, 11, 31\n",
      "[2.13455972 2.15251128 2.15499232 2.22266763 2.2649745  2.27897326\n",
      " 2.29728324 2.31104255 2.33724553 2.55868147 2.57201992 2.71197793\n",
      " 2.72490873 3.02564703 3.1079814  3.52187924 3.52235189 3.55939197\n",
      " 3.63854927 4.08898715]\n",
      "Label fear: idx 117, 71, 52, 170, 11, 211, 122, 164, 284, 51, 292, 282, 215, 67, 31, 193, 19, 174, 222, 113\n",
      "[0.55934097 0.56656762 0.57127437 0.60608704 0.65224372 0.65668475\n",
      " 0.66614341 0.66914212 0.68621878 0.69066966 0.70170609 0.72912575\n",
      " 0.73839261 0.76271454 0.76857636 0.77391966 0.78695672 0.93910621\n",
      " 1.05312072 1.07342212]\n",
      "Label neutral: idx 5, 184, 66, 33, 274, 249, 59, 17, 62, 178, 154, 113, 45, 282, 173, 32, 140, 31, 11, 222\n",
      "[0.82560005 0.83252277 0.83983303 0.85075594 0.8595786  0.93403658\n",
      " 0.94532112 0.98889631 0.98916552 0.99180731 1.02903966 1.0591744\n",
      " 1.20437622 1.21701026 1.30554228 1.4180458  1.52794885 1.54705168\n",
      " 1.73757364 1.89988713]\n",
      "Label sadness: idx 2, 211, 169, 61, 45, 113, 32, 81, 67, 134, 140, 292, 71, 267, 284, 274, 164, 282, 31, 222\n",
      "[2.30689212 2.38877497 2.41916233 2.51842951 2.53782773 2.5926259\n",
      " 2.61028582 2.69746376 2.79533255 2.81905542 2.92811834 3.06990278\n",
      " 3.3589677  3.61218337 3.61661364 3.73577953 3.73578629 4.12729554\n",
      " 4.79667944 5.92733008]\n",
      "Label surprise: idx 99, 169, 203, 45, 213, 267, 282, 248, 139, 81, 164, 299, 67, 298, 21, 113, 140, 19, 71, 31\n",
      "[1.46776387 1.50823927 1.53238452 1.53572899 1.54076456 1.57133567\n",
      " 1.58639984 1.62744924 1.64054063 1.64581993 1.65912312 1.6652446\n",
      " 1.70392113 1.84275633 2.05694434 2.29784066 2.37160922 2.40308728\n",
      " 2.48759338 2.61795496]\n",
      "Label joy: idx 45, 36, 163, 134, 31, 285, 2, 241, 104, 164, 237, 215, 210, 46, 117, 212, 193, 175, 284, 174\n",
      "[0.91492168 0.97878886 0.98555113 0.98648269 0.99174343 1.03632008\n",
      " 1.04412994 1.08523894 1.17450701 1.17615583 1.23726538 1.25514352\n",
      " 1.26530159 1.39406385 1.52614509 1.59990985 1.76059411 1.84537397\n",
      " 2.10470559 2.13946882]\n",
      "Label disgust: idx 249, 32, 17, 70, 113, 29, 282, 268, 11, 252, 197, 216, 253, 210, 173, 26, 71, 31, 140, 45\n",
      "[0.70844912 0.70922258 0.722197   0.72852605 0.75418961 0.75954453\n",
      " 0.778309   0.82486047 0.85108998 0.8597575  0.8738188  0.90067159\n",
      " 0.95160666 0.9667907  1.0155531  1.03087528 1.14896134 1.16436228\n",
      " 1.32269258 1.49360514]\n"
     ]
    }
   ],
   "source": [
    "# Apply Min-Max scaling to make the data non-negative\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Initialize SelectKBest with the desired score function (e.g., f_classif for classification tasks)\n",
    "selector = SelectKBest(score_func=f_classif, k=100)\n",
    "# Assuming X_train is your feature matrix (12840 instances x 300 dimensions)\n",
    "# and y_train is your target labels\n",
    "\n",
    "# Initialize a dictionary to store the indices of top features for each class\n",
    "top_features_by_class = {}\n",
    "top_scores = {}\n",
    "# Calculate the relevance of each feature to each class using chi-squared test\n",
    "for label in range(7):  # Assuming you have 7 classes\n",
    "    # Create a binary mask indicating instances belonging to the current class\n",
    "    mask = (Y_train == label)\n",
    "\n",
    "    # SelectKBest with chi2 as the scoring function\n",
    "    selector = SelectKBest(score_func=chi2, k=20)  # Select top 20 features\n",
    "    selector.fit(X_train_scaled, mask)  # Fit SelectKBest to the data\n",
    "    # Get the indices of the top 20 features\n",
    "    top_features_indices = np.argsort(selector.scores_)[-20:]\n",
    "    scores = selector.scores_[top_features_indices]\n",
    "    # Store the indices in the dictionary\n",
    "    top_features_by_class[label] = top_features_indices\n",
    "    top_scores[label] = scores\n",
    "    \n",
    "# Print the top features for each class\n",
    "for label, indices in top_features_by_class.items():\n",
    "    print(f\"Label {label_decoder[label]}: idx {', '.join(map(str, indices))}\")\n",
    "    print(top_scores[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b5d8c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_features_set = set()\n",
    "for label, indices in top_features_by_class.items():\n",
    "    concatenated_features_set.update(indices)\n",
    "\n",
    "concatenated_features_indices = list(concatenated_features_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37ad95c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12840, 71])\n"
     ]
    }
   ],
   "source": [
    "concatenated_features_indices = np.array(concatenated_features_indices)\n",
    "\n",
    "# Select the desired features from X_train\n",
    "selected_features2 = tensor_utterances[:, concatenated_features_indices]\n",
    "print(selected_features2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca3e54f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0008, -0.0238,  0.0514,  0.0302,  0.0129,  0.0094,  0.0147,  0.0397,\n",
       "        -0.1129,  0.0126, -0.0077,  0.0231, -0.0504,  0.0199, -0.0146,  0.0088,\n",
       "         0.0034,  0.0209, -0.0678, -0.0067, -0.0448,  0.0393,  0.0117,  0.0035,\n",
       "        -0.0213,  0.0123,  0.0290, -0.0074,  0.0315, -0.0259,  0.0545,  0.0257,\n",
       "        -0.0372, -0.0385,  0.0625, -0.0148,  0.0632,  0.0496,  0.0337,  0.0311,\n",
       "        -0.0082, -0.0564,  0.0866,  0.0339,  0.0394, -0.0050,  0.0256,  0.1272,\n",
       "         0.0153,  0.0405,  0.0374,  0.0274,  0.0806,  0.0091,  0.0531,  0.0391,\n",
       "         0.0323, -0.0449, -0.0175,  0.0234,  0.0116])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc72c402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0008,  0.0302,  0.0129,  0.0397,  0.0126,  0.0098, -0.0077, -0.1129,\n",
       "         0.0088, -0.0412, -0.0405, -0.0191,  0.0043,  0.0231,  0.0653,  0.0297,\n",
       "        -0.0202, -0.0448, -0.0076,  0.0035, -0.0020, -0.0112,  0.0239, -0.0224,\n",
       "         0.0887, -0.0495, -0.0144,  0.0282, -0.0287, -0.0410,  0.0545, -0.0296,\n",
       "         0.0248,  0.0257,  0.0510,  0.0227, -0.0083,  0.0191,  0.0006, -0.0148,\n",
       "        -0.0038, -0.0032,  0.0138, -0.0421,  0.0056,  0.0069,  0.0311, -0.0082,\n",
       "         0.0106,  0.0866,  0.0394, -0.0208, -0.0058,  0.0151, -0.0192, -0.0533,\n",
       "        -0.0043,  0.0827, -0.0217, -0.0266,  0.0263, -0.0332,  0.0436,  0.0509,\n",
       "        -0.0261, -0.0588, -0.0175,  0.0046,  0.0074,  0.0086, -0.0266])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "46d79a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca = PCA(n_components=2)\n",
    "# pca_result = pca.fit_transform(selected_features.detach().numpy())\n",
    "\n",
    "# # Plot the PCA result with color-coded labels\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# for label in np.unique(Y_train):\n",
    "#     indices = Y_train == label\n",
    "#     plt.scatter(pca_result[indices, 0], pca_result[indices, 1], label=f'{label_decoder[label]}', alpha=0.5)\n",
    "#     plt.title('PCA Visualization of Selected Utterance Embeddings (Train) with Color-Coded Labels')\n",
    "#     plt.xlabel('Principal Component 1')\n",
    "#     plt.ylabel('Principal Component 2')\n",
    "#     plt.legend()\n",
    "#     plt.grid(True)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9891e235",
   "metadata": {},
   "source": [
    "3d plottly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "efccc17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = selected_features\n",
    "# X_train = X_train / np.linalg.norm(X_train, axis=1, keepdims=True)\n",
    "# # Perform T-SNE dimensionality reduction\n",
    "# tsne = TSNE(n_components=3, random_state=42)\n",
    "# X_tsne = tsne.fit_transform(X_train)\n",
    "\n",
    "# # Create a Plotly scatter plot\n",
    "# fig = go.Figure(data=[go.Scatter3d(\n",
    "#     x=X_tsne[:, 0],\n",
    "#     y=X_tsne[:, 1],\n",
    "#     z=X_tsne[:, 2],\n",
    "#     mode='markers',\n",
    "#     marker=dict(\n",
    "#         size=3,\n",
    "#         color=Y_train,  # Assuming Y_train contains labels for coloring\n",
    "#         colorscale='Viridis',  # You can choose a different colorscale\n",
    "#         opacity=0.8\n",
    "#     )\n",
    "# )])\n",
    "\n",
    "# # Update layout\n",
    "# fig.update_layout(title='3D T-SNE Plot', autosize=False,\n",
    "#                   width=800, height=800)\n",
    "\n",
    "# # Show the plot\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca73f7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the plot as an HTML file\n",
    "# pio.write_html(fig, '3d_tsne_plot.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0feaf772",
   "metadata": {},
   "source": [
    "Selected feature's GAT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f9b3b4",
   "metadata": {},
   "source": [
    "current progress (9pm March 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cd9e733c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12840, 132])\n"
     ]
    }
   ],
   "source": [
    "# Assuming cnn_bilstm_representations and gat_representations are PyTorch tensors\n",
    "concatenated_representation = torch.cat((selected_features1, selected_features2), dim=1)\n",
    "\n",
    "# concatenated_representation1 = torch.cat((tensor_utterances, cherry_picked_nodes), dim=1)\n",
    "#  concatenated_representation2 = torch.cat((cherry_picked_nodes, all_node_feats), dim=1)\n",
    "print(concatenated_representation.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1cb6e9",
   "metadata": {},
   "source": [
    "Training and predicting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632daa54",
   "metadata": {},
   "source": [
    "1st version (only feature engineering and u')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc4cf2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(selected_features.shape)\n",
    "# # Generate sample data\n",
    "# num_instances = len(selected_features)\n",
    "# input_dim = selected_features.shape[1]\n",
    "# num_classes = 7\n",
    "\n",
    "# X_train = selected_features\n",
    "# X_train = X_train / np.linalg.norm(X_train, axis=1, keepdims=True)\n",
    "# Y_train = y_train\n",
    "# # X_train = torch.randn(num_instances, input_dim)\n",
    "# # Assuming Y_train is a vector containing the label indices (0 to num_classes-1) for each instance\n",
    "# # Y_train = torch.randint(0, num_classes, (num_instances,))\n",
    "\n",
    "# # Calculate class weights to balance the loss function\n",
    "# class_counts = torch.bincount(Y_train)\n",
    "# # class_weights = torch.tensor([0.15, 0.03, 0.20, 0.09, 0.15, 0.23, 0.04])\n",
    "\n",
    "# # Initialize the model\n",
    "# model = MyNetwork(input_dim, 7, num_classes)\n",
    "# print(model)\n",
    "# # Define loss function and optimizer\n",
    "# criterion = nn.CrossEntropyLoss(weight=None)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# # Train the model\n",
    "# num_epochs = 3000\n",
    "# for epoch in range(num_epochs):\n",
    "#     # Forward pass\n",
    "#     outputs = model(X_train)\n",
    "#     loss = criterion(outputs, Y_train)\n",
    "\n",
    "#     # Backward and optimize\n",
    "#     optimizer.zero_grad()\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "\n",
    "#     if (epoch+1) % 100 == 0:  # Reduced printing frequency for faster training progress monitoring\n",
    "#         print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fde7f6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Predict on the training data\n",
    "# with torch.no_grad():\n",
    "#     outputs = model(X_train)\n",
    "#     _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "# # Calculate accuracy\n",
    "# accuracy = (predicted == Y_train).sum().item() / num_instances\n",
    "# print(f'Training Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# unique_labels, label_counts = np.unique(predicted, return_counts=True)\n",
    "\n",
    "# # Print the counts for each unique label\n",
    "# for label, count in zip(unique_labels, label_counts):\n",
    "#     print(f\"Label {label}: {count} occurrences\")\n",
    "# print(\"------------------------\")\n",
    "\n",
    "# unique_labels, label_counts = np.unique(Y_train, return_counts=True)\n",
    "\n",
    "# # Print the counts for each unique label\n",
    "# for label, count in zip(unique_labels, label_counts):\n",
    "#     print(f\"Label {label}: {count} occurrences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4795946",
   "metadata": {},
   "source": [
    "2nd version (feature engineered u', class weighting, data resampling, cost-sensitive learning, regularization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265dc4c4",
   "metadata": {},
   "source": [
    "1. Prep data - normalize and create data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ebb893e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 0: 5960 occurrences\n",
      "Label 1: 5960 occurrences\n",
      "Label 2: 5960 occurrences\n",
      "Label 3: 5960 occurrences\n",
      "Label 4: 5960 occurrences\n",
      "Label 5: 5960 occurrences\n",
      "Label 6: 5960 occurrences\n",
      "torch.Size([41720, 132]) torch.Size([41720])\n",
      "tensor([1.2229, 5.4269, 0.3078, 2.0939, 1.2311, 0.7934, 5.0392])\n"
     ]
    }
   ],
   "source": [
    "# Generate sample data\n",
    "num_instances = len(concatenated_representation)\n",
    "input_dim = concatenated_representation.shape[1]\n",
    "num_classes = 7\n",
    "\n",
    "# Rescale input features\n",
    "selected_features = concatenated_representation / np.linalg.norm(concatenated_representation, axis=1, keepdims=True)\n",
    "\n",
    "# Apply data resampling (oversampling) to balance class distribution\n",
    "X_train, Y_train = oversample_data(concatenated_representation, y_train)\n",
    "\n",
    "# Calculate class weights for class weighting\n",
    "class_counts = np.bincount(y_train)\n",
    "total_instances = np.sum(class_counts)\n",
    "# class_weights = torch.tensor([total_instances / (num_classes * count) for count in class_counts], dtype=torch.float32)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "Y_train_tensor = torch.tensor(Y_train, dtype=torch.long)\n",
    "# print(X_train_tensor.shape, Y_train_tensor.shape)\n",
    "# X_train_tensor = torch.tensor(selected_features)\n",
    "# Y_train_tensor = torch.tensor(y_train)\n",
    "\n",
    "unique_labels, label_counts = np.unique(Y_train, return_counts=True)\n",
    "\n",
    "# Print the counts for each unique label\n",
    "for label, count in zip(unique_labels, label_counts):\n",
    "    print(f\"Label {label}: {count} occurrences\")\n",
    "\n",
    "print(X_train_tensor.shape, Y_train_tensor.shape)\n",
    "# Create a TensorDataset\n",
    "train_dataset = TensorDataset(X_train_tensor, Y_train_tensor)\n",
    "\n",
    "# Define batch size for DataLoader\n",
    "batch_size = 8\n",
    "\n",
    "# Create a PyTorch DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Initialize the model\n",
    "model = MyNetwork(input_dim, 50, num_classes)\n",
    "print(class_weights)\n",
    "# Define loss function and optimizer with class weights\n",
    "criterion = nn.CrossEntropyLoss(weight=None)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861ebf30",
   "metadata": {},
   "source": [
    "2. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9a71c886",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 100%|███████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1180.05it/s]\n",
      "Epoch 2/100: 100%|███████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1154.58it/s]\n",
      "Epoch 3/100: 100%|███████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1126.42it/s]\n",
      "Epoch 4/100: 100%|███████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1167.55it/s]\n",
      "Epoch 5/100: 100%|███████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1139.00it/s]\n",
      "Epoch 6/100: 100%|███████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1139.68it/s]\n",
      "Epoch 7/100: 100%|███████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1126.26it/s]\n",
      "Epoch 8/100: 100%|███████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1121.54it/s]\n",
      "Epoch 9/100: 100%|███████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1132.66it/s]\n",
      "Epoch 10/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1165.67it/s]\n",
      "Epoch 11/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1139.19it/s]\n",
      "Epoch 12/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1121.02it/s]\n",
      "Epoch 13/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1109.14it/s]\n",
      "Epoch 14/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:05<00:00, 1027.90it/s]\n",
      "Epoch 15/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1093.50it/s]\n",
      "Epoch 16/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1128.70it/s]\n",
      "Epoch 17/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1106.86it/s]\n",
      "Epoch 18/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1087.56it/s]\n",
      "Epoch 19/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1119.11it/s]\n",
      "Epoch 20/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1086.99it/s]\n",
      "Epoch 21/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1083.84it/s]\n",
      "Epoch 22/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1110.45it/s]\n",
      "Epoch 23/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1075.82it/s]\n",
      "Epoch 24/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1117.80it/s]\n",
      "Epoch 25/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1073.43it/s]\n",
      "Epoch 26/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1078.59it/s]\n",
      "Epoch 27/100: 100%|███████████████████████████████████████████████████████████████| 5215/5215 [00:06<00:00, 865.69it/s]\n",
      "Epoch 28/100: 100%|███████████████████████████████████████████████████████████████| 5215/5215 [00:06<00:00, 754.07it/s]\n",
      "Epoch 29/100: 100%|███████████████████████████████████████████████████████████████| 5215/5215 [00:05<00:00, 918.47it/s]\n",
      "Epoch 30/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:05<00:00, 1023.31it/s]\n",
      "Epoch 31/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:05<00:00, 1027.63it/s]\n",
      "Epoch 32/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1070.58it/s]\n",
      "Epoch 33/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:05<00:00, 1015.56it/s]\n",
      "Epoch 34/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1071.60it/s]\n",
      "Epoch 35/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1116.03it/s]\n",
      "Epoch 36/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1115.37it/s]\n",
      "Epoch 37/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1100.27it/s]\n",
      "Epoch 38/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1100.88it/s]\n",
      "Epoch 39/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1085.92it/s]\n",
      "Epoch 40/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:05<00:00, 1032.96it/s]\n",
      "Epoch 41/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1076.87it/s]\n",
      "Epoch 42/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1081.52it/s]\n",
      "Epoch 43/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1056.43it/s]\n",
      "Epoch 44/100: 100%|███████████████████████████████████████████████████████████████| 5215/5215 [00:05<00:00, 897.52it/s]\n",
      "Epoch 45/100: 100%|███████████████████████████████████████████████████████████████| 5215/5215 [00:06<00:00, 852.17it/s]\n",
      "Epoch 46/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1053.05it/s]\n",
      "Epoch 47/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1085.56it/s]\n",
      "Epoch 48/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1074.89it/s]\n",
      "Epoch 49/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1093.72it/s]\n",
      "Epoch 50/100: 100%|███████████████████████████████████████████████████████████████| 5215/5215 [00:05<00:00, 951.98it/s]\n",
      "Epoch 51/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:05<00:00, 1023.62it/s]\n",
      "Epoch 52/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:05<00:00, 1015.38it/s]\n",
      "Epoch 53/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1076.03it/s]\n",
      "Epoch 54/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:05<00:00, 1015.17it/s]\n",
      "Epoch 55/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1070.48it/s]\n",
      "Epoch 56/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1098.46it/s]\n",
      "Epoch 57/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:05<00:00, 1036.99it/s]\n",
      "Epoch 58/100: 100%|███████████████████████████████████████████████████████████████| 5215/5215 [00:05<00:00, 997.68it/s]\n",
      "Epoch 59/100: 100%|███████████████████████████████████████████████████████████████| 5215/5215 [00:05<00:00, 929.26it/s]\n",
      "Epoch 60/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1071.73it/s]\n",
      "Epoch 61/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1059.68it/s]\n",
      "Epoch 62/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1084.17it/s]\n",
      "Epoch 63/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1067.46it/s]\n",
      "Epoch 64/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1047.29it/s]\n",
      "Epoch 65/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1056.41it/s]\n",
      "Epoch 66/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1065.75it/s]\n",
      "Epoch 67/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1094.72it/s]\n",
      "Epoch 68/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1095.03it/s]\n",
      "Epoch 69/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1080.27it/s]\n",
      "Epoch 70/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1086.97it/s]\n",
      "Epoch 71/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1116.80it/s]\n",
      "Epoch 72/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1078.96it/s]\n",
      "Epoch 73/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1081.46it/s]\n",
      "Epoch 74/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1082.45it/s]\n",
      "Epoch 75/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1083.89it/s]\n",
      "Epoch 76/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1103.14it/s]\n",
      "Epoch 77/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1117.95it/s]\n",
      "Epoch 78/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1093.44it/s]\n",
      "Epoch 79/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1073.51it/s]\n",
      "Epoch 80/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1074.56it/s]\n",
      "Epoch 81/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1113.51it/s]\n",
      "Epoch 82/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1088.08it/s]\n",
      "Epoch 83/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1055.73it/s]\n",
      "Epoch 84/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1078.05it/s]\n",
      "Epoch 85/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1102.49it/s]\n",
      "Epoch 86/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1060.52it/s]\n",
      "Epoch 87/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:05<00:00, 1033.17it/s]\n",
      "Epoch 88/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1080.47it/s]\n",
      "Epoch 89/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:05<00:00, 1009.88it/s]\n",
      "Epoch 90/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1091.94it/s]\n",
      "Epoch 91/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1085.51it/s]\n",
      "Epoch 92/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1092.29it/s]\n",
      "Epoch 93/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1111.92it/s]\n",
      "Epoch 94/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1075.52it/s]\n",
      "Epoch 95/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1084.18it/s]\n",
      "Epoch 96/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1103.65it/s]\n",
      "Epoch 97/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1110.12it/s]\n",
      "Epoch 98/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1129.01it/s]\n",
      "Epoch 99/100: 100%|██████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1112.93it/s]\n",
      "Epoch 100/100: 100%|█████████████████████████████████████████████████████████████| 5215/5215 [00:04<00:00, 1121.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 1.8030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    for inputs, labels in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}'):\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item() * inputs.size(0)\n",
    "    \n",
    "    # Print average loss per epoch\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss / len(train_dataset):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b435c98b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training F1 Score: 0.3103\n",
      "F1 Score for Class anger: 0.2079\n",
      "F1 Score for Class fear: 0.3957\n",
      "F1 Score for Class neutral: 0.1907\n",
      "F1 Score for Class sadness: 0.3415\n",
      "F1 Score for Class surprise: 0.3948\n",
      "F1 Score for Class joy: 0.2340\n",
      "F1 Score for Class disgust: 0.4074\n",
      "Label anger: 3103 occurrences\n",
      "Label fear: 8416 occurrences\n",
      "Label neutral: 4506 occurrences\n",
      "Label sadness: 7588 occurrences\n",
      "Label surprise: 8512 occurrences\n",
      "Label joy: 3347 occurrences\n",
      "Label disgust: 6248 occurrences\n"
     ]
    }
   ],
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Predict on the training data\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_train_tensor)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "# Convert predicted tensor to numpy array\n",
    "predicted = predicted.numpy()\n",
    "\n",
    "# Calculate F1 score per class\n",
    "f1_per_class = f1_score(Y_train_tensor, predicted, average=None)\n",
    "f1 = f1_score(Y_train_tensor, predicted, average='macro')\n",
    "\n",
    "print(f'Training F1 Score: {f1:.4f}')\n",
    "\n",
    "unique_labels, label_counts = np.unique(predicted, return_counts=True)\n",
    "\n",
    "# Print F1 score for each class\n",
    "for i, f1 in enumerate(f1_per_class):\n",
    "    print(f'F1 Score for Class {label_decoder[i]}: {f1:.4f}')\n",
    "    \n",
    "# Print the counts for each unique label\n",
    "for label, count in zip(unique_labels, label_counts):\n",
    "    print(f\"Label {label_decoder[label]}: {count} occurrences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d19c5f4",
   "metadata": {},
   "source": [
    "3rd version is 2nd version + ensembled FC classifier"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
