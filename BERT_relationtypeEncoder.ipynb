{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c64aa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, os, math, pickle, sys, random, time\n",
    "from tqdm import tqdm\n",
    "import torch.nn.init as init\n",
    "import dgl,numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Parameter\n",
    "from collections import Counter\n",
    "import dgl.function as fn\n",
    "from dgl.nn.functional import edge_softmax\n",
    "import pandas as pd\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.nn import RGCNConv, GraphConv\n",
    "from model import DialogueGCN_MELDModel, GraphNetwork_RGCN, GraphNetwork_GAT, \\\n",
    "GraphNetwork_GAT_EdgeFeat, GraphNetwork_GATv2, GraphNetwork_GATv2_EdgeFeat, GraphNetwork_RGAT\n",
    "from model import DATASET_PATH\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from graph_context_dataset import GraphContextDataset\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f920f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "key=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a153dd45",
   "metadata": {},
   "source": [
    "<b>Make sure to specify which dataset to use\n",
    "<br>\n",
    " - dataset_original\n",
    "<br>\n",
    " - dataset_drop_noise\n",
    "<br>\n",
    " - dataset_smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a74ba53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_path = \"dataset_original\"\n",
    "# dataset_path = \"dataset_drop_noise\"\n",
    "# dataset_path = \"dataset_smote\"\n",
    "dataset_path = DATASET_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8aa9fe91",
   "metadata": {
    "code_folding": [
     0,
     38,
     60
    ]
   },
   "outputs": [],
   "source": [
    "class GATLayerWithEdgeType(nn.Module):\n",
    "    def __init__(self, num_in_features_per_head, num_out_features_per_head, num_heads, num_edge_types):\n",
    "        super(GATLayerWithEdgeType, self).__init__()\n",
    "        self.num_in_features_per_head = num_in_features_per_head\n",
    "        self.num_out_features_per_head = num_out_features_per_head\n",
    "        self.num_heads = num_heads\n",
    "        self.num_edge_types = num_edge_types\n",
    "\n",
    "        # Linear projection for node features\n",
    "        torch.manual_seed(42)\n",
    "        self.linear_proj = nn.Linear(self.num_in_features_per_head, self.num_heads * self.num_out_features_per_head)\n",
    "        \n",
    "        # Edge type embeddings\n",
    "        torch.manual_seed(42)\n",
    "        self.edge_type_embedding = nn.Embedding(self.num_edge_types, self.num_heads)\n",
    "        \n",
    "    def forward(self, input_data, edge_type):\n",
    "        node_features, edge_indices = input_data\n",
    "\n",
    "        # Linear projection for node features\n",
    "        h_linear = self.linear_proj(node_features.view(-1, self.num_in_features_per_head))\n",
    "        h_linear = h_linear.view(-1, self.num_heads, self.num_out_features_per_head)\n",
    "        h_linear = h_linear.permute(0, 2, 1)\n",
    "\n",
    "        # Edge type embedding\n",
    "        edge_type_embedding = self.edge_type_embedding(edge_type).transpose(0, 1)\n",
    "\n",
    "        # Perform matrix multiplication\n",
    "        attention_scores = torch.matmul(h_linear, edge_type_embedding).squeeze(-1)\n",
    "\n",
    "        # Softmax to get attention coefficients\n",
    "        attention_coefficients = F.softmax(attention_scores, dim=-1)\n",
    "\n",
    "        # Weighted sum of neighbor node representations\n",
    "        updated_representation = torch.matmul(attention_coefficients.transpose(1, 2), h_linear).mean(dim=2)\n",
    "\n",
    "        return updated_representation, attention_coefficients\n",
    "    \n",
    "class GATWithEdgeType(nn.Module):\n",
    "    def __init__(self, num_of_layers, num_heads_per_layer, num_features_per_layer, num_edge_types):\n",
    "        super(GATWithEdgeType, self).__init__()\n",
    "\n",
    "        self.gat_net = nn.ModuleList()\n",
    "\n",
    "        for layer in range(num_of_layers):\n",
    "            num_in_features = num_heads_per_layer[layer - 1] * num_features_per_layer[layer - 1] if layer > 0 else num_features_per_layer[0]\n",
    "            num_out_features = num_heads_per_layer[layer] * num_features_per_layer[layer]\n",
    "            self.gat_net.append(GATLayerWithEdgeType(num_in_features, num_out_features, num_heads_per_layer[layer], num_edge_types))\n",
    "\n",
    "    def forward(self, node_features, edge_indices, edge_types):\n",
    "        h = node_features\n",
    "\n",
    "        attention_scores = []\n",
    "\n",
    "        for layer in self.gat_net:\n",
    "            h, attention_coefficients = layer((h, edge_indices), edge_types)\n",
    "            attention_scores.append(attention_coefficients)\n",
    "\n",
    "        return h, attention_scores\n",
    "\n",
    "class EGATConv(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_node_feats,\n",
    "                 in_edge_feats,\n",
    "                 out_node_feats,\n",
    "                 out_edge_feats,\n",
    "                 num_heads,\n",
    "                 bias=True,\n",
    "                 **kw_args):\n",
    "\n",
    "        super().__init__()\n",
    "        self._num_heads = num_heads\n",
    "        self._out_node_feats = out_node_feats\n",
    "        self._out_edge_feats = out_edge_feats\n",
    "        \n",
    "        self.fc_node = nn.Linear(in_node_feats, out_node_feats * num_heads, bias=bias)\n",
    "        self.fc_ni = nn.Linear(in_node_feats, out_edge_feats * num_heads, bias=False)\n",
    "        self.fc_fij = nn.Linear(in_edge_feats, out_edge_feats * num_heads, bias=False)\n",
    "        self.fc_nj = nn.Linear(in_node_feats, out_edge_feats * num_heads, bias=False)\n",
    "        \n",
    "        # Attention parameter\n",
    "        self.attn = nn.Parameter(torch.FloatTensor(size=(1, num_heads, out_edge_feats)))\n",
    "        \n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.FloatTensor(size=(num_heads * out_edge_feats,)))\n",
    "        else:\n",
    "            self.register_buffer('bias', None)\n",
    "        \n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        torch.manual_seed(42)\n",
    "        gain = init.calculate_gain('relu')\n",
    "        init.xavier_normal_(self.fc_node.weight, gain=gain)\n",
    "        init.xavier_normal_(self.fc_ni.weight, gain=gain)\n",
    "        init.xavier_normal_(self.fc_fij.weight, gain=gain)\n",
    "        init.xavier_normal_(self.fc_nj.weight, gain=gain)\n",
    "        init.xavier_normal_(self.attn, gain=gain)\n",
    "        \n",
    "        if self.bias is not None:\n",
    "            nn.init.constant_(self.bias, 0)\n",
    "\n",
    "    def forward(self, graph, nfeats, efeats, get_attention=False):\n",
    "        with graph.local_scope():\n",
    "            graph.edata['f'] = efeats\n",
    "            graph.ndata['h'] = nfeats\n",
    "            \n",
    "            f_ni = self.fc_ni(nfeats)\n",
    "            f_nj = self.fc_nj(nfeats)\n",
    "            f_fij = self.fc_fij(efeats)\n",
    "            graph.srcdata.update({'f_ni' : f_ni})\n",
    "            graph.dstdata.update({'f_nj' : f_nj})\n",
    "            \n",
    "            graph.apply_edges(fn.u_add_v('f_ni', 'f_nj', 'f_tmp'))\n",
    "            f_out = graph.edata.pop('f_tmp') + f_fij\n",
    "            \n",
    "            if self.bias is not None:\n",
    "                f_out += self.bias\n",
    "            f_out = nn.functional.leaky_relu(f_out)\n",
    "            f_out = f_out.view(-1, self._num_heads, self._out_edge_feats)\n",
    "            \n",
    "            e = (f_out * self.attn).sum(dim=-1).unsqueeze(-1)\n",
    "            graph.edata['a'] = edge_softmax(graph, e)\n",
    "            graph.ndata['h_out'] = self.fc_node(nfeats).view(-1, self._num_heads, self._out_node_feats)\n",
    "            \n",
    "            graph.update_all(fn.u_mul_e('h_out', 'a', 'm'), fn.sum('m', 'h_out'))\n",
    "\n",
    "            h_out = graph.ndata['h_out'].view(-1, self._num_heads, self._out_node_feats)\n",
    "            if get_attention:\n",
    "                return h_out, f_out, graph.edata.pop('a')\n",
    "            else:\n",
    "                return h_out, f_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7adf37e",
   "metadata": {
    "code_folding": [
     0,
     11,
     29,
     31
    ]
   },
   "outputs": [],
   "source": [
    "def get_ohe(edge_types):\n",
    "    one_hot_encoding = []\n",
    "    for edge_type in edge_types:\n",
    "        if edge_type == 0:\n",
    "            one_hot_encoding.append([1., 0., 0.])\n",
    "        elif edge_type == 1:\n",
    "            one_hot_encoding.append([0., 1., 0.])\n",
    "        elif edge_type == 2:\n",
    "            one_hot_encoding.append([0., 0., 1.])\n",
    "    return torch.tensor(one_hot_encoding)\n",
    "\n",
    "def get_inferred_edgetypes_GAT(dialog, edge_types):\n",
    "    inferred_edge_types = []\n",
    "    inferred_edge_indices = []\n",
    "    for target_node in dialog.values():\n",
    "        if len(target_node) == 1:\n",
    "            inferred_edge_types.append(0)\n",
    "            inferred_edge_indices.append(0)\n",
    "        else:\n",
    "            edge_index = target_node[0][0]\n",
    "            highest_attention = target_node[0][1]\n",
    "            for src_node in target_node[1:]:\n",
    "                if highest_attention < src_node[1]:\n",
    "                    highest_attention = src_node[1]\n",
    "                    edge_index = src_node[0]\n",
    "            inferred_edge_indices.append(edge_index)\n",
    "            inferred_edge_types.append(edge_types[edge_index].tolist())\n",
    "    return inferred_edge_indices, inferred_edge_types\n",
    "\n",
    "def get_inferred_edgetypes_EGAT(edges_target_nodes, sample_edge_types, size_dialog, dialog_id):\n",
    "    inferred_edge_types = []\n",
    "    for target_idx in range(size_dialog):\n",
    "        num_edges = len(edges_target_nodes[target_idx])\n",
    "        if num_edges == 1:\n",
    "            edgetype_idx = np.argmax(edges_target_nodes[target_idx][0][1])\n",
    "            edge_idx = edges_target_nodes[target_idx][0][0]\n",
    "            inferred_edge_types.append(edgetype_idx)\n",
    "        else:\n",
    "            highest_attn_score = max(edges_target_nodes[target_idx][0][1])\n",
    "            edgetype_idx = np.argmax(edges_target_nodes[target_idx][0][1])\n",
    "            edge_idx = edges_target_nodes[target_idx][0][0]\n",
    "            for sample_edge in range(1, num_edges):\n",
    "                cur_highest_attn_score = max(edges_target_nodes[target_idx][sample_edge][1])\n",
    "                if cur_highest_attn_score > highest_attn_score:\n",
    "                    highest_attn_score = cur_highest_attn_score\n",
    "                    edgetype_idx = np.argmax(edges_target_nodes[target_idx][sample_edge][1])\n",
    "                    edge_idx = edges_target_nodes[target_idx][sample_edge][0]\n",
    "            inferred_edge_types.append(edgetype_idx)\n",
    "    return inferred_edge_types\n",
    "\n",
    "def flatten_extend(matrix):\n",
    "    flat_list = []\n",
    "    for row in matrix:\n",
    "        flat_list.extend(row)\n",
    "    return flat_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7639e77",
   "metadata": {
    "code_folding": [
     0,
     15,
     25,
     40
    ]
   },
   "outputs": [],
   "source": [
    "def create_node_pairs_list(start_idx, end_idx):\n",
    "    list_node_i = []\n",
    "    list_node_j = []\n",
    "    end_idx = end_idx - start_idx\n",
    "    start_idx = 0\n",
    "    for i in range(start_idx, end_idx+1):\n",
    "        val = 0\n",
    "        while (val <= 3) and (i+val <= end_idx):\n",
    "            target_idx = i+val\n",
    "            if target_idx >= 0:\n",
    "                list_node_i.append(i)\n",
    "                list_node_j.append(target_idx)\n",
    "            val = val+1\n",
    "    return [list_node_i, list_node_j]\n",
    "\n",
    "def create_adjacency_dict(node_pairs):\n",
    "    adjacency_list_dict = {}\n",
    "    for i in range(0, len(node_pairs[0])):\n",
    "        source_node, target_node = node_pairs[0][i], node_pairs[1][i]\n",
    "        if source_node not in adjacency_list_dict:\n",
    "            adjacency_list_dict[source_node] = [target_node]\n",
    "        else:\n",
    "            adjacency_list_dict[source_node].append(target_node)\n",
    "    return adjacency_list_dict\n",
    "\n",
    "def get_all_adjacency_list(ranges, key=0):\n",
    "    all_adjacency_list = []\n",
    "    for range_pair in ranges:\n",
    "        start_idx, end_idx = range_pair\n",
    "        if key == 0:\n",
    "            output = create_node_pairs_list(start_idx, end_idx)\n",
    "            output = create_adjacency_dict(output)\n",
    "        elif key == 1:\n",
    "            output = create_node_pairs_list(start_idx, end_idx)\n",
    "            output = torch.tensor(output)\n",
    "        else:\n",
    "            print(\"N/A\")\n",
    "        all_adjacency_list.append(output)\n",
    "    return all_adjacency_list\n",
    "\n",
    "def get_all_edge_type_list(edge_indices, encoded_speaker_list):\n",
    "    dialogs_len = len(edge_indices)\n",
    "    whole_edge_type_list = []\n",
    "    for i in range(dialogs_len):\n",
    "        dialog_nodes_pairs = edge_indices[i]\n",
    "        dialog_speakers = list(encoded_speaker_list[i])\n",
    "        dialog_len = len(dialog_nodes_pairs.keys())\n",
    "        edge_type_list = []\n",
    "        for j in range(dialog_len):\n",
    "            src_node = dialog_nodes_pairs[j]\n",
    "            node_i_idx = j\n",
    "            win_len = len(src_node)\n",
    "            for k in range(win_len):\n",
    "                node_j_idx = src_node[k]\n",
    "                if node_i_idx == node_j_idx:\n",
    "                    edge_type_list.append(0)\n",
    "                else:\n",
    "                    if dialog_speakers[node_i_idx] != dialog_speakers[node_j_idx]:\n",
    "                        edge_type_list.append(1)\n",
    "                    else:\n",
    "                        edge_type_list.append(2)\n",
    "        whole_edge_type_list.append(torch.tensor(edge_type_list).to(torch.int64))\n",
    "    return whole_edge_type_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ed53f3f",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=100):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ddb394",
   "metadata": {},
   "source": [
    "<h3> Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2c424c",
   "metadata": {},
   "source": [
    "<h4> Creating graph features from Train, Test and Validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d8a8f87",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# checkFile = os.path.isfile(\"data/dump/\" + dataset_path + \"/speaker_encoder_train.pkl\")\n",
    "# encodedSpeakersTrain = []\n",
    "# rangesTrain = []\n",
    "\n",
    "# if not checkFile:\n",
    "#     print(\"Run first the contextEncoder1 or 2 to generate this file\")\n",
    "# else:\n",
    "#     with open('data/dump/' + dataset_path + '/speaker_encoder_train.pkl', \"rb\") as file:\n",
    "#         encodedSpeakersTrain, rangesTrain = pickle.load(file)\n",
    "\n",
    "# checkFile = os.path.isfile(\"data/dump/\" + dataset_path +\"/adjListTrain.pkl\")\n",
    "# adjacencyListTrain = []\n",
    "\n",
    "# if key:\n",
    "#     adjacencyListTrain = get_all_adjacency_list(rangesTrain)\n",
    "# else:\n",
    "#     with open('data/dump/' + dataset_path + '/adjListTrain', \"rb\") as file:\n",
    "#         adjacencyListTrain = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f5170d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSpeakersAndRanges(file_path):\n",
    "    checkFile = os.path.isfile(file_path)\n",
    "    encodedSpeakers = []\n",
    "#     ranges = []\n",
    "    if not checkFile:\n",
    "        print(\"Run first the contextEncoder1.5 to generate this file\")\n",
    "        return None\n",
    "    else:\n",
    "        with open(file_path, \"rb\") as file:\n",
    "            encodedSpeakers, ranges = pickle.load(file)\n",
    "        return encodedSpeakers, ranges\n",
    "    \n",
    "def getAdjacencyList(file_path, ranges):\n",
    "    checkFile = os.path.isfile(file_path)\n",
    "    adjacencyList = []\n",
    "\n",
    "    if key:\n",
    "        adjacencyList = get_all_adjacency_list(ranges)\n",
    "    else:\n",
    "        with open(file_path, \"rb\") as file:\n",
    "            adjacencyList = pickle.load(file)\n",
    "    \n",
    "    return adjacencyList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7be6a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path1 = \"data/dump/\" + dataset_path + \"/speaker_encoder_train.pkl\"\n",
    "file_path2 = \"data/dump/\" + dataset_path + \"/speaker_encoder_test.pkl\"\n",
    "file_path3 = \"data/dump/\" + dataset_path + \"/speaker_encoder_dev.pkl\"\n",
    "\n",
    "encodedSpeakersTrain, rangesTrain = getSpeakersAndRanges(file_path1)\n",
    "encodedSpeakersTest, rangesTest = getSpeakersAndRanges(file_path2)\n",
    "encodedSpeakersDev, rangesDev = getSpeakersAndRanges(file_path3)\n",
    "\n",
    "file_path1 = 'data/dump/' + dataset_path + '/adjListTrain'\n",
    "file_path2 = 'data/dump/' + dataset_path + '/adjListTest'\n",
    "file_path3 = 'data/dump/' + dataset_path + '/adjListDev'\n",
    "\n",
    "adjacencyListTrain = getAdjacencyList(file_path1, rangesTrain)\n",
    "adjacencyListTest = getAdjacencyList(file_path1, rangesTest)\n",
    "adjacencyListDev = getAdjacencyList(file_path1, rangesDev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "771b8350",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path1 = 'embed/' + dataset_path + '/u_prime_BERT_train.pkl'\n",
    "file_path2 = 'embed/' + dataset_path + '/u_prime_BERT_test.pkl'\n",
    "file_path3 = 'embed/' + dataset_path + '/u_prime_BERT_dev.pkl'\n",
    "\n",
    "# Load the list from the file using pickle\n",
    "def getFeatures(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        emotions = pickle.load(file)\n",
    "    return emotions\n",
    "\n",
    "contextualEmbeddingsTrain = getFeatures(file_path1)\n",
    "contextualEmbeddingsTest = getFeatures(file_path2)\n",
    "contextualEmbeddingsDev = getFeatures(file_path3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6698b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(contextualEmbeddingsTrain.shape, contextualEmbeddingsTest.shape, contextualEmbeddingsDev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6055971",
   "metadata": {},
   "outputs": [],
   "source": [
    "edgeIndicesTrain = get_all_adjacency_list(rangesTrain)\n",
    "edgeTypesTrain = get_all_edge_type_list(edgeIndicesTrain, encodedSpeakersTrain)\n",
    "edgeIndicesTrain = get_all_adjacency_list(rangesTrain, key=1)\n",
    "\n",
    "edgeIndicesTest = get_all_adjacency_list(rangesTest)\n",
    "edgeTypesTest = get_all_edge_type_list(edgeIndicesTest, encodedSpeakersTest)\n",
    "edgeIndicesTest = get_all_adjacency_list(rangesTest, key=1)\n",
    "\n",
    "edgeIndicesDev = get_all_adjacency_list(rangesDev)\n",
    "edgeTypesDev = get_all_edge_type_list(edgeIndicesDev, encodedSpeakersDev)\n",
    "edgeIndicesDev = get_all_adjacency_list(rangesDev, key=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b48a81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e18118d",
   "metadata": {},
   "source": [
    "<h4> Creating \"SAMPLE\" graph features based on various graph networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16a469bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(rangesTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b197fe2",
   "metadata": {},
   "source": [
    "Start of sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc943c7d",
   "metadata": {},
   "source": [
    "<h5>DGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9caf12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.features = [torch.rand(14, 200)]\n",
    "        self.edge_index = [torch.randint(0, 14, (2, 69))]\n",
    "        self.edge_type = [torch.randint(0, 4, (69,))]\n",
    "        self.edge_index_lengths = [torch.tensor([69])]\n",
    "        self.umask = [torch.randint(0, 2, (1, 14))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.features[idx], self.edge_index[idx], self.edge_type[idx], self.edge_index_lengths[idx], self.umask[idx])\n",
    "\n",
    "# Create the dataset and dataloader\n",
    "dataset = SampleDataset()\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4874963d",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN Representation Shape: torch.Size([14, 64])\n"
     ]
    }
   ],
   "source": [
    "# D_m = 200\n",
    "# D_g = 100\n",
    "# D_p = 100\n",
    "# D_e = 100\n",
    "# D_h = 100\n",
    "# D_a = 100\n",
    "# graph_hidden_size = 64\n",
    "# n_speakers = 2\n",
    "# max_seq_len = 110\n",
    "# window_past = 0\n",
    "# window_future = 5\n",
    "# n_classes = 7\n",
    "# dropout_rec = 0.5\n",
    "# dropout = 0.5\n",
    "nodal_attention = True\n",
    "avec = False\n",
    "no_cuda = False\n",
    "\n",
    "features = torch.randn(14, 200)\n",
    "edge_index = [torch.tensor([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13],\n",
    "                            [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 0]])]\n",
    "edge_type = [torch.tensor([1, 0, 2, 2, 2, 0, 1, 3, 2, 2, 0, 2, 2, 2])]\n",
    "seq_lengths  = torch.tensor([[14]])\n",
    "umask = torch.ones(1, 1, 14)\n",
    "\n",
    "nodal_attn = False\n",
    "avec = False\n",
    "\n",
    "# Initialize the model\n",
    "model = GraphNetwork_RGCN(num_features=200, num_classes=7, num_relations=4, max_seq_len=14)\n",
    "gcn_representation = model(features, edge_index, edge_type, seq_lengths, umask, nodal_attn, avec)\n",
    "print(\"GCN Representation Shape:\", gcn_representation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3846a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40d48a0",
   "metadata": {},
   "source": [
    "<h5>GAT w/o edge feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e6cdb11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([14, 64])\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "num_features = 768\n",
    "num_classes = 7\n",
    "num_relations = 4  # This parameter is not used with GATConv but kept for compatibility\n",
    "max_seq_len = 14\n",
    "hidden_size = 64\n",
    "num_heads = 8\n",
    "dropout = 0.5\n",
    "no_cuda = False\n",
    "\n",
    "model = GraphNetwork_GAT(num_features, num_classes, num_relations, max_seq_len, hidden_size, num_heads, dropout, no_cuda)\n",
    "\n",
    "# Dummy inputs for testing\n",
    "x = torch.randn((14, num_features))  # Example feature matrix with 14 nodes\n",
    "edge_index = [torch.randint(0, 14, (2, 20))]  # Example edge index with 20 edges\n",
    "# edge_type = [torch.randint(0, num_relations, (20,))]  # Example edge types\n",
    "\n",
    "# Forward pass\n",
    "out = model(x, edge_index)\n",
    "print(\"Output shape:\", out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "928e2940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0862804c",
   "metadata": {},
   "source": [
    "<h5>GAT with edge feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "276cee90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([14, 64])\n"
     ]
    }
   ],
   "source": [
    "num_features = 768\n",
    "num_classes = 7\n",
    "num_relations = 4  # Assuming edge features have 4 dimensions\n",
    "max_seq_len = 14\n",
    "hidden_size = 64\n",
    "num_heads = 8\n",
    "dropout = 0.5\n",
    "no_cuda = False\n",
    "\n",
    "model = GraphNetwork_GAT_EdgeFeat(num_features, num_classes, num_relations, max_seq_len, hidden_size, num_heads, dropout, no_cuda)\n",
    "\n",
    "# Dummy inputs for testing\n",
    "x = torch.randn((14, num_features))\n",
    "edge_index = [torch.randint(0, 14, (2, 20))]\n",
    "edge_attr = [torch.randn((20, num_relations))]\n",
    "\n",
    "# Forward pass\n",
    "out = model(x, edge_index, edge_attr)\n",
    "print(\"Output shape:\", out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1869288a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# edge_attr = torch.randint(0, 2, (20, 1)).float()  # Example binary edge features\n",
    "# edge_attr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd71b632",
   "metadata": {},
   "source": [
    "<h5>GATv2 w/o edgetype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab557a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([14, 64])\n",
      "Output shape with attention: torch.Size([14, 64])\n",
      "Attention weights shape: torch.Size([34, 1])\n"
     ]
    }
   ],
   "source": [
    "num_features = 768\n",
    "num_classes = 7\n",
    "hidden_size = 64\n",
    "num_heads = 8\n",
    "dropout = 0.5\n",
    "no_cuda = False\n",
    "\n",
    "model = GraphNetwork_GATv2(num_features, num_classes, hidden_size, num_heads, dropout, no_cuda)\n",
    "\n",
    "# Dummy inputs for testing\n",
    "x = torch.randn((14, num_features))  # Example feature matrix with 14 nodes\n",
    "edge_index = torch.randint(0, 14, (2, 20))  # Example edge index with 20 edges\n",
    "edge_attr = torch.randn((20, 1))  # Example edge features\n",
    "\n",
    "# Forward pass\n",
    "out = model(x, edge_index, edge_attr)\n",
    "print(\"Output shape:\", out.shape)\n",
    "\n",
    "# Forward pass with attention weights\n",
    "out, (edge_index, attention_weights) = model(x, edge_index, edge_attr, return_attention_weights=True)\n",
    "print(\"Output shape with attention:\", out.shape)\n",
    "print(\"Attention weights shape:\", attention_weights.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5781299",
   "metadata": {},
   "source": [
    "<h5>GATv2 with edge type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b5ae9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([14, 64])\n"
     ]
    }
   ],
   "source": [
    "num_features = 768\n",
    "num_classes = 7\n",
    "num_relations = 4\n",
    "max_seq_len = 30\n",
    "hidden_size = 64\n",
    "num_heads = 8\n",
    "dropout = 0.5\n",
    "no_cuda = False\n",
    "\n",
    "model = GraphNetwork_GATv2_EdgeFeat(num_features, num_classes, num_relations, max_seq_len, hidden_size, num_heads, dropout, no_cuda)\n",
    "\n",
    "x = torch.randn((14, num_features))  # Example feature matrix with 14 nodes\n",
    "edge_index = torch.randint(0, 14, (2, 20))  # Example edge index with 20 edges\n",
    "edge_attr = torch.randn((20, num_relations))  # Example edge features\n",
    "\n",
    "# Forward pass\n",
    "out = model(x, edge_index, edge_attr)\n",
    "print(\"Output shape:\", out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6d91e3",
   "metadata": {},
   "source": [
    "<h5>RGAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d536b5f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6,  9,  5,  2,  8,  3, 13,  9,  1,  4, 11, 13,  7,  2, 13,  6, 13,  1,\n",
       "          0,  5],\n",
       "        [11,  4,  9,  1, 12, 11,  9, 13,  6, 11,  9,  3,  1,  0, 11,  5,  3,  2,\n",
       "          7,  5]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e05a3a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([14, 64])\n"
     ]
    }
   ],
   "source": [
    "num_features = 768\n",
    "num_classes = 7\n",
    "num_relations = 3  # Example number of relations\n",
    "hidden_size = 64\n",
    "num_heads = 8\n",
    "dropout = 0.5\n",
    "edge_dim = 1  # Dimensionality of edge attributes\n",
    "no_cuda = False\n",
    "\n",
    "\n",
    "model = GraphNetwork_RGAT(num_features, num_classes, num_relations, hidden_size, num_heads, dropout, edge_dim, no_cuda)\n",
    "\n",
    "# Dummy inputs for testing\n",
    "x = torch.randn((14, num_features))  # Example feature matrix with 14 nodes\n",
    "edge_index = torch.randint(0, 14, (2, 20))  # Example edge index with 20 edges\n",
    "edge_type = torch.randint(0, num_relations, (20,))  # Example edge types\n",
    "edge_attr = torch.randn((20, 1))  # Example edge features\n",
    "\n",
    "# Forward pass\n",
    "out = model(x, edge_index, edge_type=edge_type)\n",
    "print(\"Output shape:\", out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de94a009",
   "metadata": {},
   "source": [
    "End of sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8317848a",
   "metadata": {},
   "source": [
    "<h4> Encode speaker to train, test, and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d7bc233c",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# class GraphContextDataset(Dataset):\n",
    "#     def __init__(self, rangeSet, labels, features, edge_index, edge_type, \\\n",
    "#                  edge_index_lengths, umask, seq_lengths):\n",
    "#         self.rangeSet = rangeSet\n",
    "#         self.labels = [torch.tensor(label) for label in labels]\n",
    "#         self.features = [torch.tensor(feature) for feature in features]\n",
    "#         self.edge_index = [torch.tensor(edge) for edge in edge_index]\n",
    "#         self.edge_type = [torch.tensor(edge) for edge in edge_type]\n",
    "#         self.edge_index_lengths = [torch.tensor(length) for length in edge_index_lengths]\n",
    "#         self.umask = umask\n",
    "#         self.seq_lengths = seq_lengths\n",
    "        \n",
    "#     def __len__(self):\n",
    "#         return len(self.rangeSet)  # Use rangeSet for length\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         startIdx, endIdx = self.rangeSet[idx]\n",
    "#         return (\n",
    "#             self.labels[startIdx: endIdx+1],\n",
    "#             self.features[idx],\n",
    "#             self.edge_index[idx],\n",
    "#             self.edge_type[idx],\n",
    "#             self.edge_index_lengths[idx],\n",
    "#             self.umask[idx],\n",
    "#             self.seq_lengths[idx]\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "69ad33d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\final_yr\\t2\\THSST-2\\ug_thesis\\ER_GAT\\graph_context_dataset.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.features = [torch.tensor(feature) for feature in features]\n",
      "D:\\final_yr\\t2\\THSST-2\\ug_thesis\\ER_GAT\\graph_context_dataset.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.edge_index = [torch.tensor(edge) for edge in edge_index]\n",
      "D:\\final_yr\\t2\\THSST-2\\ug_thesis\\ER_GAT\\graph_context_dataset.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.edge_type = [torch.tensor(edge) for edge in edge_type]\n"
     ]
    }
   ],
   "source": [
    "def getDataLoaderAndLabels(file_path, ranges):\n",
    "    with open(file_path[0], 'rb') as file:\n",
    "         all_umask, \\\n",
    "         all_seq_lengths,\\\n",
    "         all_features, \\\n",
    "         all_edge_index, \\\n",
    "         all_edge_norm, \\\n",
    "         all_edge_type, \\\n",
    "         all_edge_index_lengths = pickle.load(file)\n",
    "\n",
    "    with open(file_path[1], 'rb') as file:\n",
    "        labels = pickle.load(file)\n",
    "\n",
    "    dataset = GraphContextDataset(ranges, labels,\n",
    "                                       all_features, all_edge_index,\n",
    "                                       all_edge_type,\n",
    "                                       all_edge_index_lengths,\n",
    "                                       all_umask, all_seq_lengths)\n",
    "    dataLoader = DataLoader(dataset, batch_size=1, shuffle=False, num_workers=4)\n",
    "    return dataLoader, labels\n",
    "\n",
    "file_path1 = ['embed/' + dataset_path + '/pre_h_prime_BERT_train.pkl', 'data/dump/' + dataset_path + '/labels_train.pkl']\n",
    "file_path2 = ['embed/' + dataset_path + '/pre_h_prime_BERT_test.pkl' , 'data/dump/' + dataset_path + '/labels_test.pkl']\n",
    "file_path3 = ['embed/' + dataset_path + '/pre_h_prime_BERT_dev.pkl', 'data/dump/' + dataset_path + '/labels_dev.pkl']\n",
    "\n",
    "dataLoaderTrain, trainLabels = getDataLoaderAndLabels(file_path1, rangesTrain)\n",
    "dataLoaderTest, testLabels = getDataLoaderAndLabels(file_path2, rangesTest)\n",
    "dataLoaderDev, devLabels = getDataLoaderAndLabels(file_path3, rangesDev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "76fc8abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RelationEncoding(file_path, dataLoader, model, config):\n",
    "    all_h_prime = []\n",
    "    checkFile = os.path.isfile(file_path)\n",
    "    start_time = time.time()\n",
    "    i = 0\n",
    "    j = 1\n",
    "    for _, features_in, edge_index_in, edge_type_in, _, umask, seq_lengths_in in tqdm(dataLoader, desc=\"Encoding Progress\", unit=\"batch\"):\n",
    "        if config == \"dgcn\":\n",
    "            avec, no_cuda, nodal_attn = False, False, False\n",
    "            feature = features_in.squeeze(0)\n",
    "            edge_index = edge_index_in.squeeze(0)\n",
    "            edge_type = edge_type_in.squeeze(0)\n",
    "            seq_lengths = torch.tensor(seq_lengths_in).view(1, 1)\n",
    "            graph_representation = model(feature, [edge_index], [edge_type], seq_lengths, umask, nodal_attn, avec)\n",
    "        elif config == \"GATv1_noAttn\":\n",
    "            feature = features_in.squeeze(0)\n",
    "            edge_index = edge_index_in.squeeze(0)\n",
    "            graph_representation = model(feature, [edge_index])\n",
    "            \n",
    "        elif config == \"GATv1\":\n",
    "            feature = features_in.squeeze(0)\n",
    "            edge_index = edge_index_in.squeeze(0)\n",
    "            edge_type = edge_type_in.squeeze(0)\n",
    "            num_edge_types = 8\n",
    "            edge_attr = torch.zeros((edge_type.size(0), num_edge_types))\n",
    "            edge_attr.scatter_(1, edge_type.view(-1, 1), 1)\n",
    "            graph_representation = model(feature, [edge_index], [edge_attr])\n",
    "            \n",
    "        elif config == \"GATv2_noAttn\":\n",
    "            feature = features_in.squeeze(0)\n",
    "            edge_index = edge_index_in.squeeze(0)\n",
    "            graph_representation = model(feature, edge_index)\n",
    "        \n",
    "        elif config == \"GATv2\":\n",
    "            feature = features_in.squeeze(0)\n",
    "            edge_index = edge_index_in.squeeze(0)\n",
    "            edge_type = edge_type_in.squeeze(0)\n",
    "            num_edge_types = 8\n",
    "            edge_attr = torch.zeros((edge_type.size(0), num_edge_types))\n",
    "            edge_attr.scatter_(1, edge_type.view(-1, 1), 1)\n",
    "            graph_representation = model(feature, edge_index, edge_attr)\n",
    "        \n",
    "        elif config == \"RGAT\":\n",
    "            feature = features_in.squeeze(0)\n",
    "            edge_index = edge_index_in.squeeze(0)\n",
    "            edge_type = edge_type_in.squeeze(0)\n",
    "            graph_representation = model(feature, edge_index, edge_type)\n",
    "        \n",
    "        all_h_prime.append(graph_representation.cpu())\n",
    "        \n",
    "        i = i + 1\n",
    "        if i % 500 == 0 and config == \"RGAT\":\n",
    "            pt_file_path = file_path + str(j) + \".pkl\"\n",
    "            with open(pt_file_path, 'wb') as file:  # Corrected the file path\n",
    "                pickle.dump(all_h_prime, file)\n",
    "            all_h_prime = []\n",
    "            j = j + 1\n",
    "            \n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(\"It took\", elapsed_time, \"seconds to encode train\", config)\n",
    "    \n",
    "    if config == \"RGAT\":\n",
    "        pt_file_path = file_path + str(j) + \".pkl\"\n",
    "        with open(pt_file_path, 'wb') as file:\n",
    "            pickle.dump(all_h_prime, file)\n",
    "    else:\n",
    "        with open(file_path, 'wb') as file:\n",
    "            pickle.dump(all_h_prime, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d3073ff8",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# features = torch.randn(14, 200)\n",
    "# edge_index = [torch.tensor([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13],\n",
    "#                             [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 0]])]\n",
    "# edge_type = [torch.tensor([1, 0, 2, 2, 2, 0, 1, 3, 2, 2, 0, 2, 2, 2])]\n",
    "# seq_lengths  = torch.tensor([[14]])\n",
    "# umask = torch.ones(1, 1, 14)\n",
    "# print(\"features: \", features.shape)\n",
    "# print(\"edge_index.shape: \", edge_index[0].shape)\n",
    "# print(\"edge_index: \", edge_index)\n",
    "# print(\"edge_type.shape: \", edge_type[0].shape)\n",
    "# print(\"edge_type: \", edge_type)\n",
    "# print(\"seq_lengths.shape: \", seq_lengths.shape)\n",
    "# print(\"seq_lengths: \", seq_lengths)\n",
    "# print(\"umask.shape: \", umask.shape)\n",
    "# print(\"umask: \", umask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b33d64f3",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# edge_type_mapping = {}\n",
    "\n",
    "# for j in range(2):\n",
    "#     for k in range(2):\n",
    "#         edge_type_mapping[str(j) + str(k) + '0'] = len(edge_type_mapping)\n",
    "#         edge_type_mapping[str(j) + str(k) + '1'] = len(edge_type_mapping)\n",
    "# edge_type_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648061a8",
   "metadata": {},
   "source": [
    "<h5>DGCN_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "75c77723",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding Progress: 100%|████████████████████████████████████████████████████████| 2160/2160 [00:28<00:00, 75.13batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 28.752536296844482 seconds to encode train dgcn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding Progress: 100%|██████████████████████████████████████████████████████████| 577/577 [00:12<00:00, 46.19batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 12.493099689483643 seconds to encode train dgcn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding Progress: 100%|██████████████████████████████████████████████████████████| 270/270 [00:09<00:00, 29.55batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 9.136579513549805 seconds to encode train dgcn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "file_path1 = 'embed/' + dataset_path + '/h_prime_BERT_DGCN_train.pkl'\n",
    "file_path2 = 'embed/' + dataset_path + '/h_prime_BERT_DGCN_test.pkl'\n",
    "file_path3 = 'embed/' + dataset_path + '/h_prime_BERT_DGCN_dev.pkl'\n",
    "\n",
    "if os.path.exists(file_path1) and os.path.exists(file_path2) and os.path.exists(file_path3):\n",
    "    print(\"All files exist. Skipping operation.\")\n",
    "else:\n",
    "    # Files do not exist, run the operations\n",
    "    model = GraphNetwork_RGCN(num_features=768, num_classes=7, num_relations=8, max_seq_len=30)\n",
    "    RelationEncoding(file_path1, dataLoaderTrain, model, \"dgcn\")\n",
    "    RelationEncoding(file_path2, dataLoaderTest, model, \"dgcn\")\n",
    "    RelationEncoding(file_path3, dataLoaderDev, model, \"dgcn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f46527c",
   "metadata": {},
   "source": [
    "<h5>GAT w/o edge_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f0bcdb",
   "metadata": {},
   "source": [
    "reviwing the types and shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "31e9a397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_edge_type[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "18aa4149",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# x = torch.randn((14, num_features))  # Example feature matrix with 14 nodes\n",
    "# edge_index = [torch.randint(0, 14, (2, 20))]  # Example edge index with 20 edges\n",
    "# edge_attr = [torch.randn((20, num_relations))]  # Example edge features\n",
    "# print(\"x.shape: \", x.shape)\n",
    "# print(\"edge_index.shape: \", edge_index[0].shape)\n",
    "# print(\"edge_attr.shape: \", edge_attr[0].shape)\n",
    "# print(\"x: \", x)\n",
    "# print(\"edge_index: \", edge_index)\n",
    "# print(\"edge_attr: \", edge_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "758ba04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding Progress: 100%|████████████████████████████████████████████████████████| 2160/2160 [00:26<00:00, 83.02batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 26.018385410308838 seconds to encode train GATv1_noAttn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding Progress: 100%|██████████████████████████████████████████████████████████| 577/577 [00:11<00:00, 51.90batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 11.119426250457764 seconds to encode train GATv1_noAttn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding Progress: 100%|██████████████████████████████████████████████████████████| 270/270 [00:08<00:00, 31.14batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 8.673632860183716 seconds to encode train GATv1_noAttn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_features = 768\n",
    "num_classes = 7\n",
    "num_relations = 4  # Assuming edge features have 4 dimensions\n",
    "max_seq_len = 30\n",
    "hidden_size = 64\n",
    "num_heads = 8\n",
    "dropout = 0.5\n",
    "no_cuda = False\n",
    "\n",
    "file_path1 = 'embed/' + dataset_path + '/h_prime_BERT_GATv1_train.pkl'\n",
    "file_path2 = 'embed/' + dataset_path + '/h_prime_BERT_GATv1_test.pkl'\n",
    "file_path3 = 'embed/' + dataset_path + '/h_prime_BERT_GATv1_dev.pkl'\n",
    "\n",
    "if os.path.exists(file_path1) and os.path.exists(file_path2) and os.path.exists(file_path3):\n",
    "    print(\"All files exist. Skipping operation.\")\n",
    "else:\n",
    "    model = GraphNetwork_GAT(num_features, num_classes, num_relations, max_seq_len, hidden_size, num_heads, dropout, no_cuda)\n",
    "    RelationEncoding(file_path1, dataLoaderTrain, model, \"GATv1_noAttn\")\n",
    "    RelationEncoding(file_path2, dataLoaderTest, model, \"GATv1_noAttn\")\n",
    "    RelationEncoding(file_path3, dataLoaderDev, model, \"GATv1_noAttn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb39da0",
   "metadata": {},
   "source": [
    "<h5>GAT w/ edge_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "01092d30",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Dummy inputs for testing\n",
    "# x = torch.randn((14, num_features))  # Example feature matrix with 14 nodes\n",
    "# edge_index = [torch.randint(0, 14, (2, 20))]  # Example edge index with 20 edges\n",
    "# edge_attr = [torch.randn((20, num_relations))]  # Example edge features\n",
    "# print(edge_index[0].shape)\n",
    "# print(edge_attr[0].shape)\n",
    "# print(edge_index)\n",
    "# print(edge_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "195e2641",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding Progress: 100%|████████████████████████████████████████████████████████| 2160/2160 [00:26<00:00, 80.04batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 26.98904061317444 seconds to encode train GATv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding Progress: 100%|██████████████████████████████████████████████████████████| 577/577 [00:11<00:00, 50.95batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 11.328542709350586 seconds to encode train GATv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding Progress: 100%|██████████████████████████████████████████████████████████| 270/270 [00:08<00:00, 31.70batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 8.52159833908081 seconds to encode train GATv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_features = 768\n",
    "num_classes = 7\n",
    "num_relations = 8  # Assuming edge features have 4 dimensions\n",
    "max_seq_len = 14\n",
    "hidden_size = 64\n",
    "num_heads = 8\n",
    "dropout = 0.5\n",
    "no_cuda = False\n",
    "\n",
    "model = GraphNetwork_GAT_EdgeFeat(num_features, num_classes, num_relations, max_seq_len, hidden_size, num_heads, dropout, no_cuda)\n",
    "\n",
    "file_path1 = 'embed/' + dataset_path + '/h_prime_BERT_GATv1_edgeAttr_train.pkl'\n",
    "file_path2 = 'embed/' + dataset_path + '/h_prime_BERT_GATv1_edgeAttr_test.pkl'\n",
    "file_path3 = 'embed/' + dataset_path + '/h_prime_BERT_GATv1_edgeAttr_dev.pkl'\n",
    "\n",
    "if os.path.exists(file_path1) and os.path.exists(file_path2) and os.path.exists(file_path3):\n",
    "    print(\"All files exist. Skipping operation.\")\n",
    "else:\n",
    "    RelationEncoding(file_path1, dataLoaderTrain, model, \"GATv1\")\n",
    "    RelationEncoding(file_path2, dataLoaderTest, model, \"GATv1\")\n",
    "    RelationEncoding(file_path3, dataLoaderDev, model, \"GATv1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d06c4f7",
   "metadata": {},
   "source": [
    "<h5>GATv2 w/o edge_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ff3525a0",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# x = torch.randn((14, num_features))  # Example feature matrix with 14 nodes\n",
    "# edge_index = torch.randint(0, 14, (2, 20))  # Example edge index with 20 edges\n",
    "# edge_attr = torch.randn((20, 1))  # Example edge features\n",
    "# print(x.shape)\n",
    "# print(edge_index.shape)\n",
    "# print(edge_attr.shape)\n",
    "# print(x)\n",
    "# print(edge_index)\n",
    "# print(edge_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0a40b659",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding Progress: 100%|████████████████████████████████████████████████████████| 2160/2160 [00:24<00:00, 87.25batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 24.75721836090088 seconds to encode train GATv2_noAttn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding Progress: 100%|██████████████████████████████████████████████████████████| 577/577 [00:10<00:00, 53.16batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 10.858783721923828 seconds to encode train GATv2_noAttn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding Progress: 100%|██████████████████████████████████████████████████████████| 270/270 [00:08<00:00, 32.63batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 8.276646375656128 seconds to encode train GATv2_noAttn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_features = 768\n",
    "num_classes = 7\n",
    "hidden_size = 64\n",
    "num_heads = 8\n",
    "dropout = 0.5\n",
    "no_cuda = False\n",
    "model = GraphNetwork_GATv2(num_features, num_classes, hidden_size, num_heads, dropout, no_cuda)\n",
    "file_path1 = 'embed/' + dataset_path + '/h_prime_BERT_GATv2_train.pkl'\n",
    "file_path2 = 'embed/' + dataset_path + '/h_prime_BERT_GATv2_test.pkl'\n",
    "file_path3 = 'embed/' + dataset_path + '/h_prime_BERT_GATv2_dev.pkl'\n",
    "\n",
    "if os.path.exists(file_path1) and os.path.exists(file_path2) and os.path.exists(file_path3):\n",
    "    print(\"All files exist. Skipping operation.\")\n",
    "else:\n",
    "    RelationEncoding(file_path1, dataLoaderTrain, model, \"GATv2_noAttn\")\n",
    "    RelationEncoding(file_path2, dataLoaderTest, model, \"GATv2_noAttn\")\n",
    "    RelationEncoding(file_path3, dataLoaderDev, model, \"GATv2_noAttn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cb8298",
   "metadata": {},
   "source": [
    "<h5>GATv2 w/ edge_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ea9a6dcd",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# x = torch.randn((14, num_features))  # Example feature matrix with 14 nodes\n",
    "# edge_index = torch.randint(0, 14, (2, 20))  # Example edge index with 20 edges\n",
    "# edge_attr = torch.randn((20, num_relations))  # Example edge features\n",
    "# print(x.shape)\n",
    "# print(edge_index.shape)\n",
    "# print(edge_attr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "245ee655",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding Progress: 100%|████████████████████████████████████████████████████████| 2160/2160 [00:29<00:00, 74.34batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 29.053797483444214 seconds to encode train GATv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding Progress: 100%|██████████████████████████████████████████████████████████| 577/577 [00:12<00:00, 46.60batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 12.383018493652344 seconds to encode train GATv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding Progress: 100%|██████████████████████████████████████████████████████████| 270/270 [00:11<00:00, 24.22batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 11.149035692214966 seconds to encode train GATv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_features = 768\n",
    "num_classes = 7\n",
    "num_relations = 8\n",
    "max_seq_len = 30\n",
    "hidden_size = 64\n",
    "num_heads = 8\n",
    "dropout = 0.5\n",
    "no_cuda = False\n",
    "\n",
    "model = GraphNetwork_GATv2_EdgeFeat(num_features, num_classes, num_relations, max_seq_len, hidden_size, num_heads, dropout, no_cuda)\n",
    "file_path1 = 'embed/' + dataset_path + '/h_prime_BERT_GATv2_edgeAttr_train.pkl'\n",
    "file_path2 = 'embed/' + dataset_path + '/h_prime_BERT_GATv2_edgeAttr_test.pkl'\n",
    "file_path3 = 'embed/' + dataset_path + '/h_prime_BERT_GATv2_edgeAttr_dev.pkl'\n",
    "\n",
    "if os.path.exists(file_path1) and os.path.exists(file_path2) and os.path.exists(file_path3):\n",
    "    print(\"All files exist. Skipping operation.\")\n",
    "else:\n",
    "    RelationEncoding(file_path1, dataLoaderTrain, model, \"GATv2\")\n",
    "    RelationEncoding(file_path2, dataLoaderTest, model, \"GATv2\")\n",
    "    RelationEncoding(file_path3, dataLoaderDev, model, \"GATv2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609069ea",
   "metadata": {},
   "source": [
    "<h5> RGAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "db77a2c4",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# # Dummy inputs for testing\n",
    "# x = torch.randn((14, num_features))  # Example feature matrix with 14 nodes\n",
    "# edge_index = torch.randint(0, 14, (2, 20))  # Example edge index with 20 edges\n",
    "# edge_type = torch.randint(0, num_relations, (20,))  # Example edge types\n",
    "# # edge_attr = torch.randn((20, 1))  # Example edge features\n",
    "# print(edge_type.shape)\n",
    "# print(edge_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7b92fc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding Progress: 100%|████████████████████████████████████████████████████████| 2160/2160 [02:16<00:00, 15.81batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 136.6286735534668 seconds to encode train RGAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding Progress: 100%|██████████████████████████████████████████████████████████| 577/577 [00:43<00:00, 13.29batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 43.419180393218994 seconds to encode train RGAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding Progress: 100%|██████████████████████████████████████████████████████████| 270/270 [00:16<00:00, 16.25batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 16.619714498519897 seconds to encode train RGAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_features = 768\n",
    "num_classes = 7\n",
    "num_relations = 8\n",
    "hidden_size = 64\n",
    "num_heads = 8\n",
    "dropout = 0.5\n",
    "edge_dim = 1  # Dimensionality of edge attributes\n",
    "no_cuda = False\n",
    "\n",
    "model = GraphNetwork_RGAT(num_features, num_classes, num_relations, hidden_size, num_heads, dropout, edge_dim, no_cuda)\n",
    "file_path1 = 'embed/' + dataset_path + '/h_prime_BERT_RGAT_train'\n",
    "file_path2 = 'embed/' + dataset_path + '/h_prime_BERT_RGAT_test'\n",
    "file_path3 = 'embed/' + dataset_path + '/h_prime_BERT_RGAT_dev'\n",
    "\n",
    "if os.path.exists(file_path1) and os.path.exists(file_path2) and os.path.exists(file_path3):\n",
    "    print(\"All files exist. Skipping operation.\")\n",
    "else:\n",
    "    RelationEncoding(file_path1, dataLoaderTrain, model, \"RGAT\")\n",
    "    RelationEncoding(file_path2, dataLoaderTest, model, \"RGAT\")\n",
    "    RelationEncoding(file_path3, dataLoaderDev, model, \"RGAT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "36a4c8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combinePartitionedData(file_paths, output_file_path):\n",
    "    combined_data = []\n",
    "\n",
    "    for file_path in file_paths:\n",
    "        if os.path.isfile(file_path):\n",
    "            try:\n",
    "                with open(file_path, 'rb') as file:\n",
    "                    data = pickle.load(file)\n",
    "                    combined_data.extend(data)\n",
    "            except (pickle.UnpicklingError, EOFError) as e:\n",
    "                print(f\"Error loading data from {file_path}: {e}\")\n",
    "            except Exception as e:\n",
    "                print(f\"An unexpected error occurred while processing {file_path}: {e}\")\n",
    "        else:\n",
    "            print(f\"File {file_path} does not exist and will be skipped.\")\n",
    "\n",
    "    # Save the combined data to a new pickle file\n",
    "    try:\n",
    "        with open(output_file_path, 'wb') as file:\n",
    "            pickle.dump(combined_data, file)\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving combined data to {output_file_path}: {e}\")\n",
    "        return\n",
    "\n",
    "    # Delete the original files\n",
    "    for file_path in file_paths:\n",
    "        if os.path.isfile(file_path):\n",
    "            try:\n",
    "                os.remove(file_path)\n",
    "            except OSError as e:\n",
    "                print(f\"Error deleting file {file_path}: {e}\")\n",
    "        \n",
    "file_paths1 = ['embed/' + dataset_path + '/h_prime_BERT_RGAT_train1.pkl', 'embed/' + dataset_path + '/h_prime_BERT_RGAT_train2.pkl', 'embed/' + dataset_path + '/h_prime_BERT_RGAT_train3.pkl', 'embed/' + dataset_path + '/h_prime_BERT_RGAT_train4.pkl', 'embed/' + dataset_path + '/h_prime_BERT_RGAT_train5.pkl']\n",
    "file_paths2 = ['embed/' + dataset_path + '/h_prime_BERT_RGAT_test1.pkl', 'embed/' + dataset_path + '/h_prime_BERT_RGAT_test2.pkl']\n",
    "file_paths3 = ['embed/' + dataset_path + '/h_prime_BERT_RGAT_dev1.pkl']\n",
    "output_file_path1 = 'embed/' + dataset_path + '/h_prime_BERT_RGAT_train.pkl'\n",
    "output_file_path2 = 'embed/' + dataset_path + '/h_prime_BERT_RGAT_test.pkl'\n",
    "output_file_path3 = 'embed/' + dataset_path + '/h_prime_BERT_RGAT_dev.pkl'\n",
    "\n",
    "combinePartitionedData(file_paths1, output_file_path1)\n",
    "combinePartitionedData(file_paths2, output_file_path2)\n",
    "combinePartitionedData(file_paths3, output_file_path3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e016df95",
   "metadata": {},
   "source": [
    "end of encoding train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8da874fb",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# # change D_m into\n",
    "# D_m = 100\n",
    "# D_g = 150\n",
    "# D_p = 150\n",
    "# D_e = 100\n",
    "# D_h = 100\n",
    "# D_a = 100\n",
    "# graph_h=100\n",
    "# seed_everything()\n",
    "# model = DialogueGCN_MELDModel(\n",
    "#                                D_m, D_g, D_p, D_e, D_h, D_a, graph_h,\n",
    "#                                n_speakers=2,\n",
    "#                                max_seq_len=110,\n",
    "#                                window_past=0,\n",
    "#                                window_future=5,\n",
    "#                                n_classes=7,\n",
    "#                                listener_state=False,\n",
    "#                                context_attention='general',\n",
    "#                                dropout=0.5,\n",
    "#                                nodal_attention=False,\n",
    "#                                no_cuda=False\n",
    "#                                )\n",
    "# loss_function = nn.NLLLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8e759176",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# # Example usage\n",
    "# num_features = 200\n",
    "# num_classes = 7\n",
    "# num_relations = 3  # Example number of relations\n",
    "# max_seq_len = 30\n",
    "# hidden_size = 64\n",
    "# num_heads = 8\n",
    "# dropout = 0.5\n",
    "# no_cuda = False\n",
    "\n",
    "# model = GraphNetwork4WithRGAT(num_features, num_classes, num_relations, max_seq_len, hidden_size, num_heads, dropout, no_cuda)\n",
    "\n",
    "# # Dummy inputs for testing\n",
    "# x = torch.randn((14, num_features))  # Example feature matrix with 14 nodes\n",
    "# edge_index = torch.randint(0, 14, (2, 20))  # Example edge index with 20 edges\n",
    "# edge_type = torch.randint(0, num_relations, (20,))  # Example edge types\n",
    "# edge_attr = torch.randn((20, 1))  # Example edge features\n",
    "\n",
    "# # Forward pass\n",
    "# out = model(x, edge_index, edge_type=edge_type, edge_attr=edge_attr)\n",
    "# print(\"Output shape:\", out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "18936917",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# def train_or_eval_graph_model(model, loss_function, dataloader, epoch, cuda, optimizer=None, train=False):\n",
    "#     losses, preds, labels = [], [], []\n",
    "#     scores, vids = [], []\n",
    "    \n",
    "#     ei, et, en, el = torch.empty(0).type(torch.LongTensor), torch.empty(0).type(torch.LongTensor), torch.empty(0), []\n",
    "    \n",
    "#     assert not train or optimizer != None\n",
    "#     if train:\n",
    "#         model.train()\n",
    "#     else:\n",
    "#         model.eval()\n",
    "        \n",
    "#     seed_everything()\n",
    "#     for data in dataloader:\n",
    "#         if train:\n",
    "#             optimizer.zero_grad()\n",
    "            \n",
    "#         labels, features, edge_index, edge_type, edge_index_lengths, umask, _ = data\n",
    "#         print(\"features: \", features[0].shape)\n",
    "#         print(\"edge_index: \", edge_index[0].shape)\n",
    "# #         print(edge_norm[0].shape)\n",
    "#         print(\"edge_type: \", edge_type[0].shape)\n",
    "#         print(\"edge_index_lengths: \", edge_index_lengths[0])\n",
    "#         print(\"umask: \", umask[0].shape)\n",
    "#         print(\"-------------------------------\")\n",
    "#         log_prob, e_i, e_n, e_t, e_l = model(features, edge_index,\n",
    "# #                                              edge_norm,\n",
    "#                                              edge_type, edge_index_lengths, umask)\n",
    "#         label = torch.cat([label[j][:lengths[j]] for j in range(len(label))])\n",
    "#         loss = loss_function(log_prob, label)\n",
    "\n",
    "#         ei = torch.cat([ei, e_i], dim=1)\n",
    "#         et = torch.cat([et, e_t])\n",
    "#         en = torch.cat([en, e_n])\n",
    "#         el += e_l\n",
    "\n",
    "#         preds.append(torch.argmax(log_prob, 1).cpu().numpy())\n",
    "#         labels.append(label.cpu().numpy())\n",
    "#         losses.append(loss.item())\n",
    "\n",
    "#         if train:\n",
    "#             loss.backward()\n",
    "#             if args.tensorboard:\n",
    "#                 for param in model.named_parameters():\n",
    "#                     writer.add_histogram(param[0], param[1].grad, epoch)\n",
    "#             optimizer.step()\n",
    "            \n",
    "#     if preds != []:\n",
    "#         preds = np.concatenate(preds)\n",
    "#         labels = np.concatenate(labels)\n",
    "#     else:\n",
    "#         return float('nan'), float('nan'), [], [], float('nan'), [], [], [], [], []\n",
    "    \n",
    "#     ei = ei.data.cpu().numpy()\n",
    "#     et = et.data.cpu().numpy()\n",
    "#     en = en.data.cpu().numpy()\n",
    "#     el = np.array(el)\n",
    "#     labels = np.array(labels)\n",
    "#     preds = np.array(preds)\n",
    "\n",
    "#     avg_loss = round(np.sum(losses) / len(losses), 4)\n",
    "#     avg_accuracy = round(accuracy_score(labels, preds) * 100, 2)\n",
    "#     avg_fscore = round(f1_score(labels, preds, average='macro') * 100, 2)\n",
    "#     # Add precision and recall\n",
    "#     precision = round(precision_score(labels, preds, average='macro') * 100, 2)\n",
    "#     recall = round(recall_score(labels, preds, average='macro') * 100, 2)\n",
    "#     return avg_loss, avg_accuracy, labels, preds, avg_fscore, ei, et, en, el, precision, recall\n",
    "    \n",
    "    \n",
    "# for e in range(60):\n",
    "#     train_loss, train_acc, _, _, _, train_fscore, _ = train_or_eval_graph_model(model, loss_function,\n",
    "#                                                                           dataloader, e,\n",
    "#                                                                           optimizer, True)\n",
    "#     print(\n",
    "#     'epoch: {}, train_loss: {}, train_acc: {}, train_fscore: {}, train_precision: {}, train_recall: {}, '. \\\n",
    "#     format(e + 1, train_loss, train_acc, train_fscore, train_precision, train_recall))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c871b0b4",
   "metadata": {},
   "source": [
    "<h4> Creating graph features from Test Data (NO NEED FOR THIS SECTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "de3baa3e",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# checkFile = os.path.isfile(\"data/dump/speaker_encoder_test.pkl\")\n",
    "# encodedSpeakersTest = []\n",
    "# rangesTest = []\n",
    "\n",
    "# if not checkFile:\n",
    "#     print(\"Run first the contextEncoder2 to generate this file\")\n",
    "# else:\n",
    "#     with open('data/dump/speaker_encoder_test.pkl', \"rb\") as file:\n",
    "#         encodedSpeakersTest, rangesTest = pickle.load(file)\n",
    "\n",
    "# checkFile = os.path.isfile(\"data/dump/adjListTest.pkl\")\n",
    "# adjacencyListTest = []\n",
    "\n",
    "# if key:\n",
    "#     adjacencyListTest = get_all_adjacency_list(rangesTest)\n",
    "# else:\n",
    "#     with open('data/dump/adjListTest', \"rb\") as file:\n",
    "#         adjacencyListTest = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d0b9fb93",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# file_path = 'embed/u_prime_CNNBiLSTM_test.pkl'\n",
    "\n",
    "# # Load the list from the file using pickle\n",
    "# with open(file_path, 'rb') as file:\n",
    "#     contextualEmbeddingsTest = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "29deca27",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# edgeIndicesTest = get_all_adjacency_list(rangesTest)\n",
    "# edgeTypesTest = get_all_edge_type_list(edgeIndicesTest, encodedSpeakersTest)\n",
    "# edgeIndicesTest = get_all_adjacency_list(rangesTest, key=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3e5796",
   "metadata": {},
   "source": [
    "<h4> Creating graph features from Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f0634150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO repeat the one above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c36c94f",
   "metadata": {},
   "source": [
    "<h3> Get GAT output from each set of data (DISCONTINUED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f024704",
   "metadata": {},
   "source": [
    "<h4> Instantiating the GAT (1st implementation) for 1 sample train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cacafa9a",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# num_in_features = len(contextualEmbeddingsTrain[0][0])\n",
    "# num_out_features = len(contextualEmbeddingsTrain[0][0])\n",
    "# num_heads = 4\n",
    "# num_edge_types = 3\n",
    "# gat_layer = GATLayerWithEdgeType(num_in_features, num_out_features, num_heads, num_edge_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "98a8775c",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# i = 0  # dialogue id\n",
    "# relationalEmbedding, attentionCoef = gat_layer((contextualEmbeddingsTrain[i], edgeIndicesTrain[i]), edgeTypesTrain[i])\n",
    "# print(\"h_prime shape: \", relationalEmbedding.shape, \"attention_coef shape: \", attentionCoef.shape)\n",
    "\n",
    "# targetNodes = edgeIndicesTrain[i][1].tolist()\n",
    "\n",
    "# sample = {}\n",
    "# sampleEdgetypes = []\n",
    "\n",
    "# for target_i in sorted(set(targetNodes)):\n",
    "#     sample[target_i] = []\n",
    "\n",
    "# for targetNode, idx in zip(targetNodes, range(len(targetNodes))):\n",
    "#     sample[targetNode].append([idx, relationalEmbedding[targetNode][idx].tolist()])\n",
    "\n",
    "# listEdgeIdxTrain, inferredEdgeTypes = get_inferred_edgetypes_GAT(sample, edgeTypesTrain[i])\n",
    "# sampleEdgetypes.append(inferredEdgeTypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fc9c28c3",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anger', 'disgust', 'fear', 'joy', 'neutral', 'sadness', 'surprise']\n"
     ]
    }
   ],
   "source": [
    "file = open('data/dump/' + dataset_path + '/label_decoder.pkl', 'rb')\n",
    "label_decoder = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "label_decoder = list(label_decoder.values())\n",
    "print(label_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5ca6003c",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# checkFile = os.path.isfile(\"data/dump/labels_train.pkl\")\n",
    "\n",
    "# if checkFile is False:\n",
    "#     print(\"Please run the contextEncoder1 notebook to save the label file\")\n",
    "# else:\n",
    "#     file = open('data/dump/labels_train.pkl', 'rb')\n",
    "#     y_train = pickle.load(file)\n",
    "#     file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c02f789e",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# y_train[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c6f3e8e1",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# checkFile = os.path.isfile(\"data/dump/labels_test.pkl\")\n",
    "\n",
    "# if checkFile is False:\n",
    "#     print(\"Please run the contextEncoder2 notebook to save the label file\")\n",
    "# else:\n",
    "#     file = open('data/dump/labels_test.pkl', 'rb')\n",
    "#     y_test = pickle.load(file)\n",
    "#     file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42223125",
   "metadata": {},
   "source": [
    "<h5>Unsupervised Visualizarion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d1a41a39",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# # Assuming h_prime contains the node embeddings\n",
    "# utt_size = 13\n",
    "# labels = torch.tensor(y_train[:utt_size + 1])\n",
    "\n",
    "# cherrypicked_nodes = []\n",
    "# for src_idx, edge_idx in zip(range(len(list_edge_idx)), list_edge_idx):\n",
    "#     cherrypicked_nodes.append(attention_coef[src_idx, :, edge_idx].tolist())\n",
    "# cherrypicked_nodes = torch.tensor(cherrypicked_nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "47a97231",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# h_prime_np = cherrypicked_nodes.detach().numpy()\n",
    "\n",
    "# # Perform dimensionality reduction using t-SNE\n",
    "# tsne = TSNE(n_components=3, perplexity=5, random_state=42)\n",
    "# h_prime_tsne = tsne.fit_transform(h_prime_np)\n",
    "\n",
    "# # Plot the node embeddings with different colors for each label\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# for label, emotion in zip(range(len(label_decoder)), label_decoder): \n",
    "#     indices = (labels == label).nonzero().squeeze()\n",
    "#     plt.scatter(h_prime_tsne[indices, 0], h_prime_tsne[indices, 1], label=f'{emotion}')\n",
    "# plt.title('Node Embeddings Visualization (t-SNE)', color=\"white\")\n",
    "# plt.xlabel('Dimension 1', color=\"white\")\n",
    "# plt.ylabel('Dimension 2', color=\"white\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8043a6a",
   "metadata": {},
   "source": [
    "<h4> Now get new representations of all train, test, validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "588776d9",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# # filePath = data/dump/h_prime_BERT-GAT_train.pkl\n",
    "# #            data/dump/h_prime_BERT-GAT_test.pkl\n",
    "# #            data/dump/h_prime_BERT-GAT_valid.pkl\n",
    "\n",
    "# def get_GAT_representation(filePath, contextualEmbeddings, edgeIndices, edgeTypes):\n",
    "# #     checkFile = os.path.isfile(\"data/dump/h_prime_BERT-GAT_train.pkl\") #replace it with key when deployed\n",
    "#     if key:\n",
    "#         print(\"Start of getting output of 1st GAT\")\n",
    "#         allInferredEdgetypes = []\n",
    "#         listAllEdgeIdx = []\n",
    "#         cherrypickedNodes = []\n",
    "#         for dialog, dialog_id in zip(contextualEmbeddings, range(len(contextualEmbeddings))):\n",
    "#             h_prime, attention_coef = gat_layer((dialog, edgeIndices[dialog_id]), edgeTypes[dialog_id])\n",
    "#             target_nodes = edgeIndices[dialog_id][1].tolist() # first idx represents dialogue id\n",
    "\n",
    "#             sample_edgetypes = {}\n",
    "#             for i in set(target_nodes):\n",
    "#                 sample_edgetypes[i] = []\n",
    "\n",
    "#             for target_node, edge_idx in zip(target_nodes, range(len(target_nodes))):\n",
    "#                 sample_edgetypes[target_node].append([edge_idx, h_prime[target_node][edge_idx].tolist()])\n",
    "\n",
    "#             list_edge_idx, inferred_edgetypes = get_inferred_edgetypes_GAT(sample_edgetypes,  edgeTypes[dialog_id])\n",
    "#             listAllEdgeIdx.append(list_edge_idx)\n",
    "#             allInferredEdgetypes.append(inferred_edgetypes)\n",
    "\n",
    "#             for src_idx, edge_idx in zip(range(len(list_edge_idx)), list_edge_idx):\n",
    "#                 cherrypickedNodes.append(attention_coef[src_idx, :, edge_idx].tolist())\n",
    "\n",
    "#         cherrypickedNodes = torch.tensor(cherrypickedNodes)\n",
    "#         cherrypickedNodes.shape\n",
    "#         print(\"End of getting output of 1st GAT\")\n",
    "\n",
    "#         pickle.dump([cherrypickedNodes, allInferredEdgetypes],\n",
    "#                     open(filePath, 'wb'))\n",
    "\n",
    "#     else:\n",
    "#         file = open(filePath, 'rb')\n",
    "#         cherrypickedNodes, allInferredEdgetypes = pickle.load(file)\n",
    "#         file.close()\n",
    "\n",
    "#     return cherrypickedNodes, allInferredEdgetypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d2ef42f2",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# # train data\n",
    "# cherrypickedNodesTrain, allInferredEdgetypesTrain = get_GAT_representation(\n",
    "#                                                     \"embed/h_prime_CNNBiLSTM-GAT_train.pkl\",\n",
    "#                                                     contextualEmbeddingsTrain,\n",
    "#                                                     edgeIndicesTrain,\n",
    "#                                                     edgeTypesTrain)\n",
    "# # only save the pickle data for test and validation\n",
    "# _, _ = get_GAT_representation(\"embed/h_prime_CNNBiLSTM-GAT_test.pkl\",\n",
    "#                         contextualEmbeddingsTest,\n",
    "#                         edgeIndicesTest,\n",
    "#                         edgeTypesTest)\n",
    "# # TODO add valid set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de95f55",
   "metadata": {},
   "source": [
    "<h5> Visualize Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7e56aa1c",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# labels = torch.tensor(trainLabels)\n",
    "# h_prime_np = cherrypickedNodesTrain.detach().numpy() (discontinued)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "548c237c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# runTSNE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dcd5bd42",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# if runTSNE:\n",
    "#     # List of perplexity values to loop over\n",
    "#     perplexity_values = [30, 100]\n",
    "\n",
    "#     # Loop over each perplexity value\n",
    "#     for perplexity in perplexity_values:\n",
    "#         # Initialize t-SNE with the current perplexity value\n",
    "#         tsne = TSNE(n_components=2, perplexity=perplexity, random_state=42)\n",
    "\n",
    "#         # Fit and transform the data using t-SNE\n",
    "#         h_prime_tsne = tsne.fit_transform(h_prime_np)\n",
    "\n",
    "#         # Plot the node embeddings with different colors for each label\n",
    "#         plt.figure(figsize=(10, 8))\n",
    "#         for label, emotion in zip(range(len(label_decoder)), label_decoder): \n",
    "#             indices = (labels == label).nonzero().squeeze()\n",
    "#             plt.scatter(h_prime_tsne[indices, 0], h_prime_tsne[indices, 1], label=f'{emotion}')\n",
    "#         plt.title(f'Node Embeddings Visualization (t-SNE) - Perplexity {perplexity}', color=\"white\")\n",
    "#         plt.xlabel('Dimension 1', color=\"white\")\n",
    "#         plt.ylabel('Dimension 2', color=\"white\")\n",
    "#         plt.legend()\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5caea68",
   "metadata": {},
   "source": [
    "<h4> Analyze the edgetypes of all train nodes in the context of a dialog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c236b455",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# # Assuming `all_inferred_edgetypes` and `y_train` are defined\n",
    "# df_eda = pd.DataFrame(\n",
    "#     {'edgetype': flatten_extend(allInferredEdgetypesTrain),\n",
    "#      'label': y_train,\n",
    "#     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "46b7f357",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# # Assuming `df_eda` and `CrosstabResult` are defined\n",
    "# CrosstabResult = pd.crosstab(index=df_eda['edgetype'], columns=df_eda['label'])\n",
    "\n",
    "# print(\"Crosstab Result:\")\n",
    "# print(CrosstabResult)\n",
    "# print()\n",
    "\n",
    "# # Performing Chi-squared test\n",
    "# ChiSqResult = chi2_contingency(CrosstabResult)\n",
    "\n",
    "# # P-Value is the Probability of H0 being True\n",
    "# # If P-Value > 0.05 then only we Accept the assumption(H0)\n",
    "# # H0: The variables are not correlated with each other.\n",
    "\n",
    "# print('The P-Value of the Chi-Squared Test is:', ChiSqResult[1])\n",
    "\n",
    "# if ChiSqResult[1] > 0.05:\n",
    "#     print(\"Variables are not correlated with each other\")\n",
    "# else:\n",
    "#     print(\"Two variables are correlated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540cb0a7",
   "metadata": {},
   "source": [
    "<h3> Get EGAT output from each set of data (train, test, validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "60061c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "egat = EGATConv(in_node_feats=len(contextualEmbeddingsTrain[0][0]),\n",
    "                    in_edge_feats=3,\n",
    "                    out_node_feats=64,\n",
    "                    out_edge_feats=3,\n",
    "                    num_heads=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cc9167ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_EGAT_representations(filePath, contextualEmbeddings, edgeIndices, edgeTypes, ranges):\n",
    "#     checkFile = os.path.isfile(\"data/dump/h_prime_BERT-EGAT_train.pkl\")\n",
    "    if key:\n",
    "#         print(\"Start of getting output of 2nd GAT\")\n",
    "        inferredEdgetypes = []\n",
    "        allNodeFeats = []\n",
    "\n",
    "        # Iterate over each dialogue\n",
    "        for dialog_id in tqdm(range(len(edgeIndices)), desc=\"Encoding Progress\", unit=\"batch\"):\n",
    "            startIdx, endIdx = ranges[dialog_id][0], ranges[dialog_id][1]\n",
    "            # Create a DGL graph\n",
    "            graph = dgl.graph((edgeIndices[dialog_id][0], edgeIndices[dialog_id][1]))\n",
    "\n",
    "            # Get one-hot encoded edge features\n",
    "            edge_feats = get_ohe(edgeTypes[dialog_id])\n",
    "\n",
    "            # Get outputs from the second GAT layer\n",
    "            egat_output = egat(graph, contextualEmbeddings[startIdx: endIdx+1], edge_feats)\n",
    "            new_node_feats, new_edge_feats = egat_output\n",
    "\n",
    "            # Compute mean edge features\n",
    "            mean_edge_feats = new_edge_feats.mean(dim=1)\n",
    "            allNodeFeats.append(new_node_feats.mean(dim=1).tolist())\n",
    "\n",
    "            # Prepare edge features for inference\n",
    "            target_nodes = edgeIndices[dialog_id][1].tolist()\n",
    "            sample_edgetypes = {}\n",
    "            for i in set(target_nodes):\n",
    "                sample_edgetypes[i] = []\n",
    "            for target_node, edge_idx in zip(target_nodes, range(len(target_nodes))):\n",
    "                sample_edgetypes[target_node].append([edge_idx, \n",
    "                                                      mean_edge_feats[edge_idx].tolist()])\n",
    "\n",
    "            # Infer edge types\n",
    "            sample_edgetypes = get_inferred_edgetypes_EGAT(sample_edgetypes, edgeTypes[dialog_id], \n",
    "                                                           len(contextualEmbeddings[startIdx: endIdx+1]), \n",
    "                                                           dialog_id)\n",
    "            inferredEdgetypes.append(sample_edgetypes)\n",
    "\n",
    "        # Flatten and convert node features to tensor\n",
    "        allNodeFeats = torch.tensor(flatten_extend(allNodeFeats))\n",
    "\n",
    "#         print(\"End of getting output of 2nd GAT\")\n",
    "\n",
    "        # Save the data to a pickle file\n",
    "        pickle.dump([allNodeFeats, inferredEdgetypes], open(filePath, 'wb'))\n",
    "    else:\n",
    "        # Load data from the exiflatten_extendsting pickle file\n",
    "        file = open(filePath, 'rb')\n",
    "        all_node_feats, inferredEdgetypes = pickle.load(file)\n",
    "        file.close()\n",
    "\n",
    "    return allNodeFeats, inferredEdgetypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c0afe0b4",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# tensor_squeezedTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a62f0ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (contextualEmbeddingsTrain)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "938645cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding Progress: 100%|███████████████████████████████████████████████████████| 2160/2160 [00:10<00:00, 207.52batch/s]\n",
      "Encoding Progress: 100%|█████████████████████████████████████████████████████████| 577/577 [00:02<00:00, 206.06batch/s]\n",
      "Encoding Progress: 100%|█████████████████████████████████████████████████████████| 270/270 [00:01<00:00, 211.20batch/s]\n"
     ]
    }
   ],
   "source": [
    "contextualEmbeddingsTrain_stacked = torch.cat(contextualEmbeddingsTrain, dim=0)\n",
    "allNodeFeatsTrain, inferredEdgetypesTrain = get_EGAT_representations(\n",
    "                                        \"embed/\" + dataset_path + \"/h_prime_BERT-EGAT_train.pkl\",\n",
    "                                        contextualEmbeddingsTrain_stacked,\n",
    "                                        edgeIndicesTrain,\n",
    "                                        edgeTypesTrain,\n",
    "                                        rangesTrain\n",
    "                                )\n",
    "\n",
    "contextualEmbeddingsTest_stacked = torch.cat(contextualEmbeddingsTest, dim=0)\n",
    "_, _ = get_EGAT_representations(\n",
    "        \"embed/\" + dataset_path + \"/h_prime_BERT-EGAT_test.pkl\",\n",
    "        contextualEmbeddingsTest_stacked,\n",
    "        edgeIndicesTest,\n",
    "        edgeTypesTest, \n",
    "        rangesTest\n",
    ")\n",
    "\n",
    "contextualEmbeddingsDev_stacked = torch.cat(contextualEmbeddingsDev, dim=0)\n",
    "_, _ = get_EGAT_representations(\n",
    "        \"embed/\" + dataset_path + \"/h_prime_BERT-EGAT_dev.pkl\",\n",
    "        contextualEmbeddingsDev_stacked,\n",
    "        edgeIndicesDev,\n",
    "        edgeTypesDev, \n",
    "        rangesDev\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2d83d383",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eda2 = pd.DataFrame(\n",
    "    {'edgetype': flatten_extend(inferredEdgetypesTrain),\n",
    "     'label': trainLabels,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bf36e606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crosstab Result:\n",
      " label        0    1    2     3     4    5     6\n",
      "edgetype                                       \n",
      "0            9    0    1     6     8    3     0\n",
      "1         1491  364  337  2304  5946  873  1490\n",
      "2            0    0    0     2     6    0     0\n",
      "The P-Value of the ChiSq Test is: 0.03765198295764648\n",
      "Two variables are correlated\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame from your data (df_eda2)\n",
    "# Assuming df_eda2 is already defined\n",
    "\n",
    "# Crosstabulation\n",
    "CrosstabResult2 = pd.crosstab(index=df_eda2['edgetype'], columns=df_eda2['label'])\n",
    "print(\"Crosstab Result:\\n\", CrosstabResult2)\n",
    "\n",
    "# Performing Chi-squared test\n",
    "ChiSqResult2 = chi2_contingency(CrosstabResult2)\n",
    "\n",
    "# Print the p-value of the Chi-squared test\n",
    "print('The P-Value of the ChiSq Test is:', ChiSqResult2[1])\n",
    "\n",
    "# Interpret the p-value\n",
    "if ChiSqResult2[1] > 0.05:\n",
    "    print(\"Variables are not correlated with each other\")\n",
    "else:\n",
    "    print(\"Two variables are correlated\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0213c68a",
   "metadata": {},
   "source": [
    "Testing on 1 dialog data before scaling up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "84641d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dialog_id = 0\n",
    "\n",
    "# # Create a DGL graph\n",
    "# graph = dgl.graph((edgeIndicesTrain[dialog_id][0], edgeIndicesTrain[dialog_id][1]))\n",
    "\n",
    "# # Obtain one-hot encoded edge features\n",
    "# edge_feats = get_ohe(edgeTypesTrain[dialog_id])\n",
    "\n",
    "# # Pass the graph, node representations, and edge features through the EGAT model\n",
    "# contextualEmbeddingsTrain_stacked = torch.cat(contextualEmbeddingsTrain, dim=0)\n",
    "# newNodeFeats, newEdgeFeats = egat(graph, contextualEmbeddingsTrain_stacked[0:14], edge_feats)\n",
    "\n",
    "# # Print the shapes of the new node and edge features\n",
    "# print(\"New Node Features Shape:\", newNodeFeats.shape)\n",
    "# print(\"New Edge Features Shape:\", newEdgeFeats.shape)\n",
    "\n",
    "# # Calculate the mean of node features along the second dimension (number of nodes)\n",
    "# h_prime_mean = newNodeFeats.mean(dim=1)\n",
    "\n",
    "# # Assuming you want to select only a subset of labels for visualization\n",
    "# utt_size = 13\n",
    "# labels = torch.tensor(trainLabels[:utt_size+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0bbcf4d9",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# # Convert tensor to numpy array\n",
    "# h_prime_np = h_prime_mean.detach().numpy()\n",
    "# # Perform dimensionality reduction using t-SNE\n",
    "# tsne = TSNE(n_components=2, perplexity=5, random_state=42)\n",
    "# h_prime_tsne = tsne.fit_transform(h_prime_np)\n",
    "\n",
    "# # Plot the node embeddings with different colors for each label\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# for label, emotion Ain zip(range(len(label_decoder)), label_decoder): \n",
    "#     indices = (labels == label).nonzero().squeeze()\n",
    "#     plt.scatter(h_prime_tsne[indices, 0], h_prime_tsne[indices, 1], label=f'{emotion}')\n",
    "# plt.title('Node Embeddings Visualization (t-SNE)', color=\"white\")\n",
    "# plt.xlabel('Dimension 1', color=\"white\")\n",
    "# plt.ylabel('Dimension 2', color=\"white\")\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9e75975a",
   "metadata": {},
   "outputs": [],
   "source": [
    "runTSNE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "851a250c",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "if runTSNE:\n",
    "    # Convert tensor to numpy array\n",
    "    h_prime_np = allNodeFeatsTrain.detach().numpy()\n",
    "    labels = torch.tensor(trainLabels)\n",
    "    \n",
    "    # List of perplexity values to loop over\n",
    "    perplexity_values = [30, 100]\n",
    "\n",
    "    # Loop over each perplexity value\n",
    "    for perplexity in perplexity_values:\n",
    "        # Initialize t-SNE with the current perplexity value\n",
    "        tsne = TSNE(n_components=2, perplexity=perplexity, random_state=42)\n",
    "\n",
    "        # Fit and transform the data using t-SNE\n",
    "        h_prime_tsne = tsne.fit_transform(h_prime_np)\n",
    "        print(h_prime_tsne.shape)\n",
    "        \n",
    "        # Plot the node embeddings with different colors for each label\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        for label, emotion in zip(range(len(label_decoder)), label_decoder): \n",
    "            indices = (labels == label).nonzero().squeeze()\n",
    "            plt.scatter(h_prime_tsne[indices, 0], h_prime_tsne[indices, 1], label=f'{emotion}')\n",
    "        plt.title(f'Node Embeddings Visualization (t-SNE) - Perplexity {perplexity}', color=\"white\")\n",
    "        plt.xlabel('Dimension 1', color=\"white\")\n",
    "        plt.ylabel('Dimension 2', color=\"white\")\n",
    "        plt.legend()\n",
    "        plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
