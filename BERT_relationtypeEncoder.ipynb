{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dfdc889",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, os, math, pickle, sys, random, time\n",
    "from tqdm import tqdm\n",
    "import torch.nn.init as init\n",
    "import dgl,numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Parameter\n",
    "from collections import Counter\n",
    "import dgl.function as fn\n",
    "from dgl.nn.functional import edge_softmax\n",
    "import pandas as pd\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.nn import RGCNConv, GraphConv\n",
    "from model import DialogueGCN_MELDModel, GraphNetwork_RGCN, GraphNetwork_GAT, \\\n",
    "GraphNetwork_GAT_EdgeFeat, GraphNetwork_GATv2, GraphNetwork_GATv2_EdgeFeat, GraphNetwork_RGAT, \\\n",
    "MatchingAttention, getDataLoaderAndLabels\n",
    "from model import DATASET_PATH\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from graph_context_dataset import GraphContextDataset\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from model import FCClassifier, MyNetwork, DATASET_PATH, MatchingAttention\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b48d8bc7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f920f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "key=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a153dd45",
   "metadata": {},
   "source": [
    "<b>Make sure to specify which dataset to use\n",
    "<br>\n",
    " - dataset_original\n",
    "<br>\n",
    " - dataset_drop_noise\n",
    "<br>\n",
    " - dataset_smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a74ba53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_path = \"dataset_original\"\n",
    "# dataset_path = \"dataset_drop_noise\"\n",
    "# dataset_path = \"dataset_smote\"\n",
    "dataset_path = DATASET_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8aa9fe91",
   "metadata": {
    "code_folding": [
     0,
     38,
     60
    ]
   },
   "outputs": [],
   "source": [
    "class GATLayerWithEdgeType(nn.Module):\n",
    "    def __init__(self, num_in_features_per_head, num_out_features_per_head, num_heads, num_edge_types):\n",
    "        super(GATLayerWithEdgeType, self).__init__()\n",
    "        self.num_in_features_per_head = num_in_features_per_head\n",
    "        self.num_out_features_per_head = num_out_features_per_head\n",
    "        self.num_heads = num_heads\n",
    "        self.num_edge_types = num_edge_types\n",
    "\n",
    "        # Linear projection for node features\n",
    "        torch.manual_seed(42)\n",
    "        self.linear_proj = nn.Linear(self.num_in_features_per_head, self.num_heads * self.num_out_features_per_head)\n",
    "        \n",
    "        # Edge type embeddings\n",
    "        torch.manual_seed(42)\n",
    "        self.edge_type_embedding = nn.Embedding(self.num_edge_types, self.num_heads)\n",
    "        \n",
    "    def forward(self, input_data, edge_type):\n",
    "        node_features, edge_indices = input_data\n",
    "\n",
    "        # Linear projection for node features\n",
    "        h_linear = self.linear_proj(node_features.view(-1, self.num_in_features_per_head))\n",
    "        h_linear = h_linear.view(-1, self.num_heads, self.num_out_features_per_head)\n",
    "        h_linear = h_linear.permute(0, 2, 1)\n",
    "\n",
    "        # Edge type embedding\n",
    "        edge_type_embedding = self.edge_type_embedding(edge_type).transpose(0, 1)\n",
    "\n",
    "        # Perform matrix multiplication\n",
    "        attention_scores = torch.matmul(h_linear, edge_type_embedding).squeeze(-1)\n",
    "\n",
    "        # Softmax to get attention coefficients\n",
    "        attention_coefficients = F.softmax(attention_scores, dim=-1)\n",
    "\n",
    "        # Weighted sum of neighbor node representations\n",
    "        updated_representation = torch.matmul(attention_coefficients.transpose(1, 2), h_linear).mean(dim=2)\n",
    "\n",
    "        return updated_representation, attention_coefficients\n",
    "    \n",
    "class GATWithEdgeType(nn.Module):\n",
    "    def __init__(self, num_of_layers, num_heads_per_layer, num_features_per_layer, num_edge_types):\n",
    "        super(GATWithEdgeType, self).__init__()\n",
    "\n",
    "        self.gat_net = nn.ModuleList()\n",
    "\n",
    "        for layer in range(num_of_layers):\n",
    "            num_in_features = num_heads_per_layer[layer - 1] * num_features_per_layer[layer - 1] if layer > 0 else num_features_per_layer[0]\n",
    "            num_out_features = num_heads_per_layer[layer] * num_features_per_layer[layer]\n",
    "            self.gat_net.append(GATLayerWithEdgeType(num_in_features, num_out_features, num_heads_per_layer[layer], num_edge_types))\n",
    "\n",
    "    def forward(self, node_features, edge_indices, edge_types):\n",
    "        h = node_features\n",
    "\n",
    "        attention_scores = []\n",
    "\n",
    "        for layer in self.gat_net:\n",
    "            h, attention_coefficients = layer((h, edge_indices), edge_types)\n",
    "            attention_scores.append(attention_coefficients)\n",
    "\n",
    "        return h, attention_scores\n",
    "\n",
    "class EGATConv(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_node_feats,\n",
    "                 in_edge_feats,\n",
    "                 out_node_feats,\n",
    "                 out_edge_feats,\n",
    "                 num_heads,\n",
    "                 bias=True,\n",
    "                 **kw_args):\n",
    "\n",
    "        super().__init__()\n",
    "        self._num_heads = num_heads\n",
    "        self._out_node_feats = out_node_feats\n",
    "        self._out_edge_feats = out_edge_feats\n",
    "        \n",
    "        self.fc_node = nn.Linear(in_node_feats, out_node_feats * num_heads, bias=bias)\n",
    "        self.fc_ni = nn.Linear(in_node_feats, out_edge_feats * num_heads, bias=False)\n",
    "        self.fc_fij = nn.Linear(in_edge_feats, out_edge_feats * num_heads, bias=False)\n",
    "        self.fc_nj = nn.Linear(in_node_feats, out_edge_feats * num_heads, bias=False)\n",
    "        \n",
    "        # Attention parameter\n",
    "        self.attn = nn.Parameter(torch.FloatTensor(size=(1, num_heads, out_edge_feats)))\n",
    "        \n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.FloatTensor(size=(num_heads * out_edge_feats,)))\n",
    "        else:\n",
    "            self.register_buffer('bias', None)\n",
    "        \n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        torch.manual_seed(42)\n",
    "        gain = init.calculate_gain('relu')\n",
    "        init.xavier_normal_(self.fc_node.weight, gain=gain)\n",
    "        init.xavier_normal_(self.fc_ni.weight, gain=gain)\n",
    "        init.xavier_normal_(self.fc_fij.weight, gain=gain)\n",
    "        init.xavier_normal_(self.fc_nj.weight, gain=gain)\n",
    "        init.xavier_normal_(self.attn, gain=gain)\n",
    "        \n",
    "        if self.bias is not None:\n",
    "            nn.init.constant_(self.bias, 0)\n",
    "\n",
    "    def forward(self, graph, nfeats, efeats, get_attention=False):\n",
    "        with graph.local_scope():\n",
    "            graph.edata['f'] = efeats\n",
    "            graph.ndata['h'] = nfeats\n",
    "            \n",
    "            f_ni = self.fc_ni(nfeats)\n",
    "            f_nj = self.fc_nj(nfeats)\n",
    "            f_fij = self.fc_fij(efeats)\n",
    "            graph.srcdata.update({'f_ni' : f_ni})\n",
    "            graph.dstdata.update({'f_nj' : f_nj})\n",
    "            \n",
    "            graph.apply_edges(fn.u_add_v('f_ni', 'f_nj', 'f_tmp'))\n",
    "            f_out = graph.edata.pop('f_tmp') + f_fij\n",
    "            \n",
    "            if self.bias is not None:\n",
    "                f_out += self.bias\n",
    "            f_out = nn.functional.leaky_relu(f_out)\n",
    "            f_out = f_out.view(-1, self._num_heads, self._out_edge_feats)\n",
    "            \n",
    "            e = (f_out * self.attn).sum(dim=-1).unsqueeze(-1)\n",
    "            graph.edata['a'] = edge_softmax(graph, e)\n",
    "            graph.ndata['h_out'] = self.fc_node(nfeats).view(-1, self._num_heads, self._out_node_feats)\n",
    "            \n",
    "            graph.update_all(fn.u_mul_e('h_out', 'a', 'm'), fn.sum('m', 'h_out'))\n",
    "\n",
    "            h_out = graph.ndata['h_out'].view(-1, self._num_heads, self._out_node_feats)\n",
    "            if get_attention:\n",
    "                return h_out, f_out, graph.edata.pop('a')\n",
    "            else:\n",
    "                return h_out, f_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7adf37e",
   "metadata": {
    "code_folding": [
     0,
     11,
     29,
     31
    ]
   },
   "outputs": [],
   "source": [
    "def get_ohe(edge_types):\n",
    "    one_hot_encoding = []\n",
    "    for edge_type in edge_types:\n",
    "        if edge_type == 0:\n",
    "            one_hot_encoding.append([1., 0., 0.])\n",
    "        elif edge_type == 1:\n",
    "            one_hot_encoding.append([0., 1., 0.])\n",
    "        elif edge_type == 2:\n",
    "            one_hot_encoding.append([0., 0., 1.])\n",
    "    return torch.tensor(one_hot_encoding)\n",
    "\n",
    "def get_inferred_edgetypes_GAT(dialog, edge_types):\n",
    "    inferred_edge_types = []\n",
    "    inferred_edge_indices = []\n",
    "    for target_node in dialog.values():\n",
    "        if len(target_node) == 1:\n",
    "            inferred_edge_types.append(0)\n",
    "            inferred_edge_indices.append(0)\n",
    "        else:\n",
    "            edge_index = target_node[0][0]\n",
    "            highest_attention = target_node[0][1]\n",
    "            for src_node in target_node[1:]:\n",
    "                if highest_attention < src_node[1]:\n",
    "                    highest_attention = src_node[1]\n",
    "                    edge_index = src_node[0]\n",
    "            inferred_edge_indices.append(edge_index)\n",
    "            inferred_edge_types.append(edge_types[edge_index].tolist())\n",
    "    return inferred_edge_indices, inferred_edge_types\n",
    "\n",
    "def get_inferred_edgetypes_EGAT(edges_target_nodes, sample_edge_types, size_dialog, dialog_id):\n",
    "    inferred_edge_types = []\n",
    "    for target_idx in range(size_dialog):\n",
    "        num_edges = len(edges_target_nodes[target_idx])\n",
    "        if num_edges == 1:\n",
    "            edgetype_idx = np.argmax(edges_target_nodes[target_idx][0][1])\n",
    "            edge_idx = edges_target_nodes[target_idx][0][0]\n",
    "            inferred_edge_types.append(edgetype_idx)\n",
    "        else:\n",
    "            highest_attn_score = max(edges_target_nodes[target_idx][0][1])\n",
    "            edgetype_idx = np.argmax(edges_target_nodes[target_idx][0][1])\n",
    "            edge_idx = edges_target_nodes[target_idx][0][0]\n",
    "            for sample_edge in range(1, num_edges):\n",
    "                cur_highest_attn_score = max(edges_target_nodes[target_idx][sample_edge][1])\n",
    "                if cur_highest_attn_score > highest_attn_score:\n",
    "                    highest_attn_score = cur_highest_attn_score\n",
    "                    edgetype_idx = np.argmax(edges_target_nodes[target_idx][sample_edge][1])\n",
    "                    edge_idx = edges_target_nodes[target_idx][sample_edge][0]\n",
    "            inferred_edge_types.append(edgetype_idx)\n",
    "    return inferred_edge_types\n",
    "\n",
    "def flatten_extend(matrix):\n",
    "    flat_list = []\n",
    "    for row in matrix:\n",
    "        flat_list.extend(row)\n",
    "    return flat_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7639e77",
   "metadata": {
    "code_folding": [
     0,
     15,
     25,
     40
    ]
   },
   "outputs": [],
   "source": [
    "def create_node_pairs_list(start_idx, end_idx):\n",
    "    list_node_i = []\n",
    "    list_node_j = []\n",
    "    end_idx = end_idx - start_idx\n",
    "    start_idx = 0\n",
    "    for i in range(start_idx, end_idx+1):\n",
    "        val = 0\n",
    "        while (val <= 3) and (i+val <= end_idx):\n",
    "            target_idx = i+val\n",
    "            if target_idx >= 0:\n",
    "                list_node_i.append(i)\n",
    "                list_node_j.append(target_idx)\n",
    "            val = val+1\n",
    "    return [list_node_i, list_node_j]\n",
    "\n",
    "def create_adjacency_dict(node_pairs):\n",
    "    adjacency_list_dict = {}\n",
    "    for i in range(0, len(node_pairs[0])):\n",
    "        source_node, target_node = node_pairs[0][i], node_pairs[1][i]\n",
    "        if source_node not in adjacency_list_dict:\n",
    "            adjacency_list_dict[source_node] = [target_node]\n",
    "        else:\n",
    "            adjacency_list_dict[source_node].append(target_node)\n",
    "    return adjacency_list_dict\n",
    "\n",
    "def get_all_adjacency_list(ranges, key=0):\n",
    "    all_adjacency_list = []\n",
    "    for range_pair in ranges:\n",
    "        start_idx, end_idx = range_pair\n",
    "        if key == 0:\n",
    "            output = create_node_pairs_list(start_idx, end_idx)\n",
    "            output = create_adjacency_dict(output)\n",
    "        elif key == 1:\n",
    "            output = create_node_pairs_list(start_idx, end_idx)\n",
    "            output = torch.tensor(output)\n",
    "        else:\n",
    "            print(\"N/A\")\n",
    "        all_adjacency_list.append(output)\n",
    "    return all_adjacency_list\n",
    "\n",
    "def get_all_edge_type_list(edge_indices, encoded_speaker_list):\n",
    "    dialogs_len = len(edge_indices)\n",
    "    whole_edge_type_list = []\n",
    "    for i in range(dialogs_len):\n",
    "        dialog_nodes_pairs = edge_indices[i]\n",
    "        dialog_speakers = list(encoded_speaker_list[i])\n",
    "        dialog_len = len(dialog_nodes_pairs.keys())\n",
    "        edge_type_list = []\n",
    "        for j in range(dialog_len):\n",
    "            src_node = dialog_nodes_pairs[j]\n",
    "            node_i_idx = j\n",
    "            win_len = len(src_node)\n",
    "            for k in range(win_len):\n",
    "                node_j_idx = src_node[k]\n",
    "                if node_i_idx == node_j_idx:\n",
    "                    edge_type_list.append(0)\n",
    "                else:\n",
    "                    if dialog_speakers[node_i_idx] != dialog_speakers[node_j_idx]:\n",
    "                        edge_type_list.append(1)\n",
    "                    else:\n",
    "                        edge_type_list.append(2)\n",
    "        whole_edge_type_list.append(torch.tensor(edge_type_list).to(torch.int64))\n",
    "    return whole_edge_type_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ed53f3f",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=100):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ddb394",
   "metadata": {},
   "source": [
    "<h3> Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2c424c",
   "metadata": {},
   "source": [
    "<h4> Creating graph features from Train, Test and Validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d8a8f87",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# checkFile = os.path.isfile(\"data/dump/\" + dataset_path + \"/speaker_encoder_train.pkl\")\n",
    "# encodedSpeakersTrain = []\n",
    "# rangesTrain = []\n",
    "\n",
    "# if not checkFile:\n",
    "#     print(\"Run first the contextEncoder1 or 2 to generate this file\")\n",
    "# else:\n",
    "#     with open('data/dump/' + dataset_path + '/speaker_encoder_train.pkl', \"rb\") as file:\n",
    "#         encodedSpeakersTrain, rangesTrain = pickle.load(file)\n",
    "\n",
    "# checkFile = os.path.isfile(\"data/dump/\" + dataset_path +\"/adjListTrain.pkl\")\n",
    "# adjacencyListTrain = []\n",
    "\n",
    "# if key:\n",
    "#     adjacencyListTrain = get_all_adjacency_list(rangesTrain)\n",
    "# else:\n",
    "#     with open('data/dump/' + dataset_path + '/adjListTrain', \"rb\") as file:\n",
    "#         adjacencyListTrain = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f5170d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSpeakersAndRanges(file_path):\n",
    "    checkFile = os.path.isfile(file_path)\n",
    "    encodedSpeakers = []\n",
    "#     ranges = []\n",
    "    if not checkFile:\n",
    "        print(\"Run first the contextEncoder1.5 to generate this file\")\n",
    "        return None\n",
    "    else:\n",
    "        with open(file_path, \"rb\") as file:\n",
    "            encodedSpeakers, ranges = pickle.load(file)\n",
    "        return encodedSpeakers, ranges\n",
    "    \n",
    "def getAdjacencyList(file_path, ranges):\n",
    "    checkFile = os.path.isfile(file_path)\n",
    "    adjacencyList = []\n",
    "\n",
    "    if key:\n",
    "        adjacencyList = get_all_adjacency_list(ranges)\n",
    "    else:\n",
    "        with open(file_path, \"rb\") as file:\n",
    "            adjacencyList = pickle.load(file)\n",
    "    \n",
    "    return adjacencyList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7be6a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path1 = \"data/dump/\" + dataset_path + \"/speaker_encoder_train.pkl\"\n",
    "file_path2 = \"data/dump/\" + dataset_path + \"/speaker_encoder_test.pkl\"\n",
    "file_path3 = \"data/dump/\" + dataset_path + \"/speaker_encoder_dev.pkl\"\n",
    "\n",
    "encodedSpeakersTrain, rangesTrain = getSpeakersAndRanges(file_path1)\n",
    "encodedSpeakersTest, rangesTest = getSpeakersAndRanges(file_path2)\n",
    "encodedSpeakersDev, rangesDev = getSpeakersAndRanges(file_path3)\n",
    "\n",
    "file_path1 = 'data/dump/' + dataset_path + '/adjListTrain'\n",
    "file_path2 = 'data/dump/' + dataset_path + '/adjListTest'\n",
    "file_path3 = 'data/dump/' + dataset_path + '/adjListDev'\n",
    "\n",
    "adjacencyListTrain = getAdjacencyList(file_path1, rangesTrain)\n",
    "adjacencyListTest = getAdjacencyList(file_path1, rangesTest)\n",
    "adjacencyListDev = getAdjacencyList(file_path1, rangesDev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "771b8350",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path1 = 'embed/' + dataset_path + '/u_prime_BERT_train.pkl'\n",
    "file_path2 = 'embed/' + dataset_path + '/u_prime_BERT_test.pkl'\n",
    "file_path3 = 'embed/' + dataset_path + '/u_prime_BERT_dev.pkl'\n",
    "\n",
    "# Load the list from the file using pickle\n",
    "def getFeatures(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        emotions = pickle.load(file)\n",
    "    return emotions\n",
    "\n",
    "contextualEmbeddingsTrain = getFeatures(file_path1)\n",
    "contextualEmbeddingsTest = getFeatures(file_path2)\n",
    "contextualEmbeddingsDev = getFeatures(file_path3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6698b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(contextualEmbeddingsTrain.shape, contextualEmbeddingsTest.shape, contextualEmbeddingsDev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6055971",
   "metadata": {},
   "outputs": [],
   "source": [
    "edgeIndicesTrain = get_all_adjacency_list(rangesTrain)\n",
    "edgeTypesTrain = get_all_edge_type_list(edgeIndicesTrain, encodedSpeakersTrain)\n",
    "edgeIndicesTrain = get_all_adjacency_list(rangesTrain, key=1)\n",
    "\n",
    "edgeIndicesTest = get_all_adjacency_list(rangesTest)\n",
    "edgeTypesTest = get_all_edge_type_list(edgeIndicesTest, encodedSpeakersTest)\n",
    "edgeIndicesTest = get_all_adjacency_list(rangesTest, key=1)\n",
    "\n",
    "edgeIndicesDev = get_all_adjacency_list(rangesDev)\n",
    "edgeTypesDev = get_all_edge_type_list(edgeIndicesDev, encodedSpeakersDev)\n",
    "edgeIndicesDev = get_all_adjacency_list(rangesDev, key=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b48a81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e18118d",
   "metadata": {},
   "source": [
    "<h4> Creating \"SAMPLE\" graph features based on various graph networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16a469bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(rangesTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b197fe2",
   "metadata": {},
   "source": [
    "Start of sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc943c7d",
   "metadata": {},
   "source": [
    "<h5>DGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9caf12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.features = [torch.rand(14, 200)]\n",
    "        self.edge_index = [torch.randint(0, 14, (2, 69))]\n",
    "        self.edge_type = [torch.randint(0, 4, (69,))]\n",
    "        self.edge_index_lengths = [torch.tensor([69])]\n",
    "        self.umask = [torch.randint(0, 2, (1, 14))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.features[idx], self.edge_index[idx], self.edge_type[idx], self.edge_index_lengths[idx], self.umask[idx])\n",
    "\n",
    "# Create the dataset and dataloader\n",
    "dataset = SampleDataset()\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4874963d",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# features = torch.randn(14, 200)\n",
    "# edge_index = [torch.tensor([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13],\n",
    "#                             [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 0]])]\n",
    "# edge_type = [torch.tensor([1, 0, 2, 2, 2, 0, 1, 3, 2, 2, 0, 2, 2, 2])]\n",
    "# seq_lengths  = torch.tensor([[14]])\n",
    "# umask = torch.ones(1, 1, 14)\n",
    "\n",
    "# nodal_attn = False\n",
    "# avec = False\n",
    "\n",
    "# # Initialize the model\n",
    "# model = GraphNetwork_RGCN(num_features=200, num_classes=7, num_relations=4, max_seq_len=14)\n",
    "# gcn_representation = model(features, edge_index, edge_type)\n",
    "# print(\"GCN Representation Shape:\", gcn_representation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3846a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40d48a0",
   "metadata": {},
   "source": [
    "<h5>GAT w/o edge feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e6cdb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example usage:\n",
    "# num_features = 768\n",
    "# num_classes = 7\n",
    "# num_relations = 4  # This parameter is not used with GATConv but kept for compatibility\n",
    "# max_seq_len = 14\n",
    "# hidden_size = 64\n",
    "# num_heads = 8\n",
    "# dropout = 0.5\n",
    "# no_cuda = False\n",
    "\n",
    "# model = GraphNetwork_GAT(num_features, num_classes, num_relations, max_seq_len, hidden_size, num_heads, dropout, no_cuda)\n",
    "\n",
    "# # Dummy inputs for testing\n",
    "# x = torch.randn((14, num_features))  # Example feature matrix with 14 nodes\n",
    "# edge_index = [torch.randint(0, 14, (2, 20))]  # Example edge index with 20 edges\n",
    "# # edge_type = [torch.randint(0, num_relations, (20,))]  # Example edge types\n",
    "\n",
    "# # Forward pass\n",
    "# out = model(x, edge_index)\n",
    "# print(\"Output shape:\", out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0862804c",
   "metadata": {},
   "source": [
    "<h5>GAT with edge feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "276cee90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_features = 768\n",
    "# num_classes = 7\n",
    "# num_relations = 4  # Assuming edge features have 4 dimensions\n",
    "# max_seq_len = 14\n",
    "# hidden_size = 64\n",
    "# num_heads = 8\n",
    "# dropout = 0.5\n",
    "# no_cuda = False\n",
    "\n",
    "# model = GraphNetwork_GAT_EdgeFeat(num_features, num_classes, num_relations, max_seq_len,\n",
    "#                                   hidden_size, num_heads, dropout)\n",
    "\n",
    "# # Dummy inputs for testing\n",
    "# x = torch.randn((14, num_features))\n",
    "# edge_index = [torch.randint(0, 14, (2, 20))]\n",
    "# edge_attr = [torch.randn((20, num_relations))]\n",
    "\n",
    "# # Forward pass\n",
    "# out = model(x, edge_index, edge_attr)\n",
    "# print(\"Output shape:\", out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1869288a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# edge_attr = torch.randint(0, 2, (20, 1)).float()  # Example binary edge features\n",
    "# edge_attr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd71b632",
   "metadata": {},
   "source": [
    "<h5>GATv2 w/o edgetype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab557a25",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# num_features = 768\n",
    "# num_classes = 7\n",
    "# hidden_size = 64\n",
    "# num_heads = 8\n",
    "# dropout = 0.5\n",
    "# no_cuda = False\n",
    "\n",
    "# model = GraphNetwork_GATv2(num_features, num_classes, hidden_size, num_heads, dropout)\n",
    "\n",
    "# # Dummy inputs for testing\n",
    "# x = torch.randn((14, num_features))  # Example feature matrix with 14 nodes\n",
    "# edge_index = torch.randint(0, 14, (2, 20))  # Example edge index with 20 edges\n",
    "# edge_attr = torch.randn((20, 1))  # Example edge features\n",
    "\n",
    "# # Forward pass\n",
    "# out = model(x, edge_index, edge_attr)\n",
    "# print(\"Output shape:\", out.shape)\n",
    "\n",
    "# # Forward pass with attention weights\n",
    "# out, (edge_index, attention_weights) = model(x, edge_index, edge_attr, return_attention_weights=True)\n",
    "# print(\"Output shape with attention:\", out.shape)\n",
    "# print(\"Attention weights shape:\", attention_weights.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5781299",
   "metadata": {},
   "source": [
    "<h5>GATv2 with edge type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b5ae9cb",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# num_features = 768\n",
    "# num_classes = 7\n",
    "# num_relations = 4\n",
    "# max_seq_len = 30\n",
    "# hidden_size = 64\n",
    "# num_heads = 8\n",
    "# dropout = 0.5\n",
    "# no_cuda = False\n",
    "\n",
    "# model = GraphNetwork_GATv2_EdgeFeat(num_features, num_classes, num_relations,\n",
    "#                                     max_seq_len, hidden_size, num_heads, dropout)\n",
    "\n",
    "# x = torch.randn((14, num_features))  # Example feature matrix with 14 nodes\n",
    "# edge_index = torch.randint(0, 14, (2, 20))  # Example edge index with 20 edges\n",
    "# edge_attr = torch.randn((20, num_relations))  # Example edge features\n",
    "\n",
    "# # Forward pass\n",
    "# out = model(x, edge_index, edge_attr)\n",
    "# print(\"Output shape:\", out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6d91e3",
   "metadata": {},
   "source": [
    "<h5>RGAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d536b5f8",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e05a3a7e",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# num_features = 768\n",
    "# num_classes = 7\n",
    "# num_relations = 3  # Example number of relations\n",
    "# hidden_size = 64\n",
    "# num_heads = 8\n",
    "# dropout = 0.5\n",
    "# edge_dim = 1  # Dimensionality of edge attributes\n",
    "# no_cuda = False\n",
    "\n",
    "\n",
    "# model = GraphNetwork_RGAT(num_features, num_classes, num_relations, hidden_size, num_heads, dropout, \n",
    "#                           edge_dim)\n",
    "\n",
    "# # Dummy inputs for testing\n",
    "# x = torch.randn((14, num_features))  # Example feature matrix with 14 nodes\n",
    "# edge_index = torch.randint(0, 14, (2, 20))  # Example edge index with 20 edges\n",
    "# edge_type = torch.randint(0, num_relations, (20,))  # Example edge types\n",
    "# edge_attr = torch.randn((20, 1))  # Example edge features\n",
    "\n",
    "# # Forward pass\n",
    "# out = model(x, edge_index, edge_type=edge_type)\n",
    "# print(\"Output shape:\", out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de94a009",
   "metadata": {},
   "source": [
    "End of sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8317848a",
   "metadata": {},
   "source": [
    "<h4> Encode speaker to train, test, and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "69ad33d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path1 = ['embed/' + dataset_path + '/pre_h_prime_BERT_train.pkl', 'data/dump/' + dataset_path + '/labels_train.pkl']\n",
    "file_path2 = ['embed/' + dataset_path + '/pre_h_prime_BERT_test.pkl' , 'data/dump/' + dataset_path + '/labels_test.pkl']\n",
    "file_path3 = ['embed/' + dataset_path + '/pre_h_prime_BERT_dev.pkl', 'data/dump/' + dataset_path + '/labels_dev.pkl']\n",
    "\n",
    "dataLoaderTrain, trainLabels = getDataLoaderAndLabels(file_path1, rangesTrain)\n",
    "dataLoaderTest, testLabels = getDataLoaderAndLabels(file_path2, rangesTest)\n",
    "dataLoaderDev, devLabels = getDataLoaderAndLabels(file_path3, rangesDev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "76fc8abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RelationEncoding(file_path, dataLoader, model, config):\n",
    "    all_h_prime = []\n",
    "    all_matchatt = []\n",
    "    checkFile = os.path.isfile(file_path)\n",
    "    start_time = time.time()\n",
    "    batch_size = 500  # Batch size for saving intermediate results\n",
    "\n",
    "    i = 0\n",
    "    j = 1\n",
    "\n",
    "    for _, features_in, edge_index_in, edge_type_in, _ in tqdm(dataLoader, desc=\"Encoding Progress\", unit=\"batch\"):\n",
    "        if config == \"dgcn\":\n",
    "            feature = features_in.squeeze(0)\n",
    "            edge_index = edge_index_in.squeeze(0)\n",
    "            edge_type = edge_type_in.squeeze(0)\n",
    "            graph_representation = model(feature, [edge_index], [edge_type])\n",
    "        elif config == \"GATv1_noAttn\":\n",
    "            feature = features_in.squeeze(0)\n",
    "            edge_index = edge_index_in.squeeze(0)\n",
    "            graph_representation = model(feature, [edge_index])\n",
    "        elif config == \"GATv1\":\n",
    "            feature = features_in.squeeze(0)\n",
    "            edge_index = edge_index_in.squeeze(0)\n",
    "            edge_type = edge_type_in.squeeze(0)\n",
    "            num_edge_types = 8\n",
    "            edge_attr = torch.zeros((edge_type.size(0), num_edge_types))\n",
    "            edge_attr.scatter_(1, edge_type.view(-1, 1), 1)\n",
    "            graph_representation = model(feature, [edge_index], [edge_attr])\n",
    "        elif config == \"GATv2_noAttn\":\n",
    "            feature = features_in.squeeze(0)\n",
    "            edge_index = edge_index_in.squeeze(0)\n",
    "            graph_representation = model(feature, edge_index)\n",
    "        elif config == \"GATv2\":\n",
    "            feature = features_in.squeeze(0)\n",
    "            edge_index = edge_index_in.squeeze(0)\n",
    "            edge_type = edge_type_in.squeeze(0)\n",
    "            num_edge_types = 8\n",
    "            edge_attr = torch.zeros((edge_type.size(0), num_edge_types))\n",
    "            edge_attr.scatter_(1, edge_type.view(-1, 1), 1)\n",
    "            graph_representation = model(feature, edge_index, edge_attr)\n",
    "        elif config == \"RGAT\":\n",
    "            feature = features_in.squeeze(0)\n",
    "            edge_index = edge_index_in.squeeze(0)\n",
    "            edge_type = edge_type_in.squeeze(0)\n",
    "            graph_representation = model(x=feature, edge_index=edge_index, edge_type=edge_type)\n",
    "        \n",
    "        all_h_prime.append(graph_representation.cpu())\n",
    "\n",
    "        i += 1\n",
    "        if i % batch_size == 0 and config == \"RGAT\":\n",
    "            pt_file_path = f\"{file_path}_{j}.pkl\"\n",
    "            with open(pt_file_path, 'wb') as file:\n",
    "                pickle.dump(all_h_prime, file)\n",
    "            all_h_prime = []\n",
    "            j += 1\n",
    "            \n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(\"It took\", elapsed_time, \"seconds to encode train\", config)\n",
    "    \n",
    "    if all_h_prime:  # Save any remaining data\n",
    "        if config == \"RGAT\":\n",
    "            pt_file_path = f\"{file_path}_{j}.pkl\"\n",
    "            with open(pt_file_path, 'wb') as file:\n",
    "                pickle.dump(all_h_prime, file)\n",
    "        else:\n",
    "            with open(file_path, 'wb') as file:\n",
    "                pickle.dump(all_h_prime, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d3073ff8",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# features = torch.randn(14, 200)\n",
    "# edge_index = [torch.tensor([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13],\n",
    "#                             [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 0]])]\n",
    "# edge_type = [torch.tensor([1, 0, 2, 2, 2, 0, 1, 3, 2, 2, 0, 2, 2, 2])]\n",
    "# seq_lengths  = torch.tensor([[14]])\n",
    "# umask = torch.ones(1, 1, 14)\n",
    "# print(\"features: \", features.shape)\n",
    "# print(\"edge_index.shape: \", edge_index[0].shape)\n",
    "# print(\"edge_index: \", edge_index)\n",
    "# print(\"edge_type.shape: \", edge_type[0].shape)\n",
    "# print(\"edge_type: \", edge_type)\n",
    "# print(\"seq_lengths.shape: \", seq_lengths.shape)\n",
    "# print(\"seq_lengths: \", seq_lengths)\n",
    "# print(\"umask.shape: \", umask.shape)\n",
    "# print(\"umask: \", umask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b33d64f3",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# edge_type_mapping = {}\n",
    "\n",
    "# for j in range(2):\n",
    "#     for k in range(2):\n",
    "#         edge_type_mapping[str(j) + str(k) + '0'] = len(edge_type_mapping)\n",
    "#         edge_type_mapping[str(j) + str(k) + '1'] = len(edge_type_mapping)\n",
    "# edge_type_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648061a8",
   "metadata": {},
   "source": [
    "<h5>DGCN_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "75c77723",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding Progress: 100%|████████████████████████████████████████████████████████| 1588/1588 [00:20<00:00, 78.38batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 20.278258085250854 seconds to encode train dgcn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding Progress: 100%|██████████████████████████████████████████████████████████| 435/435 [00:10<00:00, 40.87batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 10.646728038787842 seconds to encode train dgcn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding Progress: 100%|██████████████████████████████████████████████████████████| 203/203 [00:08<00:00, 22.58batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 8.990310430526733 seconds to encode train dgcn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "file_path1 = 'embed/' + dataset_path + '/h_prime_BERT_DGCN_train.pkl'\n",
    "file_path2 = 'embed/' + dataset_path + '/h_prime_BERT_DGCN_test.pkl'\n",
    "file_path3 = 'embed/' + dataset_path + '/h_prime_BERT_DGCN_dev.pkl'\n",
    "\n",
    "if os.path.exists(file_path1) and os.path.exists(file_path2) and os.path.exists(file_path3):\n",
    "    print(\"All files exist. Skipping operation.\")\n",
    "else:\n",
    "    # Files do not exist, run the operations\n",
    "    model = GraphNetwork_RGCN(num_features=768, num_relations=8)\n",
    "    RelationEncoding(file_path1, dataLoaderTrain, model, \"dgcn\")\n",
    "    RelationEncoding(file_path2, dataLoaderTest, model, \"dgcn\")\n",
    "    RelationEncoding(file_path3, dataLoaderDev, model, \"dgcn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f46527c",
   "metadata": {},
   "source": [
    "<h5>GAT w/o edge_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f0bcdb",
   "metadata": {},
   "source": [
    "reviwing the types and shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "31e9a397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_edge_type[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "18aa4149",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# x = torch.randn((14, num_features))  # Example feature matrix with 14 nodes\n",
    "# edge_index = [torch.randint(0, 14, (2, 20))]  # Example edge index with 20 edges\n",
    "# edge_attr = [torch.randn((20, num_relations))]  # Example edge features\n",
    "# print(\"x.shape: \", x.shape)\n",
    "# print(\"edge_index.shape: \", edge_index[0].shape)\n",
    "# print(\"edge_attr.shape: \", edge_attr[0].shape)\n",
    "# print(\"x: \", x)\n",
    "# print(\"edge_index: \", edge_index)\n",
    "# print(\"edge_attr: \", edge_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "758ba04f",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding Progress: 100%|████████████████████████████████████████████████████████| 1588/1588 [00:19<00:00, 80.33batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 19.769598722457886 seconds to encode train GATv1_noAttn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding Progress: 100%|██████████████████████████████████████████████████████████| 435/435 [00:10<00:00, 41.22batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 10.55435037612915 seconds to encode train GATv1_noAttn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding Progress: 100%|██████████████████████████████████████████████████████████| 203/203 [00:08<00:00, 23.74batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 8.552019596099854 seconds to encode train GATv1_noAttn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_features = 768\n",
    "num_relations = 4  # Assuming edge features have 4 dimensions\n",
    "hidden_size = 128\n",
    "num_heads = 8\n",
    "dropout = 0.5\n",
    "no_cuda = False\n",
    "\n",
    "file_path1 = 'embed/' + dataset_path + '/h_prime_BERT_GATv1_train.pkl'\n",
    "file_path2 = 'embed/' + dataset_path + '/h_prime_BERT_GATv1_test.pkl'\n",
    "file_path3 = 'embed/' + dataset_path + '/h_prime_BERT_GATv1_dev.pkl'\n",
    "\n",
    "if os.path.exists(file_path1) and os.path.exists(file_path2) and os.path.exists(file_path3):\n",
    "    print(\"All files exist. Skipping operation.\")\n",
    "else:\n",
    "    model = GraphNetwork_GAT(num_features, num_relations, hidden_size, num_heads, dropout, no_cuda)\n",
    "    RelationEncoding(file_path1, dataLoaderTrain, model, \"GATv1_noAttn\")\n",
    "    RelationEncoding(file_path2, dataLoaderTest, model, \"GATv1_noAttn\")\n",
    "    RelationEncoding(file_path3, dataLoaderDev, model, \"GATv1_noAttn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb39da0",
   "metadata": {},
   "source": [
    "<h5>GAT w/ edge_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "01092d30",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Dummy inputs for testing\n",
    "# x = torch.randn((14, num_features))  # Example feature matrix with 14 nodes\n",
    "# edge_index = [torch.randint(0, 14, (2, 20))]  # Example edge index with 20 edges\n",
    "# edge_attr = [torch.randn((20, num_relations))]  # Example edge features\n",
    "# print(edge_index[0].shape)\n",
    "# print(edge_attr[0].shape)\n",
    "# print(edge_index)\n",
    "# print(edge_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "195e2641",
   "metadata": {
    "code_folding": [
     13
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding Progress: 100%|████████████████████████████████████████████████████████| 1588/1588 [00:19<00:00, 79.75batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 19.916845560073853 seconds to encode train GATv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding Progress: 100%|██████████████████████████████████████████████████████████| 435/435 [00:10<00:00, 39.66batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 10.968683242797852 seconds to encode train GATv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding Progress: 100%|██████████████████████████████████████████████████████████| 203/203 [00:08<00:00, 23.23batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 8.738834142684937 seconds to encode train GATv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_features = 768\n",
    "num_relations = 8  # Assuming edge features have 4 dimensions\n",
    "hidden_size = 128\n",
    "num_heads = 8\n",
    "dropout = 0.5\n",
    "no_cuda = False\n",
    "\n",
    "model = GraphNetwork_GAT_EdgeFeat(num_features, num_relations, hidden_size, num_heads, dropout,)\n",
    "\n",
    "file_path1 = 'embed/' + dataset_path + '/h_prime_BERT_GATv1_edgeAttr_train.pkl'\n",
    "file_path2 = 'embed/' + dataset_path + '/h_prime_BERT_GATv1_edgeAttr_test.pkl'\n",
    "file_path3 = 'embed/' + dataset_path + '/h_prime_BERT_GATv1_edgeAttr_dev.pkl'\n",
    "\n",
    "if os.path.exists(file_path1) and os.path.exists(file_path2) and os.path.exists(file_path3):\n",
    "    print(\"All files exist. Skipping operation.\")\n",
    "else:\n",
    "    RelationEncoding(file_path1, dataLoaderTrain, model, \"GATv1\")\n",
    "    RelationEncoding(file_path2, dataLoaderTest, model, \"GATv1\")\n",
    "    RelationEncoding(file_path3, dataLoaderDev, model, \"GATv1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d06c4f7",
   "metadata": {},
   "source": [
    "<h5>GATv2 w/o edge_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ff3525a0",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# x = torch.randn((14, num_features))  # Example feature matrix with 14 nodes\n",
    "# edge_index = torch.randint(0, 14, (2, 20))  # Example edge index with 20 edges\n",
    "# edge_attr = torch.randn((20, 1))  # Example edge features\n",
    "# print(x.shape)\n",
    "# print(edge_index.shape)\n",
    "# print(edge_attr.shape)\n",
    "# print(x)\n",
    "# print(edge_index)\n",
    "# print(edge_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0a40b659",
   "metadata": {
    "code_folding": [
     11,
     13
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding Progress: 100%|███████████████████████████████████████████████████████| 1588/1588 [00:14<00:00, 108.37batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 14.652884006500244 seconds to encode train GATv2_noAttn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding Progress: 100%|██████████████████████████████████████████████████████████| 435/435 [00:09<00:00, 47.65batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 9.1306893825531 seconds to encode train GATv2_noAttn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding Progress: 100%|██████████████████████████████████████████████████████████| 203/203 [00:07<00:00, 25.40batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 7.992076873779297 seconds to encode train GATv2_noAttn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_features = 768\n",
    "num_classes = 7\n",
    "hidden_size = 128\n",
    "num_heads = 8\n",
    "dropout = 0.5\n",
    "no_cuda = False\n",
    "model = GraphNetwork_GATv2(num_features, hidden_size, num_heads, dropout, no_cuda)\n",
    "file_path1 = 'embed/' + dataset_path + '/h_prime_BERT_GATv2_train.pkl'\n",
    "file_path2 = 'embed/' + dataset_path + '/h_prime_BERT_GATv2_test.pkl'\n",
    "file_path3 = 'embed/' + dataset_path + '/h_prime_BERT_GATv2_dev.pkl'\n",
    "\n",
    "if os.path.exists(file_path1) and os.path.exists(file_path2) and os.path.exists(file_path3):\n",
    "    print(\"All files exist. Skipping operation.\")\n",
    "else:\n",
    "    RelationEncoding(file_path1, dataLoaderTrain, model, \"GATv2_noAttn\")\n",
    "    RelationEncoding(file_path2, dataLoaderTest, model, \"GATv2_noAttn\")\n",
    "    RelationEncoding(file_path3, dataLoaderDev, model, \"GATv2_noAttn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cb8298",
   "metadata": {},
   "source": [
    "<h5>GATv2 w/ edge_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ea9a6dcd",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# x = torch.randn((14, num_features))  # Example feature matrix with 14 nodes\n",
    "# edge_index = torch.randint(0, 14, (2, 20))  # Example edge index with 20 edges\n",
    "# edge_attr = torch.randn((20, num_relations))  # Example edge features\n",
    "# print(x.shape)\n",
    "# print(edge_index.shape)\n",
    "# print(edge_attr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "245ee655",
   "metadata": {
    "code_folding": [
     14
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding Progress: 100%|████████████████████████████████████████████████████████| 1588/1588 [00:21<00:00, 72.31batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 21.962221384048462 seconds to encode train GATv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding Progress: 100%|██████████████████████████████████████████████████████████| 435/435 [00:11<00:00, 38.21batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 11.385448455810547 seconds to encode train GATv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding Progress: 100%|██████████████████████████████████████████████████████████| 203/203 [00:09<00:00, 22.37batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 9.0736665725708 seconds to encode train GATv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_features = 768\n",
    "num_classes = 7\n",
    "num_relations = 8\n",
    "max_seq_len = 30\n",
    "hidden_size = 128\n",
    "num_heads = 8\n",
    "dropout = 0.5\n",
    "no_cuda = False\n",
    "\n",
    "model = GraphNetwork_GATv2_EdgeFeat(num_features, num_relations, hidden_size, num_heads, dropout)\n",
    "file_path1 = 'embed/' + dataset_path + '/h_prime_BERT_GATv2_edgeAttr_train.pkl'\n",
    "file_path2 = 'embed/' + dataset_path + '/h_prime_BERT_GATv2_edgeAttr_test.pkl'\n",
    "file_path3 = 'embed/' + dataset_path + '/h_prime_BERT_GATv2_edgeAttr_dev.pkl'\n",
    "\n",
    "if os.path.exists(file_path1) and os.path.exists(file_path2) and os.path.exists(file_path3):\n",
    "    print(\"All files exist. Skipping operation.\")\n",
    "else:\n",
    "    RelationEncoding(file_path1, dataLoaderTrain, model, \"GATv2\")\n",
    "    RelationEncoding(file_path2, dataLoaderTest, model, \"GATv2\")\n",
    "    RelationEncoding(file_path3, dataLoaderDev, model, \"GATv2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609069ea",
   "metadata": {},
   "source": [
    "<h5> RGAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "db77a2c4",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# # Dummy inputs for testing\n",
    "# x = torch.randn((14, num_features))  # Example feature matrix with 14 nodes\n",
    "# edge_index = torch.randint(0, 14, (2, 20))  # Example edge index with 20 edges\n",
    "# edge_type = torch.randint(0, num_relations, (20,))  # Example edge types\n",
    "# # edge_attr = torch.randn((20, 1))  # Example edge features\n",
    "# print(edge_type.shape)\n",
    "# print(edge_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7b92fc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding Progress: 100%|████████████████████████████████████████████████████████| 1588/1588 [00:58<00:00, 27.04batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 58.7189302444458 seconds to encode train RGAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding Progress: 100%|██████████████████████████████████████████████████████████| 435/435 [00:19<00:00, 22.76batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 19.14017152786255 seconds to encode train RGAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding Progress: 100%|██████████████████████████████████████████████████████████| 203/203 [00:12<00:00, 16.30batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 12.457051753997803 seconds to encode train RGAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_features = 768\n",
    "num_classes = 7\n",
    "num_relations = 8\n",
    "hidden_size = 64\n",
    "num_heads = 8\n",
    "dropout = 0.5\n",
    "edge_dim = 1  # Dimensionality of edge attributes\n",
    "no_cuda = False\n",
    "\n",
    "model = GraphNetwork_RGAT(num_features, num_relations, hidden_size, num_heads, dropout, edge_dim, no_cuda)\n",
    "file_path1 = 'embed/' + dataset_path + '/h_prime_BERT_RGAT_train'\n",
    "file_path2 = 'embed/' + dataset_path + '/h_prime_BERT_RGAT_test'\n",
    "file_path3 = 'embed/' + dataset_path + '/h_prime_BERT_RGAT_dev'\n",
    "\n",
    "if os.path.exists(file_path1+\".pkl\") or os.path.exists(file_path2+\".pkl\") or os.path.exists(file_path3+\".pkl\"):\n",
    "    print(\"All files exist. Skipping operation.\")\n",
    "else:\n",
    "    RelationEncoding(file_path1, dataLoaderTrain, model, \"RGAT\")\n",
    "    RelationEncoding(file_path2, dataLoaderTest, model, \"RGAT\")\n",
    "    RelationEncoding(file_path3, dataLoaderDev, model, \"RGAT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf743465",
   "metadata": {},
   "source": [
    "<b> Watch out here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "36a4c8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File embed/dataset_drop_noise/h_prime_BERT_RGAT_train_5.pkl does not exist and will be skipped.\n",
      "File embed/dataset_drop_noise/h_prime_BERT_RGAT_test_2.pkl does not exist and will be skipped.\n"
     ]
    }
   ],
   "source": [
    "def combinePartitionedData(file_paths, output_file_path):\n",
    "    combined_h_prime = []\n",
    "\n",
    "    for file_path in file_paths:\n",
    "        if os.path.isfile(file_path):\n",
    "            try:\n",
    "                with open(file_path, 'rb') as file:\n",
    "                    data = pickle.load(file)\n",
    "                    combined_h_prime.extend(data)\n",
    "\n",
    "            except (pickle.UnpicklingError, EOFError) as e:\n",
    "                print(f\"Error loading data from {file_path}: {e}\")\n",
    "            except Exception as e:\n",
    "                print(f\"An unexpected error occurred while processing {file_path}: {e}\")\n",
    "        else:\n",
    "            print(f\"File {file_path} does not exist and will be skipped.\")\n",
    "\n",
    "    try:\n",
    "        with open(output_file_path, 'wb') as file:\n",
    "            pickle.dump(combined_h_prime, file)\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving combined data to {output_file_path}: {e}\")\n",
    "        return\n",
    "\n",
    "    # Delete the original files\n",
    "#     for file_path in file_paths:\n",
    "#         if os.path.isfile(file_path):\n",
    "#             try:\n",
    "#                 os.remove(file_path)\n",
    "#             except OSError as e:\n",
    "#                 print(f\"Error deleting file {file_path}: {e}\")\n",
    "\n",
    "file_paths1 = [\n",
    "    'embed/' + dataset_path + '/h_prime_BERT_RGAT_train_1.pkl',\n",
    "    'embed/' + dataset_path + '/h_prime_BERT_RGAT_train_2.pkl',\n",
    "    'embed/' + dataset_path + '/h_prime_BERT_RGAT_train_3.pkl',\n",
    "    'embed/' + dataset_path + '/h_prime_BERT_RGAT_train_4.pkl',\n",
    "    'embed/' + dataset_path + '/h_prime_BERT_RGAT_train_5.pkl'\n",
    "]\n",
    "\n",
    "file_paths2 = [\n",
    "    'embed/' + dataset_path + '/h_prime_BERT_RGAT_test_1.pkl',\n",
    "    'embed/' + dataset_path + '/h_prime_BERT_RGAT_test_2.pkl'\n",
    "]\n",
    "\n",
    "file_paths3 = [\n",
    "    'embed/' + dataset_path + '/h_prime_BERT_RGAT_dev_1.pkl'\n",
    "]\n",
    "\n",
    "output_file_path1 = 'embed/' + dataset_path + '/h_prime_BERT_RGAT_train.pkl'\n",
    "output_file_path2 = 'embed/' + dataset_path + '/h_prime_BERT_RGAT_test.pkl'\n",
    "output_file_path3 = 'embed/' + dataset_path + '/h_prime_BERT_RGAT_dev.pkl'\n",
    "\n",
    "combinePartitionedData(file_paths1, output_file_path1)\n",
    "combinePartitionedData(file_paths2, output_file_path2)\n",
    "combinePartitionedData(file_paths3, output_file_path3)\n",
    "\n",
    "# # Verifying the combined output\n",
    "# with open(output_file_path1, 'rb') as file:\n",
    "#     tmp1 = pickle.load(file)\n",
    "# print(len(tmp1))  # should print 2\n",
    "# print(len(tmp1[0]))  # should print the combined length of all h_prime elements\n",
    "# print(len(tmp1[1]))  # should print the combined length of all AttObject elements\n",
    "\n",
    "# with open(output_file_path2, 'rb') as file:\n",
    "#     tmp2 = pickle.load(file)\n",
    "# print(len(tmp2))  # should print 2\n",
    "# print(len(tmp2[0]))  # should print the combined length of all h_prime elements\n",
    "# print(len(tmp2[1]))  # should print the combined length of all AttObject elements\n",
    "\n",
    "# with open(output_file_path3, 'rb') as file:\n",
    "#     tmp3 = pickle.load(file)\n",
    "# print(len(tmp3))  # should print 2\n",
    "# print(len(tmp3[0]))  # should print the combined length of all h_prime elements\n",
    "# print(len(tmp3[1]))  # should print the combined length of all AttObject elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "32b5f767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1588\n",
      "435\n",
      "203\n"
     ]
    }
   ],
   "source": [
    "with open(output_file_path1, 'rb') as file:\n",
    "    tmp1 = pickle.load(file)\n",
    "print(len(tmp1))\n",
    "\n",
    "with open(output_file_path2, 'rb') as file:\n",
    "    tmp2 = pickle.load(file)\n",
    "print(len(tmp2))\n",
    "\n",
    "with open(output_file_path3, 'rb') as file:\n",
    "    tmp3 = pickle.load(file)\n",
    "print(len(tmp3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e016df95",
   "metadata": {},
   "source": [
    "end of encoding train data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3e5796",
   "metadata": {},
   "source": [
    "<h4> Creating graph features from Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f0634150",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# TODO repeat the one above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c36c94f",
   "metadata": {},
   "source": [
    "<h3> Get GAT output from each set of data (DISCONTINUED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f024704",
   "metadata": {},
   "source": [
    "<h4> Instantiating the GAT (1st implementation) for 1 sample train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cacafa9a",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# num_in_features = len(contextualEmbeddingsTrain[0][0])\n",
    "# num_out_features = len(contextualEmbeddingsTrain[0][0])\n",
    "# num_heads = 4\n",
    "# num_edge_types = 3\n",
    "# gat_layer = GATLayerWithEdgeType(num_in_features, num_out_features, num_heads, num_edge_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "98a8775c",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# i = 0  # dialogue id\n",
    "# relationalEmbedding, attentionCoef = gat_layer((contextualEmbeddingsTrain[i], edgeIndicesTrain[i]), edgeTypesTrain[i])\n",
    "# print(\"h_prime shape: \", relationalEmbedding.shape, \"attention_coef shape: \", attentionCoef.shape)\n",
    "\n",
    "# targetNodes = edgeIndicesTrain[i][1].tolist()\n",
    "\n",
    "# sample = {}\n",
    "# sampleEdgetypes = []\n",
    "\n",
    "# for target_i in sorted(set(targetNodes)):\n",
    "#     sample[target_i] = []\n",
    "\n",
    "# for targetNode, idx in zip(targetNodes, range(len(targetNodes))):\n",
    "#     sample[targetNode].append([idx, relationalEmbedding[targetNode][idx].tolist()])\n",
    "\n",
    "# listEdgeIdxTrain, inferredEdgeTypes = get_inferred_edgetypes_GAT(sample, edgeTypesTrain[i])\n",
    "# sampleEdgetypes.append(inferredEdgeTypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fc9c28c3",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anger', 'disgust', 'fear', 'joy', 'neutral', 'sadness', 'surprise']\n"
     ]
    }
   ],
   "source": [
    "file = open('data/dump/' + dataset_path + '/label_decoder.pkl', 'rb')\n",
    "label_decoder = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "label_decoder = list(label_decoder.values())\n",
    "print(label_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5ca6003c",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "checkFile = os.path.isfile('data/dump/' + dataset_path + '/labels_train.pkl')\n",
    "\n",
    "if checkFile is False:\n",
    "    print(\"Please run the contextEncoder1 notebook to save the label file\")\n",
    "else:\n",
    "    file = open('data/dump/' + dataset_path + '/labels_train.pkl', 'rb')\n",
    "    y_train = pickle.load(file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c02f789e",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     6\n",
       "1     6\n",
       "2     6\n",
       "3     4\n",
       "4     4\n",
       "5     6\n",
       "6     5\n",
       "7     4\n",
       "8     4\n",
       "9     6\n",
       "10    5\n",
       "11    4\n",
       "12    3\n",
       "13    3\n",
       "14    5\n",
       "Name: Emotion, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c6f3e8e1",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# checkFile = os.path.isfile(\"data/dump/labels_test.pkl\")\n",
    "\n",
    "# if checkFile is False:\n",
    "#     print(\"Please run the contextEncoder2 notebook to save the label file\")\n",
    "# else:\n",
    "#     file = open('data/dump/labels_test.pkl', 'rb')\n",
    "#     y_test = pickle.load(file)\n",
    "#     file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42223125",
   "metadata": {},
   "source": [
    "<h5>Unsupervised Visualizarion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d1a41a39",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# # Assuming h_prime contains the node embeddings\n",
    "# utt_size = 13\n",
    "# labels = torch.tensor(y_train[:utt_size + 1])\n",
    "\n",
    "# cherrypicked_nodes = []\n",
    "# for src_idx, edge_idx in zip(range(len(list_edge_idx)), list_edge_idx):\n",
    "#     cherrypicked_nodes.append(attention_coef[src_idx, :, edge_idx].tolist())\n",
    "# cherrypicked_nodes = torch.tensor(cherrypicked_nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "47a97231",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# h_prime_np = cherrypicked_nodes.detach().numpy()\n",
    "\n",
    "# # Perform dimensionality reduction using t-SNE\n",
    "# tsne = TSNE(n_components=3, perplexity=5, random_state=42)\n",
    "# h_prime_tsne = tsne.fit_transform(h_prime_np)\n",
    "\n",
    "# # Plot the node embeddings with different colors for each label\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# for label, emotion in zip(range(len(label_decoder)), label_decoder): \n",
    "#     indices = (labels == label).nonzero().squeeze()\n",
    "#     plt.scatter(h_prime_tsne[indices, 0], h_prime_tsne[indices, 1], label=f'{emotion}')\n",
    "# plt.title('Node Embeddings Visualization (t-SNE)', color=\"white\")\n",
    "# plt.xlabel('Dimension 1', color=\"white\")\n",
    "# plt.ylabel('Dimension 2', color=\"white\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8043a6a",
   "metadata": {},
   "source": [
    "<h4> Now get new representations of all train, test, validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "588776d9",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# # filePath = data/dump/h_prime_BERT-GAT_train.pkl\n",
    "# #            data/dump/h_prime_BERT-GAT_test.pkl\n",
    "# #            data/dump/h_prime_BERT-GAT_valid.pkl\n",
    "\n",
    "# def get_GAT_representation(filePath, contextualEmbeddings, edgeIndices, edgeTypes):\n",
    "# #     checkFile = os.path.isfile(\"data/dump/h_prime_BERT-GAT_train.pkl\") #replace it with key when deployed\n",
    "#     if key:\n",
    "#         print(\"Start of getting output of 1st GAT\")\n",
    "#         allInferredEdgetypes = []\n",
    "#         listAllEdgeIdx = []\n",
    "#         cherrypickedNodes = []\n",
    "#         for dialog, dialog_id in zip(contextualEmbeddings, range(len(contextualEmbeddings))):\n",
    "#             h_prime, attention_coef = gat_layer((dialog, edgeIndices[dialog_id]), edgeTypes[dialog_id])\n",
    "#             target_nodes = edgeIndices[dialog_id][1].tolist() # first idx represents dialogue id\n",
    "\n",
    "#             sample_edgetypes = {}\n",
    "#             for i in set(target_nodes):\n",
    "#                 sample_edgetypes[i] = []\n",
    "\n",
    "#             for target_node, edge_idx in zip(target_nodes, range(len(target_nodes))):\n",
    "#                 sample_edgetypes[target_node].append([edge_idx, h_prime[target_node][edge_idx].tolist()])\n",
    "\n",
    "#             list_edge_idx, inferred_edgetypes = get_inferred_edgetypes_GAT(sample_edgetypes,  edgeTypes[dialog_id])\n",
    "#             listAllEdgeIdx.append(list_edge_idx)\n",
    "#             allInferredEdgetypes.append(inferred_edgetypes)\n",
    "\n",
    "#             for src_idx, edge_idx in zip(range(len(list_edge_idx)), list_edge_idx):\n",
    "#                 cherrypickedNodes.append(attention_coef[src_idx, :, edge_idx].tolist())\n",
    "\n",
    "#         cherrypickedNodes = torch.tensor(cherrypickedNodes)\n",
    "#         cherrypickedNodes.shape\n",
    "#         print(\"End of getting output of 1st GAT\")\n",
    "\n",
    "#         pickle.dump([cherrypickedNodes, allInferredEdgetypes],\n",
    "#                     open(filePath, 'wb'))\n",
    "\n",
    "#     else:\n",
    "#         file = open(filePath, 'rb')\n",
    "#         cherrypickedNodes, allInferredEdgetypes = pickle.load(file)\n",
    "#         file.close()\n",
    "\n",
    "#     return cherrypickedNodes, allInferredEdgetypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d2ef42f2",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# # train data\n",
    "# cherrypickedNodesTrain, allInferredEdgetypesTrain = get_GAT_representation(\n",
    "#                                                     \"embed/h_prime_BERT-GAT_train.pkl\",\n",
    "#                                                     contextualEmbeddingsTrain,\n",
    "#                                                     edgeIndicesTrain,\n",
    "#                                                     edgeTypesTrain)\n",
    "# # only save the pickle data for test and validation\n",
    "# _, _ = get_GAT_representation(\"embed/h_prime_BERT-GAT_test.pkl\",\n",
    "#                         contextualEmbeddingsTest,\n",
    "#                         edgeIndicesTest,\n",
    "#                         edgeTypesTest)\n",
    "# # TODO add valid set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de95f55",
   "metadata": {},
   "source": [
    "<h5> Visualize Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7e56aa1c",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# labels = torch.tensor(trainLabels)\n",
    "# h_prime_np = cherrypickedNodesTrain.detach().numpy() (discontinued)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "548c237c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# runTSNE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dcd5bd42",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# if runTSNE:\n",
    "#     # List of perplexity values to loop over\n",
    "#     perplexity_values = [30, 100]\n",
    "\n",
    "#     # Loop over each perplexity value\n",
    "#     for perplexity in perplexity_values:\n",
    "#         # Initialize t-SNE with the current perplexity value\n",
    "#         tsne = TSNE(n_components=2, perplexity=perplexity, random_state=42)\n",
    "\n",
    "#         # Fit and transform the data using t-SNE\n",
    "#         h_prime_tsne = tsne.fit_transform(h_prime_np)\n",
    "\n",
    "#         # Plot the node embeddings with different colors for each label\n",
    "#         plt.figure(figsize=(10, 8))\n",
    "#         for label, emotion in zip(range(len(label_decoder)), label_decoder): \n",
    "#             indices = (labels == label).nonzero().squeeze()\n",
    "#             plt.scatter(h_prime_tsne[indices, 0], h_prime_tsne[indices, 1], label=f'{emotion}')\n",
    "#         plt.title(f'Node Embeddings Visualization (t-SNE) - Perplexity {perplexity}', color=\"white\")\n",
    "#         plt.xlabel('Dimension 1', color=\"white\")\n",
    "#         plt.ylabel('Dimension 2', color=\"white\")\n",
    "#         plt.legend()\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5caea68",
   "metadata": {},
   "source": [
    "<h4> Analyze the edgetypes of all train nodes in the context of a dialog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c236b455",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# # Assuming `all_inferred_edgetypes` and `y_train` are defined\n",
    "# df_eda = pd.DataFrame(\n",
    "#     {'edgetype': flatten_extend(allInferredEdgetypesTrain),\n",
    "#      'label': y_train,\n",
    "#     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "46b7f357",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# # Assuming `df_eda` and `CrosstabResult` are defined\n",
    "# CrosstabResult = pd.crosstab(index=df_eda['edgetype'], columns=df_eda['label'])\n",
    "\n",
    "# print(\"Crosstab Result:\")\n",
    "# print(CrosstabResult)\n",
    "# print()\n",
    "\n",
    "# # Performing Chi-squared test\n",
    "# ChiSqResult = chi2_contingency(CrosstabResult)\n",
    "\n",
    "# # P-Value is the Probability of H0 being True\n",
    "# # If P-Value > 0.05 then only we Accept the assumption(H0)\n",
    "# # H0: The variables are not correlated with each other.\n",
    "\n",
    "# print('The P-Value of the Chi-Squared Test is:', ChiSqResult[1])\n",
    "\n",
    "# if ChiSqResult[1] > 0.05:\n",
    "#     print(\"Variables are not correlated with each other\")\n",
    "# else:\n",
    "#     print(\"Two variables are correlated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540cb0a7",
   "metadata": {},
   "source": [
    "<h3> Get EGAT output from each set of data (train, test, validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "60061c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size=64\n",
    "egat = EGATConv(in_node_feats=len(contextualEmbeddingsTrain[0][0]),\n",
    "                    in_edge_feats=3,\n",
    "                    out_node_feats=hidden_size,\n",
    "                    out_edge_feats=3,\n",
    "                    num_heads=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cc9167ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_EGAT_representations(filePath, contextualEmbeddings, edgeIndices, edgeTypes, ranges):\n",
    "    checkFile = os.path.isfile(filePath)\n",
    "#     ranges = []\n",
    "    if not checkFile:\n",
    "        inferredEdgetypes = []\n",
    "        allNodeFeats = []\n",
    "\n",
    "        for dialog_id in tqdm(range(len(edgeIndices)), desc=\"Encoding Progress\", unit=\"batch\"):\n",
    "            startIdx, endIdx = ranges[dialog_id][0], ranges[dialog_id][1]\n",
    "\n",
    "            graph = dgl.graph((edgeIndices[dialog_id][0], edgeIndices[dialog_id][1]))\n",
    "            edge_feats = get_ohe(edgeTypes[dialog_id])\n",
    "\n",
    "            egat_output = egat(graph, contextualEmbeddings[startIdx: endIdx+1], edge_feats)\n",
    "            new_node_feats, new_edge_feats = egat_output\n",
    "\n",
    "            # Compute mean edge features\n",
    "            mean_edge_feats = new_edge_feats.mean(dim=1)\n",
    "            allNodeFeats.append(new_node_feats.max(dim=1).values)\n",
    "#             allNodeFeats.append(new_node_feats.sum(dim=1))\n",
    "\n",
    "            # Prepare edge features for inference\n",
    "            target_nodes = edgeIndices[dialog_id][1].tolist()\n",
    "            sample_edgetypes = {}\n",
    "            for i in set(target_nodes):\n",
    "                sample_edgetypes[i] = []\n",
    "            for target_node, edge_idx in zip(target_nodes, range(len(target_nodes))):\n",
    "                sample_edgetypes[target_node].append([edge_idx, \n",
    "                                                      mean_edge_feats[edge_idx].tolist()])\n",
    "        pickle.dump(allNodeFeats, open(filePath, 'wb'))\n",
    "\n",
    "    else:\n",
    "        file = open(filePath, 'rb')\n",
    "        allNodeFeats = pickle.load(file)\n",
    "        file.close()\n",
    "\n",
    "    return allNodeFeats, _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "938645cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding Progress: 100%|███████████████████████████████████████████████████████| 1588/1588 [00:04<00:00, 319.02batch/s]\n",
      "Encoding Progress: 100%|█████████████████████████████████████████████████████████| 435/435 [00:01<00:00, 318.07batch/s]\n",
      "Encoding Progress: 100%|█████████████████████████████████████████████████████████| 203/203 [00:00<00:00, 306.95batch/s]\n"
     ]
    }
   ],
   "source": [
    "contextualEmbeddingsTrain_stacked = torch.cat(contextualEmbeddingsTrain, dim=0)\n",
    "allNodeFeatsTrain, inferredEdgetypesTrain = get_EGAT_representations(\n",
    "                                        \"embed/\" + dataset_path + \"/h_prime_BERT_EGAT_train.pkl\",\n",
    "                                        contextualEmbeddingsTrain_stacked,\n",
    "                                        edgeIndicesTrain,\n",
    "                                        edgeTypesTrain,\n",
    "                                        rangesTrain\n",
    "                                )\n",
    "\n",
    "contextualEmbeddingsTest_stacked = torch.cat(contextualEmbeddingsTest, dim=0)\n",
    "_, _ = get_EGAT_representations(\n",
    "        \"embed/\" + dataset_path + \"/h_prime_BERT_EGAT_test.pkl\",\n",
    "        contextualEmbeddingsTest_stacked,\n",
    "        edgeIndicesTest,\n",
    "        edgeTypesTest, \n",
    "        rangesTest\n",
    ")\n",
    "\n",
    "contextualEmbeddingsDev_stacked = torch.cat(contextualEmbeddingsDev, dim=0)\n",
    "_, _ = get_EGAT_representations(\n",
    "        \"embed/\" + dataset_path + \"/h_prime_BERT_EGAT_dev.pkl\",\n",
    "        contextualEmbeddingsDev_stacked,\n",
    "        edgeIndicesDev,\n",
    "        edgeTypesDev, \n",
    "        rangesDev\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "878a3c6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6955, 768])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contextualEmbeddingsTrain_stacked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8e4cc671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 64])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allNodeFeatsTrain[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3c2a765a",
   "metadata": {
    "code_folding": [
     0,
     13,
     18
    ]
   },
   "outputs": [],
   "source": [
    "class FCClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, dropout_rate):\n",
    "        super(FCClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "def shuffle_data(X_set, Y_set):\n",
    "    indices = np.arange(len(X_set))\n",
    "    np.random.shuffle(indices)\n",
    "    return X_set[indices], Y_set[indices]\n",
    "\n",
    "def model_train2(X_set=None, Y_set=None, X_test=None, Y_test=None, num_epochs=20, \n",
    "                 loss_difference_threshold=0.001, hidden_dims=128, dropout_rate=0.5, \n",
    "                 lr=0.0001, optimizer_class=optim.Adam, criterion_class=nn.CrossEntropyLoss, \n",
    "                 nodalAtt=None, umask=None, seq_len=None, no_cuda=True, ranges=None):\n",
    "    \n",
    "    output_dim = 7  # Number of classes\n",
    "    input_dim = X_set.shape[1] if len(X_set) > 0 else 0\n",
    "    model = FCClassifier(input_dim, hidden_dims, output_dim, dropout_rate)\n",
    "    \n",
    "    device = 'cuda' if torch.cuda.is_available() and not no_cuda else 'cpu'\n",
    "    model = model.to(device)\n",
    "    \n",
    "    criterion = criterion_class()\n",
    "    optimizer = optimizer_class(model.parameters(), lr=lr)\n",
    "    \n",
    "    loss_history = []\n",
    "    accuracy_history = []\n",
    "    previous_loss = float('inf')\n",
    "\n",
    "    epoch_num = num_epochs\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_instances = 0\n",
    "        \n",
    "        # Shuffle the dataset at the beginning of each epoch\n",
    "        X_set, Y_set = shuffle_data(X_set, Y_set)\n",
    "\n",
    "        inputs = X_set.float().to(device)\n",
    "        labels = Y_set.long().to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        outputs = outputs.squeeze()\n",
    "\n",
    "        log_prob = F.log_softmax(outputs, dim=1)\n",
    "        labels = labels.squeeze()\n",
    "\n",
    "        # Ensure labels are 1D\n",
    "        if len(labels.shape) > 1:\n",
    "            labels = labels.view(-1)\n",
    "\n",
    "        loss = criterion(log_prob, labels)\n",
    "\n",
    "        # Check for NaN loss values\n",
    "        if torch.isnan(loss):\n",
    "            print(\"NaN loss encountered. Skipping this batch.\")\n",
    "            continue\n",
    "\n",
    "        # Apply gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(log_prob, dim=1)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "        total_instances += labels.size(0)\n",
    "\n",
    "        epoch_loss = total_loss\n",
    "        accuracy = correct_predictions / total_instances\n",
    "\n",
    "        loss_history.append(epoch_loss)\n",
    "        accuracy_history.append(accuracy)\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {accuracy:.4f}')\n",
    "\n",
    "        if epoch > 0:\n",
    "            loss_diff = abs(epoch_loss - previous_loss)\n",
    "            if loss_diff < loss_difference_threshold:\n",
    "                print(f\"Training stopped early at epoch {epoch+1}.\")\n",
    "                print(f\"Loss difference ({loss_diff}) is below the threshold ({loss_difference_threshold}).\")\n",
    "                epoch_num = epoch + 1\n",
    "                break\n",
    "        \n",
    "        previous_loss = epoch_loss\n",
    "\n",
    "    # Test the model\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        inputs = X_test\n",
    "        labels = Y_test\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        outputs = outputs.squeeze()\n",
    "        labels = labels.squeeze()\n",
    "\n",
    "        log_prob = F.log_softmax(outputs, dim=1)\n",
    "        _, predicted = torch.max(log_prob, dim=1)\n",
    "\n",
    "\n",
    "    # Generate the classification report\n",
    "    report = classification_report(labels.cpu(),  predicted.cpu(), zero_division=0)\n",
    "    print(report)\n",
    "    \n",
    "    return model, epoch_num, loss_history, accuracy_history, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7271105",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6e7269b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 1\n",
    "# pair = rangesTrain[i]\n",
    "# X_set = torch.tensor(allNodeFeatsTrain[i]).clone()\n",
    "# y_set = y_train[pair[0]: pair[1]+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a7c04633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model, epoch_num, loss_history, accuracy_history, report = model_train2(\n",
    "#     X_set=X_set, Y_set=Y_set, X_test=X_set, Y_test=Y_set, num_epochs=20, \n",
    "#     loss_difference_threshold=0.001, hidden_dims=128, dropout_rate=0.5, lr=0.0001, \n",
    "#     optimizer_class=optim.Adam, criterion_class=nn.CrossEntropyLoss, no_cuda=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2d8211",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019b1419",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d10c956",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d91fae7",
   "metadata": {},
   "source": [
    "if not inferredEdgetypesTrain:\n",
    "    df_eda2 = pd.DataFrame(\n",
    "        {'edgetype': flatten_extend(inferredEdgetypesTrain),\n",
    "         'label': trainLabels,\n",
    "        })\n",
    "    # Create a DataFrame from your data (df_eda2)\n",
    "    # Assuming df_eda2 is already defined\n",
    "\n",
    "    # Crosstabulation\n",
    "    CrosstabResult2 = pd.crosstab(index=df_eda2['edgetype'], columns=df_eda2['label'])\n",
    "    print(\"Crosstab Result:\\n\", CrosstabResult2)\n",
    "\n",
    "    # Performing Chi-squared test\n",
    "    ChiSqResult2 = chi2_contingency(CrosstabResult2)\n",
    "\n",
    "    # Print the p-value of the Chi-squared test\n",
    "    print('The P-Value of the ChiSq Test is:', ChiSqResult2[1])\n",
    "\n",
    "    # Interpret the p-value\n",
    "    if ChiSqResult2[1] > 0.05:\n",
    "        print(\"Variables are not correlated with each other\")\n",
    "    else:\n",
    "        print(\"Two variables are correlated\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0213c68a",
   "metadata": {},
   "source": [
    "Testing on 1 dialog data before scaling up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "84641d47",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# dialog_id = 0\n",
    "\n",
    "# # Create a DGL graph\n",
    "# graph = dgl.graph((edgeIndicesTrain[dialog_id][0], edgeIndicesTrain[dialog_id][1]))\n",
    "\n",
    "# # Obtain one-hot encoded edge features\n",
    "# edge_feats = get_ohe(edgeTypesTrain[dialog_id])\n",
    "\n",
    "# # Pass the graph, node representations, and edge features through the EGAT model\n",
    "# contextualEmbeddingsTrain_stacked = torch.cat(contextualEmbeddingsTrain, dim=0)\n",
    "# newNodeFeats, newEdgeFeats = egat(graph, contextualEmbeddingsTrain_stacked[0:14], edge_feats)\n",
    "\n",
    "# # Print the shapes of the new node and edge features\n",
    "# print(\"New Node Features Shape:\", newNodeFeats.shape)\n",
    "# print(\"New Edge Features Shape:\", newEdgeFeats.shape)\n",
    "\n",
    "# # Calculate the mean of node features along the second dimension (number of nodes)\n",
    "# h_prime_mean = newNodeFeats.mean(dim=1)\n",
    "\n",
    "# # Assuming you want to select only a subset of labels for visualization\n",
    "# utt_size = 13\n",
    "# labels = torch.tensor(trainLabels[:utt_size+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0bbcf4d9",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# # Convert tensor to numpy array\n",
    "# h_prime_np = h_prime_mean.detach().numpy()\n",
    "# # Perform dimensionality reduction using t-SNE\n",
    "# tsne = TSNE(n_components=2, perplexity=5, random_state=42)\n",
    "# h_prime_tsne = tsne.fit_transform(h_prime_np)\n",
    "\n",
    "# # Plot the node embeddings with different colors for each label\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# for label, emotion Ain zip(range(len(label_decoder)), label_decoder): \n",
    "#     indices = (labels == label).nonzero().squeeze()\n",
    "#     plt.scatter(h_prime_tsne[indices, 0], h_prime_tsne[indices, 1], label=f'{emotion}')\n",
    "# plt.title('Node Embeddings Visualization (t-SNE)', color=\"white\")\n",
    "# plt.xlabel('Dimension 1', color=\"white\")\n",
    "# plt.ylabel('Dimension 2', color=\"white\")\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9e75975a",
   "metadata": {},
   "outputs": [],
   "source": [
    "runTSNE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "851a250c",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "if runTSNE:\n",
    "    # Convert tensor to numpy array\n",
    "    h_prime_np = allNodeFeatsTrain.detach().numpy()\n",
    "    labels = torch.tensor(trainLabels)\n",
    "    \n",
    "    # List of perplexity values to loop over\n",
    "    perplexity_values = [30, 100]\n",
    "\n",
    "    # Loop over each perplexity value\n",
    "    for perplexity in perplexity_values:\n",
    "        # Initialize t-SNE with the current perplexity value\n",
    "        tsne = TSNE(n_components=2, perplexity=perplexity, random_state=42)\n",
    "\n",
    "        # Fit and transform the data using t-SNE\n",
    "        h_prime_tsne = tsne.fit_transform(h_prime_np)\n",
    "        print(h_prime_tsne.shape)\n",
    "        \n",
    "        # Plot the node embeddings with different colors for each label\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        for label, emotion in zip(range(len(label_decoder)), label_decoder): \n",
    "            indices = (labels == label).nonzero().squeeze()\n",
    "            plt.scatter(h_prime_tsne[indices, 0], h_prime_tsne[indices, 1], label=f'{emotion}')\n",
    "        plt.title(f'Node Embeddings Visualization (t-SNE) - Perplexity {perplexity}', color=\"white\")\n",
    "        plt.xlabel('Dimension 1', color=\"white\")\n",
    "        plt.ylabel('Dimension 2', color=\"white\")\n",
    "        plt.legend()\n",
    "        plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
