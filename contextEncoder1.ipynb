{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7856ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import pickle\n",
    "import collections\n",
    "import importlib\n",
    "import datetime\n",
    "import torch\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from chardet import detect\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from collections import defaultdict, Counter\n",
    "from wordebd import WORDEBD\n",
    "from vocab import Vocab, Vectors\n",
    "from munch import Munch\n",
    "from cnnlstmseq import CNNLSTMseq\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Autoreload extensions (if you're using Jupyter Notebook or IPython)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f23de1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "key=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a273b63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoding_type(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        rawdata = f.read()\n",
    "    return detect(rawdata)['encoding']\n",
    "\n",
    "def detect_misspelling(source):\n",
    "    pass\n",
    "\n",
    "def replace_spelling(source):\n",
    "    return re.sub(\"Ã…f\", \"'\", source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08e24b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(data):\n",
    "    '''\n",
    "    Preprocess text data\n",
    "    @param data: list of text examples\n",
    "    @return preprocessed_data: list of preprocessed text examples\n",
    "    '''\n",
    "    preprocessed_data = []\n",
    "    for example in data:\n",
    "        # Convert to lowercase\n",
    "        example = example.lower()\n",
    "        # Remove punctuation\n",
    "        example = re.sub(r'[^\\w\\s]', '', example)\n",
    "        preprocessed_data.append(example)\n",
    "    return preprocessed_data\n",
    "\n",
    "def load_pretrained_glove():\n",
    "    print(\"Loading GloVe...\")\n",
    "    glv_vector = {}\n",
    "    f = open('/embed/glove/glove.840B.300d.txt', encoding='utf-8')\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word, coefs = values[0], np.asarray(values[1:], dtype='float')\n",
    "        try:\n",
    "            glv_vector[word] = coefs\n",
    "        except ValueError:\n",
    "            continue\n",
    "    f.close()\n",
    "    start_time = time.time()\n",
    "    print(f\"Took {time.time() - start_time} seconds to load pretrained GloVe model.\")\n",
    "    return glv_vector\n",
    "\n",
    "def encode_labels(encoder, l):\n",
    "    return encoder[l]\n",
    "\n",
    "def _read_words(data, convmode=None):\n",
    "    '''    \n",
    "    Count the occurrences of all words\n",
    "    @param convmode: str, None for non conversational scope, 'naive' for classic or naive approach, 'conv' for conversation depth into account (one additional dim and nested values)\n",
    "    @param data: list of examples\n",
    "    @return words: list of words (with duplicates)\n",
    "    '''    \n",
    "    words = []\n",
    "    if convmode is None:\n",
    "        for example in data:\n",
    "            words += example.split()\n",
    "    return words\n",
    "\n",
    "def find_value_ranges(lst):\n",
    "    value_ranges = []\n",
    "    start_index = 0\n",
    "\n",
    "    for i in range(1, len(lst)):\n",
    "        if lst[i] != lst[i - 1]:\n",
    "            value_ranges.append((start_index, i - 1))\n",
    "            start_index = i\n",
    "\n",
    "    # Add the last range\n",
    "    value_ranges.append((start_index, len(lst) - 1))\n",
    "\n",
    "    return value_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d2cf5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12840, 12)\n",
      "(3400, 12)\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV file\n",
    "X_train = pd.read_csv('data/train_sent_emo_dya.csv', encoding='shift_jis')\n",
    "X_test = pd.read_csv('data/test_sent_emo_dya.csv', encoding='utf-8')\n",
    "\n",
    "# Display the first three rows\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5825e9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features to drop\n",
    "drop_features = list(X_train.columns[6:]) \n",
    "\n",
    "# Create DataFrame for target labels\n",
    "y_train = pd.DataFrame()\n",
    "y_test = pd.DataFrame()\n",
    "\n",
    "y_train[\"Emotion\"] = X_train[\"Emotion\"].copy()\n",
    "y_test[\"Emotion\"] = X_test[\"Emotion\"].copy()\n",
    "\n",
    "y_train[\"Dialogue_ID\"] = X_train[\"Dialogue_ID\"].copy()\n",
    "y_test[\"Dialogue_ID\"] = X_test[\"Dialogue_ID\"].copy()\n",
    "\n",
    "# Drop features from X_train DataFrame\n",
    "X_train = X_train.drop(drop_features, axis=1)\n",
    "X_test = X_test.drop(drop_features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b73b303f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Utterance          Speaker  \\\n",
      "0   also i was the point person on my companys tra...         Chandler   \n",
      "1                      you mustve had your hands full  The Interviewer   \n",
      "2                               that i did that i did         Chandler   \n",
      "3         so lets talk a little bit about your duties  The Interviewer   \n",
      "4                                my duties  all right         Chandler   \n",
      "5   now youll be heading a whole division so youll...  The Interviewer   \n",
      "6                                               i see         Chandler   \n",
      "7   but therell be perhaps 30 people under you so ...  The Interviewer   \n",
      "8                                        good to know         Chandler   \n",
      "9                               we can go into detail  The Interviewer   \n",
      "10                               no dont i beg of you         Chandler   \n",
      "11  all right then well have a definite answer for...  The Interviewer   \n",
      "12                                             really         Chandler   \n",
      "13                          absolutely  you can relax  The Interviewer   \n",
      "\n",
      "     Emotion Sentiment  Dialogue_ID  Utterance_ID  \n",
      "0    neutral   neutral            0             0  \n",
      "1    neutral   neutral            0             1  \n",
      "2    neutral   neutral            0             2  \n",
      "3    neutral   neutral            0             3  \n",
      "4   surprise  positive            0             4  \n",
      "5    neutral   neutral            0             5  \n",
      "6    neutral   neutral            0             6  \n",
      "7    neutral   neutral            0             7  \n",
      "8    neutral   neutral            0             8  \n",
      "9    neutral   neutral            0             9  \n",
      "10      fear  negative            0            10  \n",
      "11   neutral   neutral            0            11  \n",
      "12  surprise  positive            0            12  \n",
      "13   neutral   neutral            0            13  \n"
     ]
    }
   ],
   "source": [
    "# Preprocess the \"Utterance\" column\n",
    "X_train[\"Utterance\"] = preprocess_text(X_train[\"Utterance\"].tolist())\n",
    "X_test[\"Utterance\"] = preprocess_text(X_test[\"Utterance\"].tolist())\n",
    "\n",
    "# Print the first 14 rows of X_train DataFrame\n",
    "print(X_train[:14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86036b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkFile1 = os.path.isfile(\"data/dump/label_encoder.pkl\")\n",
    "checkFile2 = os.path.isfile(\"data/dump/label_decoder.pkl\")\n",
    "\n",
    "if not(checkFile1 and checkFile2):\n",
    "    labels = sorted(set(y_train.Emotion))\n",
    "    labelEncoder = {label: i for i, label in enumerate(labels)}\n",
    "    labelDecoder = {i: label for i, label in enumerate(labels)}\n",
    "\n",
    "    pickle.dump(labelEncoder, open('data/dump/label_encoder.pkl', 'wb'))\n",
    "    pickle.dump(labelDecoder, open('data/dump/label_decoder.pkl', 'wb'))\n",
    "else:\n",
    "    file1 = open('data/dump/label_encoder.pkl', 'rb')\n",
    "    file2 = open('data/dump/label_decoder.pkl', 'rb')\n",
    "    labelEncoder = pickle.load(file1)\n",
    "    labelDecoder = pickle.load(file2)\n",
    "    file1.close()\n",
    "    file2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6211e8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply label encoding to the \"Emotion\" column in y_train\n",
    "y_train[\"Emotion\"] = y_train[\"Emotion\"].apply(lambda x: encode_labels(labelEncoder, x))\n",
    "y_test[\"Emotion\"] = y_test[\"Emotion\"].apply(lambda x: encode_labels(labelEncoder, x))\n",
    "\n",
    "# Copy the encoded \"Emotion\" column from y_train to X_train\n",
    "X_train[\"Emotion\"] = y_train[\"Emotion\"].copy()\n",
    "X_test[\"Emotion\"] = y_test[\"Emotion\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a15940aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the file already exists\n",
    "checkFile1 = os.path.isfile(\"data/dump/labels_train.pkl\")\n",
    "checkFile2 = os.path.isfile(\"data/dump/labels_test.pkl\")\n",
    "\n",
    "if not (checkFile1 and checkFile2):\n",
    "    pickle.dump(X_train[\"Emotion\"], open('data/dump/labels_train.pkl', 'wb'))\n",
    "    pickle.dump(X_test[\"Emotion\"], open('data/dump/labels_test.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0db6676b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the file already exists\n",
    "checkFile = os.path.isfile(\"data/dump/train_labels.pkl\")\n",
    "\n",
    "# If the file doesn't exist, save the \"Emotion\" column of X_train DataFrame as train_labels.pkl\n",
    "if not checkFile:\n",
    "    pickle.dump(X_train[\"Emotion\"], open('data/dump/train_labels.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bfd7bc75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\final_yr\\23-24 t2\\THSST-2\\ug_thesis\\ER_GAT\\data/wiki-news-300d-1M.vec exists\n"
     ]
    }
   ],
   "source": [
    "# Define the file path\n",
    "file_path = os.path.join(os.getcwd(), \"data/wiki-news-300d-1M.vec\")\n",
    "    \n",
    "# Check if the file exists\n",
    "if os.path.isfile(file_path):\n",
    "    print(f\"{file_path} exists\")\n",
    "else:\n",
    "    print(f\"The file does not exist in the current directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb9d2864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total num. of words: 1583, word vector dimension: 300\n"
     ]
    }
   ],
   "source": [
    "# Define the vectors\n",
    "vectors = Vectors(name=\"wiki-news-300d-1M.vec\", url=\"data/\", cache=\"data/\")\n",
    "\n",
    "# Cache the vectors file\n",
    "# vectors.cache(name=\"data/wiki-news-300d-1M.vec\", url=\"data/\", cache=\"data/\")\n",
    "\n",
    "# Create vocabulary\n",
    "vocab = Vocab(\n",
    "    counter=collections.Counter(_read_words(X_train[\"Utterance\"])),\n",
    "    vectors=vectors,\n",
    "    specials=['<pad>', '<unk>'],\n",
    "    min_freq=5\n",
    ")\n",
    "\n",
    "# Print word embedding statistics\n",
    "wv_size = vocab.vectors.size()\n",
    "print('Total num. of words: {}, word vector dimension: {}'.format(\n",
    "    wv_size[0],\n",
    "    wv_size[1]\n",
    "))\n",
    "\n",
    "# Initialize word embeddings\n",
    "ebd = WORDEBD(vocab, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "adb829b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.stoi[\"get\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10574f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters using Munch\n",
    "args = Munch({\n",
    "    \"cnn_filter_sizes\": [3, 4, 5],\n",
    "    \"cnn_num_filters\": 100,\n",
    "    \"cuda\": -1,\n",
    "    \"mode\": \"train\",\n",
    "    \"snapshot\": '',\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1a4583",
   "metadata": {},
   "source": [
    "Creating an embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58701488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNNLSTMseq(\n",
      "  (ebd): WORDEBD(\n",
      "    (embedding_layer): Embedding(1583, 300)\n",
      "  )\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv1d(300, 100, kernel_size=(3,), stride=(1,))\n",
      "    (1): Conv1d(300, 100, kernel_size=(4,), stride=(1,))\n",
      "    (2): Conv1d(300, 100, kernel_size=(5,), stride=(1,))\n",
      "  )\n",
      "  (lstm): LSTM(300, 150, bidirectional=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model with word embeddings and parameters\n",
    "model = CNNLSTMseq(ebd, args)\n",
    "\n",
    "# Print the model object\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f1dd207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/03/20 18:22:51, Building embedding\n"
     ]
    }
   ],
   "source": [
    "print(\"{}, Building embedding\".format(\n",
    "    datetime.datetime.now().strftime('%y/%m/%d %H:%M:%S')), flush=True)\n",
    "\n",
    "if args.snapshot != '':\n",
    "    if args.multitask:\n",
    "        print(\"{}, Loading pretrained embedding from {}\".format(\n",
    "            datetime.datetime.now().strftime('%y/%m/%d %H:%M:%S'),\n",
    "            '%s_%s.ebd' % (args.snapshot, args.task)\n",
    "        ))\n",
    "        model.load_state_dict(torch.load('%s_%s.ebd' % (args.snapshot, args.task)), strict=False)\n",
    "    else:\n",
    "        print(\"{}, Loading pretrained embedding from {}\".format(\n",
    "            datetime.datetime.now().strftime('%y/%m/%d %H:%M:%S'),\n",
    "            '{}.ebd'.format(args.snapshot)\n",
    "        ))\n",
    "        model.load_state_dict(torch.load('{}.ebd'.format(args.snapshot)), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f7828620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNLSTMseq(\n",
       "  (ebd): WORDEBD(\n",
       "    (embedding_layer): Embedding(1583, 300)\n",
       "  )\n",
       "  (convs): ModuleList(\n",
       "    (0): Conv1d(300, 100, kernel_size=(3,), stride=(1,))\n",
       "    (1): Conv1d(300, 100, kernel_size=(4,), stride=(1,))\n",
       "    (2): Conv1d(300, 100, kernel_size=(5,), stride=(1,))\n",
       "  )\n",
       "  (lstm): LSTM(300, 150, bidirectional=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19929c11",
   "metadata": {},
   "source": [
    "Testing on smaller data. Uncomment to see the size of updated representations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da518513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data\n",
    "data = [\"how\", \"i see you hi\", \"foo my bad i want to see my babe\"]\n",
    "\n",
    "# Initialize variables\n",
    "input_data = []\n",
    "max_seq_len_list = []\n",
    "\n",
    "# Process each conversation in the data\n",
    "for conversation in data:\n",
    "    # Tokenize each conversation into words\n",
    "    conversation_tokens = conversation.split()\n",
    "\n",
    "    # Convert words to indices\n",
    "    turn_indices = [vocab.stoi[word] if word in vocab.stoi else vocab.stoi['<unk>'] for word in conversation_tokens]\n",
    "    turn_tensor = torch.tensor(turn_indices, dtype=torch.long)  # Specify data type as long\n",
    "\n",
    "    # Pad sequences to a fixed length (adjust this based on your model requirements)\n",
    "    max_seq_len = len(turn_tensor)\n",
    "    max_seq_len_list.append(max_seq_len)\n",
    "    padded_turn = torch.nn.functional.pad(turn_tensor, pad=(0, max_seq_len - len(turn_tensor)))\n",
    "\n",
    "    # Append the padded turn\n",
    "    input_data.append(padded_turn)\n",
    "\n",
    "# Determine the maximum sequence length across all conversations\n",
    "max_seq_len = max(5, max(max_seq_len_list))\n",
    "\n",
    "# Pad all conversations to the same maximum sequence length\n",
    "for i, padded_turn in enumerate(input_data):\n",
    "    input_data[i] = torch.nn.functional.pad(padded_turn, pad=(0, max_seq_len - len(padded_turn)))\n",
    "\n",
    "# Stack all padded turns along a new dimension to create batched input\n",
    "input_data_stacked = torch.stack(input_data)\n",
    "\n",
    "# Construct input data dictionary\n",
    "input_data_dict = {'Utterance': input_data_stacked}\n",
    "\n",
    "# Perform the forward pass (inference) to obtain the numerical representation\n",
    "with torch.no_grad():  # Disable gradient calculation during inference\n",
    "    output_representation = model(input_data_dict)\n",
    "\n",
    "# Output representation now contains the numerical representation of the input text dialog data\n",
    "# print(output_representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d786d8a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Utterance': tensor([[ 66,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  2,  70,   3,  88,   0,   0,   0,   0,   0],\n",
       "         [  1,  18, 257,   2,  78,   5,  70,  18,   1]])}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618d7e17",
   "metadata": {},
   "source": [
    "Extracting ranges of each dialog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3718155a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2160\n",
      "577\n"
     ]
    }
   ],
   "source": [
    "rangesTrain = find_value_ranges(X_train[\"Dialogue_ID\"])\n",
    "print(len(rangesTrain))\n",
    "\n",
    "rangesTest = find_value_ranges(X_test[\"Dialogue_ID\"])\n",
    "print(len(rangesTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb140da",
   "metadata": {},
   "source": [
    "<h4> Contextualizing Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7abe85c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out of 2160\n",
      "100 out of 2160\n",
      "200 out of 2160\n",
      "300 out of 2160\n",
      "400 out of 2160\n",
      "500 out of 2160\n",
      "600 out of 2160\n",
      "700 out of 2160\n",
      "800 out of 2160\n",
      "900 out of 2160\n",
      "1000 out of 2160\n",
      "1100 out of 2160\n",
      "1200 out of 2160\n",
      "1300 out of 2160\n",
      "1400 out of 2160\n",
      "1500 out of 2160\n",
      "1600 out of 2160\n",
      "1700 out of 2160\n",
      "1800 out of 2160\n",
      "1900 out of 2160\n",
      "2000 out of 2160\n",
      "2100 out of 2160\n",
      "Contexualized train data - Elapsed time: 11.40854787826538 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Initialize variables\n",
    "contexualEmbeddingsTrain = []\n",
    "max_seq_len_list = []\n",
    "\n",
    "# Check if the file exists\n",
    "# If the file doesn't exist, compute updated representations and save them\n",
    "if key:\n",
    "    for range_pair, iteration in zip(rangesTrain, range(len(rangesTrain))):\n",
    "        start_idx, end_idx = range_pair\n",
    "        \n",
    "        if iteration % 100 == 0:\n",
    "            print(f\"{iteration} out of {len(rangesTrain)}\")\n",
    "            \n",
    "        conversation = X_train['Utterance'][start_idx:end_idx + 1]\n",
    "        input_data = []\n",
    "\n",
    "        for utterance in conversation:\n",
    "            # Tokenize each conversation into words\n",
    "            utterance_tokens = utterance.split()\n",
    "\n",
    "            # Convert words to indices\n",
    "            turn_indices = [vocab.stoi[word] if word in vocab.stoi else vocab.stoi['<unk>'] for word in utterance_tokens]   \n",
    "            turn_tensor = torch.tensor(turn_indices, dtype=torch.long)  # Specify data type as long\n",
    "\n",
    "            # Pad sequences to a fixed length (adjust this based on your model requirements)\n",
    "            max_seq_len = len(turn_tensor)\n",
    "            max_seq_len_list.append(max_seq_len)\n",
    "            padded_turn = torch.nn.functional.pad(turn_tensor, pad=(0, max_seq_len - len(turn_tensor)))\n",
    "\n",
    "            # Append the padded turn\n",
    "            input_data.append(padded_turn)\n",
    "\n",
    "        # Determine the maximum sequence length across all conversations\n",
    "        max_seq_len = max(5, max(max_seq_len_list))\n",
    "\n",
    "        # Pad all conversations to the same maximum sequence length\n",
    "        for i, padded_turn in enumerate(input_data):\n",
    "            input_data[i] = torch.nn.functional.pad(padded_turn, pad=(0, max_seq_len - len(padded_turn)))  \n",
    "\n",
    "        # Stack all padded turns along a new dimension to create batched input\n",
    "        input_data_stacked = torch.stack(input_data)\n",
    "\n",
    "        # Construct input data dictionary\n",
    "        input_data_dict = {'Utterance': input_data_stacked}\n",
    "\n",
    "        # Perform the forward pass (inference) to obtain the numerical representation\n",
    "        with torch.no_grad():  # Disable gradient calculation during inference\n",
    "            output_representation = model(input_data_dict)\n",
    "\n",
    "        contexualEmbeddingsTrain.append(output_representation)\n",
    "\n",
    "        # Save the list to a file using pickle\n",
    "#         if iteration % 800 == 0 | iteration == len(ranges):\n",
    "    file_path = f'embed/u_prime_CNNBiLSTM_train.pkl'\n",
    "    with open(file_path, 'wb') as file:\n",
    "            pickle.dump(contexualEmbeddingsTrain, file)\n",
    "#             contexualEmbeddingsTrain = []\n",
    "\n",
    "# If the file exists, load the list from the file\n",
    "else:\n",
    "    file_path = 'embed/u_prime_CNNBiLSTM_train.pkl'\n",
    "    with open(file_path, 'rb') as file:\n",
    "        contexualEmbeddingsTrain = pickle.load(file)\n",
    "        \n",
    "# Record end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Contexualized train data - Elapsed time: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7646a2",
   "metadata": {},
   "source": [
    "<h4> Contexualizing Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ae993144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out of 577\n",
      "100 out of 577\n",
      "200 out of 577\n",
      "300 out of 577\n",
      "400 out of 577\n",
      "500 out of 577\n",
      "Contexualized test data - Elapsed time: 2.736368417739868 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Initialize variables\n",
    "contexualEmbeddingsTest = []\n",
    "max_seq_len_list = []\n",
    "\n",
    "# Check if the file exists\n",
    "# If the file doesn't exist, compute updated representations and save them\n",
    "if key:\n",
    "    for range_pair, iteration in zip(rangesTest, range(len(rangesTest))):\n",
    "        start_idx, end_idx = range_pair\n",
    "        \n",
    "        if iteration % 100 == 0:\n",
    "            print(f\"{iteration} out of {len(rangesTest)}\")\n",
    "            \n",
    "        conversation = X_test['Utterance'][start_idx:end_idx + 1]\n",
    "        input_data = []\n",
    "\n",
    "        for utterance in conversation:\n",
    "            # Tokenize each conversation into words\n",
    "            utterance_tokens = utterance.split()\n",
    "\n",
    "            # Convert words to indices\n",
    "            turn_indices = [vocab.stoi[word] if word in vocab.stoi else vocab.stoi['<unk>'] for word in utterance_tokens]   \n",
    "            turn_tensor = torch.tensor(turn_indices, dtype=torch.long)  # Specify data type as long\n",
    "\n",
    "            # Pad sequences to a fixed length (adjust this based on your model requirements)\n",
    "            max_seq_len = len(turn_tensor)\n",
    "            max_seq_len_list.append(max_seq_len)\n",
    "            padded_turn = torch.nn.functional.pad(turn_tensor, pad=(0, max_seq_len - len(turn_tensor)))\n",
    "\n",
    "            # Append the padded turn\n",
    "            input_data.append(padded_turn)\n",
    "\n",
    "        # Determine the maximum sequence length across all conversations\n",
    "        max_seq_len = max(5, max(max_seq_len_list))\n",
    "\n",
    "        # Pad all conversations to the same maximum sequence length\n",
    "        for i, padded_turn in enumerate(input_data):\n",
    "            input_data[i] = torch.nn.functional.pad(padded_turn, pad=(0, max_seq_len - len(padded_turn)))  \n",
    "\n",
    "        # Stack all padded turns along a new dimension to create batched input\n",
    "        input_data_stacked = torch.stack(input_data)\n",
    "\n",
    "        # Construct input data dictionary\n",
    "        input_data_dict = {'Utterance': input_data_stacked}\n",
    "\n",
    "        # Perform the forward pass (inference) to obtain the numerical representation\n",
    "        with torch.no_grad():  # Disable gradient calculation during inference\n",
    "            output_representation = model(input_data_dict)\n",
    "\n",
    "        contexualEmbeddingsTest.append(output_representation)\n",
    "\n",
    "        # Save the list to a file using pickle\n",
    "#         if iteration % 800 == 0 | iteration == len(ranges):\n",
    "    file_path = f'embed/u_prime_CNNBiLSTM_test.pkl'\n",
    "    with open(file_path, 'wb') as file:\n",
    "            pickle.dump(contexualEmbeddingsTest, file)\n",
    "#             contexualEmbeddingsTrain = []\n",
    "\n",
    "# If the file exists, load the list from the file\n",
    "else:\n",
    "    file_path = 'embed/u_prime_CNNBiLSTM_test.pkl'\n",
    "    with open(file_path, 'rb') as file:\n",
    "        contexualEmbeddingsTest = pickle.load(file)\n",
    "        \n",
    "# Record end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Contexualized test data - Elapsed time: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635c6c03",
   "metadata": {},
   "source": [
    "<h4> Getting speaker encoder for train setÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4459dbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the file exists\n",
    "checkFile = os.path.isfile(\"data/dump/speaker_encoder_train.pkl\")\n",
    "encodedSpeakersTrain = []\n",
    "\n",
    "if not checkFile:\n",
    "    for range_pair in rangesTrain:\n",
    "        start_idx, end_idx = range_pair\n",
    "        speaker_per_dialog = X_train['Speaker'][start_idx:end_idx + 1].copy()\n",
    "        speaker_feature = sorted(set(speaker_per_dialog))\n",
    "        speaker_encoder = {feature: i for i, feature in enumerate(speaker_feature)}\n",
    "        speaker_decoder = {i: feature for i, feature in enumerate(speaker_feature)}\n",
    "\n",
    "        encoded_speaker = speaker_per_dialog.replace(speaker_encoder)\n",
    "        encodedSpeakersTrain.append(encoded_speaker)\n",
    "\n",
    "    # Save encoded speaker list and ranges to a file using pickle\n",
    "    file_path = 'data/dump/speaker_encoder_train.pkl'\n",
    "    with open(file_path, 'wb') as file:\n",
    "        pickle.dump([encodedSpeakersTrain, rangesTrain], file)\n",
    "else:\n",
    "    # Load encoded speaker list and ranges from the existing pickle file\n",
    "    file = open('data/dump/speaker_encoder_train.pkl', \"rb\")\n",
    "    encodedSpeakersTrain, rangesTrain = pickle.load(file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cf00b0",
   "metadata": {},
   "source": [
    "<h4> Getting speaker encoder for test setÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "65ff6791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the file exists\n",
    "checkFile = os.path.isfile(\"data/dump/speaker_encoder_test.pkl\")\n",
    "encodedSpeakersTest = []\n",
    "\n",
    "if not checkFile:\n",
    "    for range_pair in rangesTest:\n",
    "        start_idx, end_idx = range_pair\n",
    "        speaker_per_dialog = X_test['Speaker'][start_idx:end_idx + 1].copy()\n",
    "        speaker_feature = sorted(set(speaker_per_dialog))\n",
    "        speaker_encoder = {feature: i for i, feature in enumerate(speaker_feature)}\n",
    "        speaker_decoder = {i: feature for i, feature in enumerate(speaker_feature)}\n",
    "\n",
    "        encoded_speaker = speaker_per_dialog.replace(speaker_encoder)\n",
    "        encodedSpeakersTest.append(encoded_speaker)\n",
    "\n",
    "    # Save encoded speaker list and ranges to a file using pickle\n",
    "    file_path = 'data/dump/speaker_encoder_test.pkl'\n",
    "    with open(file_path, 'wb') as file:\n",
    "        pickle.dump([encodedSpeakersTest, rangesTest], file)\n",
    "else:\n",
    "    # Load encoded speaker list and ranges from the existing pickle file\n",
    "    file = open('data/dump/speaker_encoder_test.pkl', \"rb\")\n",
    "    encodedSpeakersTest, rangesTest = pickle.load(file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530a19cb",
   "metadata": {},
   "source": [
    "Unsupervised visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b5f1de43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Concatenate all the tensors representing individual utterances\n",
    "# concatenated_tensors = []\n",
    "# for dialogue_tensor in updated_representations:\n",
    "#     concatenated_tensors.extend(dialogue_tensor)\n",
    "\n",
    "# # Convert the concatenated list of tensors into a single tensor\n",
    "# tensor_utterances = torch.stack(concatenated_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "12995d9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'anger',\n",
       " 1: 'disgust',\n",
       " 2: 'fear',\n",
       " 3: 'joy',\n",
       " 4: 'neutral',\n",
       " 5: 'sadness',\n",
       " 6: 'surprise'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "23c553ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(labelDecoder.values())\n",
    "num_instance=len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3d031c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anger: 1500 occurrences\n",
      "disgust: 364 occurrences\n",
      "fear: 338 occurrences\n",
      "joy: 2312 occurrences\n",
      "neutral: 5960 occurrences\n",
      "sadness: 876 occurrences\n",
      "surprise: 1490 occurrences\n"
     ]
    }
   ],
   "source": [
    "# Calculate the counts for each unique label\n",
    "unique_labels, label_counts = np.unique(list(X_train[\"Emotion\"][:num_instance]), return_counts=True)\n",
    "\n",
    "# Print the counts for each unique label\n",
    "for label, count in zip(unique_labels, label_counts):\n",
    "    print(f\"{labelDecoder[label]}: {count} occurrences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c07b8f",
   "metadata": {},
   "source": [
    "<h4> Visualize utterance embeddnig (u') with T-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d430fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = torch.tensor(X_train[\"Emotion\"][:num_instance])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1043832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed63efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# runTSNE = 1\n",
    "# if runTSNE:\n",
    "#     from sklearn.manifold import TSNE\n",
    "#     import matplotlib.pyplot as plt\n",
    "\n",
    "#     # List of perplexity values to loop over\n",
    "#     perplexity_values = [50, 100]\n",
    "\n",
    "#     # Loop over each perplexity value\n",
    "#     for perplexity in perplexity_values:\n",
    "#         # Initialize t-SNE with the current perplexity value\n",
    "#         tsne = TSNE(n_components=2, perplexity=perplexity, random_state=42)\n",
    "\n",
    "#         # Fit and transform the data using t-SNE\n",
    "#         h_prime_tsne = tsne.fit_transform(tensor_utterances[:num_instance].detach().numpy())\n",
    "\n",
    "#         # Plot the node embeddings with different colors for each label\n",
    "#         plt.figure(figsize=(10, 8))\n",
    "#         for label, emotion in zip(range(len(label_encoder)), label_encoder):\n",
    "#             indices = (labels == label).nonzero().squeeze()\n",
    "#             plt.scatter(h_prime_tsne[indices, 0], h_prime_tsne[indices, 1], label=f'{emotion}')\n",
    "#         plt.title(f'Utterance Embeddings (Train) Visualization (t-SNE) - Perplexity {perplexity}', color=\"white\")\n",
    "#         plt.xlabel('Dimension 1', color=\"white\")\n",
    "#         plt.ylabel('Dimension 2', color=\"white\")\n",
    "#         plt.legend()\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e2170c",
   "metadata": {},
   "source": [
    "<h4> Visualize utterance embedding (u') with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e6dc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca = PCA(n_components=2)\n",
    "# pca_result = pca.fit_transform(tensor_utterances[:num_instance].detach().numpy())\n",
    "\n",
    "# # Plot the PCA result with color-coded labels\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# for label in np.unique(labels):\n",
    "#     indices = labels == label\n",
    "#     plt.scatter(pca_result[indices, 0], pca_result[indices, 1], label=f'{label_decoder[label]}', alpha=0.5)\n",
    "# plt.title('PCA Visualization of Utterance Embeddings (Train) with Color-Coded Labels')\n",
    "# plt.xlabel('Principal Component 1')\n",
    "# plt.ylabel('Principal Component 2')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
